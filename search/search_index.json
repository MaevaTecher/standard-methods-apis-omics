{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This online resource is part of the chapter \u201cStandard methods and good practices in Apis honey bee \u2018omics research\u201d from the BEEBOOK volume IV. </p> <p>This collaborative work has been developed by 16 honey bee experts, which you can learn more about in the Meet the Team section.</p> <p>You can easily navigate between each section using the table of contents on the left side.</p>"},{"location":"#citation","title":"Citation","text":"<p>Please cite the methods and tutorials described here as:</p> <p>\u201cTecher et al., Standard methods and good practices in Apis honey bee omics research, Journal of Apicultural Research TJAR (in press)\"</p>"},{"location":"Section_1/","title":"1. The \u2018omics revolution in Apis: More data than meets the eye","text":"<p>While digging into our evolutionary history through archeology, we found that humans have interacted with bees for at least 40,000 years, revealing a profound and intricate connection (d\u2019Errico et al., 2012). In the native range of the honey bee Apis mellifera, beeswax was utilized in pottery during the Neolithic agricultural revolution (Roffet-Salque et al., 2015). Given this ancient relationship and associated benefits, it came as no surprise that the western honey bee genome was among the first insects to be sequenced in 2006 (Honeybee Genome Sequencing Consortium, 2006; Toth &amp; Zayed, 2021). This breakthrough paved the way for multiple research avenues and applications for studying A. mellifera evolution, biology, behavior, genetics, conservation, and health, which have been extensively reviewed by Toth and Zayed (2021) and Grozinger and Zayed (2020). Still, the Apis genus (Apidae, Hymenoptera) encompasses at least ten other species showing an incredible diversity of adaptations in Asia and Oceania (Panziera et al., 2022; Radloff et al., 2010; Randall Hepburn &amp; Radloff, 2011).</p> <p>Toth and Zayed (2020) have thoroughly summarized the explosive growth of honey bee genetics and genomics studies since 2006. Early on, short DNA and RNA sequences obtained via Sanger sequencing (~100-1500 bp) regularly enriched the A. mellifera GenBank database. Now, progressively high-throughput and next-generation sequencing (NGS) technologies produce millions of sequences per individual and must be compiled into \u201cdigestible\u201d Sequence Read Archive (SRA) format. This massive volume of genetic data can be overwhelming and is likely underutilized. For example, our search in the SRA Run Selector of NCBI (accessed on 23 January 2023), yielded 15,458 hits strictly associated with <code>(Apis[Organism]) AND \"Apis mellifera\"[orgn:_txid7460]</code> (Figure 1A). This creates opportunities for processing and comparing large data sets of A. mellifera but requires a standardized baseline for future comparative questions and analyses.</p> <p>The actual SRA size generated from A. mellifera genomes and metagenomes is surely underestimated here, due to inconsistencies in the metadata reports. Evans et al. (2013) anticipated the comparison hardships and discordances that could arise from such a global burst of data and responded with the first set of standard methods and molecular toolkits for A. mellifera. The timely publication of the resulting BEEBOOK chapter preceded the release of 99.2% (n = 8,185) and 94.1% (n= 4,715) of the total genomic and transcriptomic SRA available at the time of our survey, respectively. This emphasizes the need of standardizing not only the upstream data generation processes (e.g., sampling, wet lab processing and sequencing) but also downstream processes (such as sharing and facilitating open access distribution online).</p> <p></p>"},{"location":"Section_1/#figure-1-the-cumulated-short-read-archive-on-ncbi-for-a-apis-mellifera-or-b-apis-stricto-sensu-reflects-the-burst-in-genetic-and-genomic-resources-since-the-release-of-the-western-honey-bee-genome-in-2006","title":"Figure 1. The cumulated short read archive on NCBI for A) \u201cApis mellifera\u201d or B) \u201cApis\u201d stricto sensu reflects the burst in genetic and genomic resources since the release of the western honey bee genome in 2006.","text":"<p>If A. mellifera remains the winning and most curated species within Apis genus, its sister species A. cerana displays an early similar growth trajectory (Figure 1B). Since 2011, multiple and improved versions of five Apis species genomes have been sequenced (Figure 2), offering new opportunities for the comparison of their biology and genomes. The development of new BEEBOOK chapters dedicated to A. cerana and the further recognition of its unique evolutive history and biological traits are likely to drive a burst in data generation, analysis, and sharing. Fortunately, many of the molecular standard methods are applicable beyond A. mellifera and, in some cases, transferrable to other arthropods (Childers et al., 2021; Lawniczak et al., 2022).</p> <p></p>"},{"location":"Section_1/#figure-2-five-reference-genomes-of-apis-honey-bee-species-have-been-assembled-and-improved-since-the-first-genome-release-the-current-timeline-of-the-assemblies-publicly-released-eg-acsnu-20-gfc_0014425551-as-well-as-the-representative-genome-refseq-for-each-species-and-subspecies-was-built-using-the-latest-ncbi-update","title":"Figure 2. Five reference genomes of Apis honey bee species have been assembled and improved since the first genome release. The current timeline of the assemblies publicly released (e.g., ACSNU-2.0 [GFC_001442555.1]), as well as the representative genome (RefSeq) for each species and subspecies, was built using the latest NCBI update.","text":"<p>In parallel, the emergence of new omics techniques and steady progress in wet lab and bioinformatics techniques urged a revision and expansion of the Evans et al. (2013) chapter. The data generated by epigenomics, proteomics, and metabolomics are also expanding resources, and it becomes crucial to understand how to analyze, use and share them efficiently. Ultimately, Apis research will move toward multi-omics integration, and it will become crucial to efficiently utilize unique or rare samples for multiple layers of data generation and analysis. We encourage niche-specialized Apis researchers to familiarize themselves with the outputs and capabilities of each omic method to fully leverage the wealth of accessible data. Leveraging our experience with the transient nature of omics technologies and bioinformatics pipelines, we have enhanced this BEEBOOK chapter into an interactive wiki-style format (Deligkaris, 2022). We compiled the most up-to-date methods while also describing the applications and limitations. Finally, we offer recommendations for the standardization of data sharing in view of the omics future in Apis. Our hope is that this chapter will become a lasting resource as the technologies continue to advance.</p>"},{"location":"Section_10_1/","title":"10. Microbiome analysis","text":""},{"location":"Section_10_1/#101-introduction","title":"10.1. Introduction","text":"<p>The increased concern for honey bee health has led to a collective effort by researchers to unravel the major contributors to honey bee fitness. Increasingly, the microbiome \u2013 the suite of microorganisms, from their genes to metabolites \u2013 is thought to play a major role in honey bee health. Nine main bacterial taxa compose the gut microbiome of honey bee workers, and among them, Snodgrassella, Gilliamella, Bombilactobacillus, Lactobacillus nr. melliventris, and Bifidobacterium form what is known as the core gut microbiome (Zheng et al., 2018). Thus far, we know these gut-associated bacteria contribute to the honey bee\u2019s nutrition (Engel &amp; Moran, 2013; Ke\u0161nerov\u00e1 et al., 2017), immune system (Kwong et al., 2017), detoxification of xenobiotics (Wu et al., 2020), response against pathogens (Raymann et al., 2018), colony structure through nestmate recognition (Vernier et al., 2020), and several other roles that ultimately impact colony fitness (Figure 22A).</p> <p>Though the interconnectedness between honey bee gut microbiota and honey bee health is undeniable, the interconnectedness between honey bee health and the microbiome of hive interiors should also be taken into account. Honey bees are highly eusocial insects, meaning the entire colony - individuals, environments, and associated microbes - will impact the colony's success. Also, honey bees will spend most of their lives within the hive, where horizontal transmission of microbes between beehive environments and the individuals occurs (Anderson et al., 2013). Pesticides, for example, not only cause microbiota dysbiosis on honey bee guts (Kowallik &amp; Mikheyev, 2021; Motta &amp; Moran, 2020), but also accumulate to dangerous levels within hives (Calatayud-Vernich et al., 2018), and may thus affect the different microbial communities present within managed colonies. In addition, food reserves (bee bread, nectar, etc.) can also act as pathogen reservoirs within honey bee colonies and may contribute to pathogen transmission.</p> <p>Until recently, the majority of bee microbiome investigations focused on the worker bee gut composition and used culture-dependent genome sequencing or 16S rRNA gene amplicon sequencing to characterize the entire bacterial community (Kwong et al., 2017). However, shot-gun metagenomic approaches have been proving that the microbiome of honey bees may be much more diverse than previously thought. In a single colony, the microbiome can greatly differ among individuals at the strain-level, and this translates to differences in functional capabilities (Ellegaard &amp; Engel, 2019), which may be also related to the diversity of phages infecting these strains (Bonilla-Rosso et al., 2020; Deboutte et al., 2020). In addition, fungi are also starting to gain more notoriety in microbiome studies, since they are prevalent in bee colonies and may have important interactions with the whole microbial community and the bees (Anderson et al., 2011). Therefore, both amplicon sequencing (16S rRNA for bacteria, ITS for fungi) and shot-gun metagenomics are useful approaches in a microbiome study.</p> <p>With modified sampling protocols, microbiome studies can be conducted on both tissue samples and hive samples, such as propolis, wax, and honey (Figure 22B). Here we present protocols for conducting basic tissue and non-tissue microbiome studies focused on culture-independent approaches that are appropriate for the first screen of bacterial and fungal communities. While some of the methods described here are equivalent to those described in Engel et al. (2016) and derived from general recommendation for microbiome studies (Hammer et al., 2015), we have included additional sample preparation measures to reduce noise in the data, procedures for sampling hive materials, a worked example of data analysis procedures (including amplicon sequence variant (ASV)-based analysis), links to external resources, and updated commentary on where the field is headed.</p> <p></p>"},{"location":"Section_10_1/#figure-22-microbiome-overview-a-ways-the-gut-microbiome-can-influence-honey-bees-and-colony-fitness-b-types-of-samples-and-sequencing-approaches-results-of-culture-dependent-genome-sequencing-are-limited-to-taxa-amenable-to-laboratory-cultures-while-shot-gun-metagenomics-offers-the-widest-taxa-breadth-note-the-difference-between-mature-bee-bread-shiny-surface-and-fresh-pollen-chalky-surface-photos-by-leslie-kennah","title":"Figure 22. Microbiome overview. A) Ways the gut microbiome can influence honey bees and colony fitness. B) Types of samples and sequencing approaches. Results of culture-dependent genome sequencing are limited to taxa amenable to laboratory cultures, while shot-gun metagenomics offers the widest taxa breadth. Note the difference between mature bee bread (shiny surface) and fresh pollen (chalky surface). Photos by Leslie Kennah.","text":""},{"location":"Section_10_2/","title":"10. Microbiome analysis","text":""},{"location":"Section_10_2/#102-sampling-and-dna-extraction","title":"10.2. Sampling and DNA extraction","text":""},{"location":"Section_10_2/#1021-considerations","title":"10.2.1. Considerations","text":""},{"location":"Section_10_2/#10211-general","title":"10.2.1.1. General","text":"<ul> <li> <p>If you won\u2019t be able to use the fresh samples for the DNA extraction or would like to culture microbes from them later, you may follow the procedures for sampling or dissection, then macerate each sample in individual tubes with 1X PBS, add glycerol to a final concentration of 25% and store them at -80 \u00b0C until use.</p> </li> <li> <p>Change dissection and sample collection instruments (tweezers, scissors, scalpels, spoons, etc.) between samples. If you don't have the option of using individual tools per sample, you can clean instruments between dissections by dipping them in 70% ethanol and flame sterilizing them, or use disposable individual scalpel sterile blades.</p> </li> <li> <p>It is a good practice to check for DNA quality and quantity in a 1% agarose gel and Qubit Fluorometer, or directly in an 4200 TapeStation (Agilent Technologies Inc.), following quality parameters stated by the manufacturer.</p> </li> <li> <p>Controlling cross-contamination is essential. Spin tubes before opening them, especially after incubation steps, to avoid contamination due to any drops inside the caps.</p> </li> <li> <p>You must include negative controls along with the whole experiment: DNA extraction, PCR (in the case of amplicon sequencing), library preparation, and sequencing. These negative controls should be obtained following the exact same protocol as the regular samples, but substituting sample by the buffer. This will allow you to identify contaminants in your sample post-sequencing.</p> </li> <li> <p>In addition to relative quantities, you can also recover absolute quantities of microbiome members by using a spike-in standard control containing accurately quantified cell numbers of specific microbe combinations.</p> </li> </ul>"},{"location":"Section_10_2/#10212-tissue-sample-handling","title":"10.2.1.2. Tissue sample handling","text":"<ul> <li> <p>If your investigation will focus on the microbes associated with internal organs, you may consider surface-sterilizing the larvae or adult bee to ensure you do not contaminate your sample. However, this is a time-consuming step that may not have a significant impact on results (Hammer et al., 2015).</p> </li> <li> <p>The same protocol makes use of commercial kits and suggests specific sequencing platforms for the purpose of presenting a complete procedure. However, while certain steps are essential for reliable microbiome characterization \u2013 as indicated in the protocol \u2013 the materials used can be replaced according to availability.</p> </li> </ul>"},{"location":"Section_10_2/#10213-hive-material-sample-handling","title":"10.2.1.3. Hive material sample handling","text":"<ul> <li> <p>Considering the multiple sources of pollen and saliva in bee bread, the pooling of multiple cells (\u2265 10 cells) is recommended to obtain a representative sample. If possible, the targeted cells to be used for DNA extraction should be located on both sides of the comb and on different comb edges.</p> </li> <li> <p>Bee bread physicochemical characteristics change over time and affect the bee bread microbiome. Thus, sampling bee bread cells of similar ages is also recommended. Recently packed pollen cells will have separated layers and a porous, chalky texture, crumbling easily. Older bee bread will still have various layers, but with a more waxy and shiny texture.</p> </li> <li> <p>For sampling hard surfaces, e.g. the hive entrance, we recommend using cotton-headed swabs, which facilitate in-field sampling, sample transportation, and storage. The drawback of this sampling method is the low DNA load, often paired with low absorbance scores (&lt; 10 ng/\u03bcl).</p> </li> </ul>"},{"location":"Section_10_2/#1022-protocol-for-tissue-samples","title":"10.2.2. Protocol for tissue samples","text":""},{"location":"Section_10_2/#10221-materials","title":"10.2.2.1. Materials","text":"<ul> <li> <p>Kits: DNeasy Blood &amp; Tissue Kit (QIAGEN) and complementary reagents.</p> </li> <li> <p>Equipment: Dissection microscope, bead-beating tissue homogenizer (e.g. FastPrep-24\u2122 5G, (MP Biomedicals); or Precellys-24, (Bertin Technologies)), microtubes, pipettes, and tips (10 - 1000 ul).</p> </li> <li> <p>Reagents: 70% ethanol, 1X PBS, 0.1% sodium hypochlorite solution and 0.22 \u03bcm filtered or autoclaved water (optional).</p> </li> <li> <p>Disposable dissection tools or materials for quick sterilization of tools between samples (70% ethanol and a flame).</p> </li> <li> <p>Sample tubes suitable for a bead-beating homogenizer (e.g. Lysing Matrix E tubes, (MP Biomedicals))</p> </li> </ul>"},{"location":"Section_10_2/#10222-dissection-methods","title":"10.2.2.2. Dissection methods","text":"<ol> <li> <p>Clean and sterilise bench and tools with 70% ethanol.</p> </li> <li> <p>Rinse the bee\u2019s body for 3 min in 0.1% sodium hypochlorite and then 3 times in filtered, autoclaved water (optional; see Considerations).</p> </li> <li> <p>Dissect each tissue sample with a new, sterile microdissection tool to avoid cross-contamination. See Carreck et al. (2013) for guidance on dissecting specific tissues.</p> </li> <li> <p>Place the tissue sample in a homogenization tube and proceed to lysis (Section 10.2.2.3). TIP: If you are only interested in the bacterial fraction, a lysozyme treatment for bacterial cell wall lysis before DNA extraction may also be a good lysis option.</p> </li> </ol>"},{"location":"Section_10_2/#10223-dna-extraction-methods","title":"10.2.2.3. DNA extraction methods","text":"<ol> <li>Add your sample to a Lysing Matrix E tube with 400 \u00b5L of 1X PBS. Homogenize in FastPrep-24\u2122 5G for 45 s at speed 6 m/s.</li> <li>Transfer 180 \u00b5l of the sample to a new tube, add 20 \u03bcL of proteinase K from DNeasy Blood &amp; Tissue Kit (QIAGEN) and incubate the samples for 2 h at 56 \u00b0C. Vortex occasionally during incubation.</li> <li>Add 4 \u00b5l RNase A (100 mg/ml), mix by vortexing, and incubate for 2 min at room temperature (~ 22\u00b0C).</li> <li>Continue by following the recommended steps of the DNeasy Blood &amp; Tissue Kit (QIAGEN) manufacturer\u2019s protocol for \u201cPurification of Total DNA from Animal Tissues (Spin-Column Protocol)\u201d. For a small amount of initial tissue (e.g., 1 bee gut) elute the DNA in the final step with 2 x 30 \u03bcL of AE buffer to improve yields.</li> <li>Store the DNA samples at \u2264 -20 \u00b0C until ready for sequencing.</li> </ol>"},{"location":"Section_10_2/#1023-protocol-for-sampling-hive-materials","title":"10.2.3. Protocol for sampling hive materials","text":"<p>Bee bread is a sugar-rich mixture of packed pollen, nectar, honey, and enzymes derived from the saliva of honey bees (Anderson et al., 2011). Bee activity and lactic acid bacteria acidify this mixture over time, resulting in decreased bacterial yet increased fungal populations (Disayathanoowat et al., 2020). The bee bread bacteriome is dominated by Proteobacteria and Actinobacteria (Anderson et al., 2011; Disayathanoowat et al., 2020; Mu\u00f1oz-Colmenero et al., 2020).</p> <p>The hive entrance, on the other hand, acts as a barrier, separating the hive interior and exterior. Thus, this hive niche can be used to detect and measure organisms entering or leaving beehives. However, there is scarce knowledge regarding the microbial diversity and composition of this beehive niche.</p>"},{"location":"Section_10_2/#10231-materials","title":"10.2.3.1. Materials","text":"<ul> <li> <p>Kits: QIAamp DNA Mini Kit (QIAGEN)</p> </li> <li> <p>Equipment: thermal mixer, vortex, and centrifuge, pipettes, pipette tips, microtubes, chemical hood (bee bread samples only), sterile cotton swabs (hive entrance samples only)</p> </li> <li> <p>Reagents: 1x PBS, 96-100% ethanol (to prepare kit solutions)</p> </li> <li> <p>For bee bread samples only: phenol:chloroform:isoamyl alcohol (25:24:1, v/v), chloroform (&gt;99%)</p> </li> </ul>"},{"location":"Section_10_2/#10232-methods-for-bee-bread-sampling-and-dna-extraction","title":"10.2.3.2. Methods for bee bread sampling and DNA extraction","text":"<ol> <li> <p>In a comb piece containing bee bread, locate a non-broken and preferably full cell.</p> </li> <li> <p>Depending on sample consistency, introduce either tweezers depth inside the cell (at each side of the bee bread) or a large pipette tip (i.e. cut 1000 \u03bcl tips) through the center.</p> </li> <li> <p>Pull out the bee bread carefully, shaking gently, and introduce it into a clean tube large enough to hold pooled samples (2-15 mL). Break the bee bread inside the tube to facilitate subsequent steps</p> </li> <li> <p>Repeat steps 1-4 until an appropriate number of cells are obtained.</p> </li> <li> <p>Add 1 mL of 1x PBS per cell (i.e. 4 mL to a tube containing samples from 4 cells) and homogenize (pipetting) until the sample is uniformly suspended.</p> </li> <li> <p>Transfer 200 \u03bcl of sample to a new tube. The remaining sample can be stored at -20 \u00b0C (-80 \u00b0C, ideally) in case the extraction must be repeated.</p> </li> <li> <p>Add 40 \u03bcl of proteinase K and 400 \u03bcl of Buffer AL, vortex (~15 seconds) and incubate at 56 \u00b0C (mixing at 600 rpm) for 1 hour.</p> </li> <li> <p>Now, work in a fume hood. Transfer the supernatant to a new tube, add 600 \u03bcl of phenol:chloroform:isoamyl alcohol, vortex intensely, and centrifuge for 15 min at 14,000 rpm. NOTE: For lab space in which hazardous agents phenol:chloroform can not be used, we recommend the usage of commercial kits dedicated to microbiome DNA extraction as an alternative</p> </li> <li> <p>Transfer the supernatant to a new tube, add 600 \u03bcl of chloroform, vortex intensely, and centrifuge for 5 min at 14,000 rpm.</p> </li> <li> <p>Transfer the supernatant to a new tube, add 400 \u03bcl of 96-100% ethanol, vortex briefly (~15 seconds), and spin.</p> </li> <li> <p>Working in the fume hood is no longer necessary. Transfer the sample (supernatant from step 10) to the column (no more than 700 \u03bcl) and follow the established DNA extraction protocol for the kit, until eluting the DNA in 60 \u03bcl of buffer AE.</p> </li> <li> <p>Store the DNA samples at \u2264 -20 \u00b0C until ready for sequencing.</p> </li> </ol>"},{"location":"Section_10_2/#10233-methods-for-hive-entrance-sampling-and-dna-extraction","title":"10.2.3.3. Methods for hive entrance sampling and DNA extraction","text":"<ol> <li> <p>In order to collect microorganisms stuck to the hive entrance or door, use sterile cotton swabs to scrub the surface. To maximize surface covering, the entrance should be swabbed by scrubbing left and right several times (~6) per swab tip (using 3 \u2013 4 swabs per hive).</p> </li> <li> <p>Cut the heads of two cotton swab samples, deposit in a 2 mL tube, and add 800\u03bcl of PBS.</p> </li> <li> <p>Add 20 \u03bcl of protease and 400 \u03bcl of AL Buffer and vortex.</p> </li> <li> <p>Incubate at 56 \u00baC and 900 rpm for 1.5 hours.</p> </li> <li> <p>Transfer the liquid to a new tube (tube A) and add 20 \u03bcl of protease plus 400 \u03bcl of AL Buffer to the original tube (tube B).</p> </li> <li> <p>Incubate both tubes A and B at 56 \u00b0C and 900 rpm for 1.5 hours.</p> </li> <li> <p>Add 400 \u03bcl of 96-100% ethanol and vortex briefly (~15 seconds).</p> </li> <li> <p>Transfer the sample to the column (no more than 700 \u03bcl) and follow the established DNA extraction protocol, until eluting the DNA in 100 \u03bcl of buffer AE. TIP: Using a larger elution volume increases sample recovery.</p> </li> <li> <p>Store the DNA samples at \u2264 -20 \u00b0C until ready for sequencing.</p> </li> </ol>"},{"location":"Section_10_3/","title":"10. Microbiome analysis","text":""},{"location":"Section_10_3/#103-amplicon-sequencing","title":"10.3. Amplicon sequencing","text":"<p>Gene-based markers for bacterial and fungal identification, also known as amplicon sequencing or metabarcoding, is often performed through bacterial- or fungal-specific marker gene sequencing. 16S rRNA gene amplification is the most common for bacteria, while the 18S rRNA gene or the internal transcribed spacer (ITS) are used for fungal analysis (Romero et al., 2019). The 16S rRNA gene is constituted by 9 hypervariable regions (V1-V9) surrounded by conserved sequences (Chakravorty et al., 2007) , which are conserved yet variable enough to be differentiated in most bacterial species. The eukaryotic 18S rRNA gene is not as conserved as its prokaryotic equivalent and often results in unidentified taxa (Frau et al., 2019). Longer ITSs (ITS1, ITS2, and the 5.8S rRNA gene), however, have been successfully used to identify fungal gut species in honey bees (Decker et al., 2023; Nguyen &amp; Rehan, 2022; Wen et al., 2017; Yun et al., 2018). The approach described below provides a generic guide for how to conduct amplicon sequencing for microbiome analysis, for which any of the abovementioned targets could be used. Important differences would be the design of the primer (specific to the target) and the amplification conditions.</p>"},{"location":"Section_10_3/#1031-considerations","title":"10.3.1. Considerations","text":"<ul> <li> <p>The choice of primer can alter diversity estimates and may alter the annealing efficiency for certain templates. Due to the sequence-length variation of ITS (Frau et al., 2019), it is important to carefully choose the pair of primers and sequencing platforms to use. We suggest following the Earth Microbiome protocols to choose primers for the amplification of 16S rRNA, 18S rRNA, and ITS barcode genes. Primers can be ordered directly from Integrated DNA Technologies (IDT) or Eurofins.</p> </li> <li> <p>We recommend buying the primers with adapters and barcodes included to reduce the handling and library synthesis cost downstream. For paired-end read sequencing in Illumina platforms, we also recommend targeting regions that will ensure a sequence overlap of at least ~50 bp.</p> </li> <li> <p>Conduct PCR for each primer pair in triplicate for each sample. These triplicate samples will be pooled at the end of amplification and serve to reduce random PCR artifacts across your reactions. Use a consistent quantity of DNA input (e.g., 200 ng).</p> </li> <li> <p>Use a proofreading high-fidelity polymerase (e.g., Phusion\u00ae High-Fidelity PCR Master Mix with HF Buffer, New England Biolabs, Inc) to limit spurious artifactual diversity introduced in your amplification of the genes.</p> </li> <li> <p>Negative control samples should always be sequenced. Some bacterial taxa are known contaminants derived from sample processing (e.g. DNA extraction kits) (Salter et al., 2014), while different sequencing platforms might favor amplification of specific microorganisms.</p> </li> <li> <p>Batch effects cause significant differences across experiments, unrelated to biotic factors. These effects are major issues in microbiome data, and common when processing samples using multiple sequencing runs. Thus, it is a good idea to always select a set of samples to use as a reference, which will be added to all sequencing runs of an experiment.</p> </li> <li> <p>Amplicon sequencing depth will strongly depend on the expected diversity of the gut microbiome (more diversity requires a higher depth to sample the community). Considering the published work on the bee microbiome, for example, we would recommend a first sequencing depth of 5,000 reads/sample.</p> </li> <li> <p>Demonstrated examples for bacterial and fungal) amplicon sequencing can be found on the Illumina website.</p> </li> </ul>"},{"location":"Section_10_3/#1032-materials-for-amplicon-sequencing","title":"10.3.2. Materials for amplicon sequencing","text":"<ul> <li> <p>Kits: PureLink PCR Purification Kit (Invitrogen), Quant-iT (Invitrogen), Nextera XT DNA Library Preparation Kit (Illumina), MiSeq Reagent Kit v2 (Illumina)</p> </li> <li> <p>Equipment: PCR thermocycler, fluorescent spectrophotometer (compatible with 96-well plates), MiSeq instrument (Illumina) agarose gel electrophoresis apparatus and associated reagents</p> </li> <li> <p>Reagents: Phusion\u00ae High-Fidelity PCR Master Mix with HF Buffer (New England Biolabs, Inc). Forward and Reverse primers to target the particular gene of interest (e.g. 16S rRNA, 18S rRNA, ITS)</p> </li> <li> <p>PCR plates</p> </li> </ul>"},{"location":"Section_10_3/#1033-methods-for-amplicon-sequencing","title":"10.3.3. Methods for amplicon sequencing","text":"<ol> <li> <p>Mix a defined quantity of DNA with 1 X of Phusion\u00ae High-Fidelity PCR Master Mix with HF Buffer (New England Biolabs, Inc), forward and reverse primers to a final concentration of 0.5 \u00b5M, in a final reaction volume of 50 \u00b5L.</p> </li> <li> <p>In the thermocycler run an initial denaturation at 98 \u00b0C for 2 min, followed by 30 cycles of 98 \u00b0C denaturation for 10 s, 55 \u00b0C annealing for 30 s and 72 \u00b0C extension for 30 s, with a final extension step at 72 \u00b0C for 10 min. TIP: Be attentive to primer melting point requirements and change the annealing temperature if needed.</p> </li> <li> <p>Check for the amplicon size in a 1 % agarose gel and then purify the PCR product with PureLink PCR Purification Kit following the manufacturer's recommendations. If you did not include barcodes in your primer synthesis, you must prepare libraries with the Nextera XT DNA Library Preparation Kit, following the manufacturer's instructions, using one barcode per sample.</p> </li> <li> <p>The amplicons produced as part of this protocol must be normalized by concentration and pooled for sequencing. If you will be pooling your samples yourself, we recommend using the Quant-iT kit, as per manufacturer instructions.</p> </li> <li> <p>After pooling your sample such that the same amount of DNA from each amplicon is added to your sequencing run, you will clean up your PCR amplicons using the PureLink PCR Purification Kit again.</p> </li> <li> <p>These amplicons should be sequenced using 2 \u00d7 250 paired-end reads on a Miseq platform using the MiSeq Reagent Kit v2.</p> </li> </ol>"},{"location":"Section_10_4/","title":"10. Microbiome analysis","text":""},{"location":"Section_10_4/#104-microbiome-data-analysis","title":"10.4. Microbiome data analysis","text":"<p>Regardless of whether 16S, 18S, or IST amplicons are used, the general principle is that microbial taxonomy can be inferred by comparing the gene fragment sequence to a specific database. Concurrently, relative abundances can be calculated based on the number of amplicon copies. Below we provide guidance on strategies and softwares that can be used to complete this type of analysis.</p>"},{"location":"Section_10_4/#1041-recommended-software","title":"10.4.1. Recommended software","text":"<p>There are currently several pieces of software used to process amplicon data, either by inferring operational taxonomic units (OTUs) or amplicon sequence variants (ASVs). While OTUs represent a cluster of multiple and similar sequences, for ASVs the differences in nucleotides will result in a unique variant and a more detailed picture of the diversity. We recommend here the Mothur pipeline (Schloss, 2020) for quality control of your reads, contig formation, chimera removal, alignment to the 16S rRNA gene, and generation of OTUs and ASVs. For taxonomy, Mothur uses Bayesian analysis of kmer profiles, returning the most likely match with the database. All these steps are detailed in the standard operating procedure (SOP) (Schloss, 2020).</p> <p>Commonly used databases are SILVA and UNITE, for bacteria and fungi respectively. Several other more curated databases are also available for the study of bee species, such as RDP for annotated bacterial and archaeal 16S rRNA sequences and fungal 28S rRNA sequences (Cole et al., 2014), and BEExact for bacterial 16S rRNA sequences often found in bee species (Daisley &amp; Reid, 2021). The choice of database is important, as it can lead to errors in taxonomic placement if sequence representatives from your environment are misidentified or absent (Newton &amp; Roeselers, 2012).</p> <p>The next steps may include statistical analyses and plotting results, for which you can continue to follow the Mothur SOP or the QIIME 2 pipeline (see Section 10.4.2). In general, we recommend measuring alpha diversity to generate rarefaction curves describing the number of OTUs or ASVs as a function of sampling effort, and beta diversity to compare samples\u2019 community structure. Distance matrices can be visualized using the Principal Coordinates Analysis (PCoA) or the Non-metric multidimensional scaling (NMDS) plots. You can also test for the microbiota dynamics with a Permutational Multivariate Analysis of Variance (PERMANOVA) using factors of your choice (e.g., caste, apiary, season, treatments). (Engel et al., 2013) has more information on these exploratory techniques. The Mothur wiki (https://mothur.org/wiki/)) has extensive information about data processing in their manual. Here, we provide an alternative worked example using QIIME 2.</p>"},{"location":"Section_10_4/#1042-guidance-on-the-data-analysis-methods-an-example-with-qiime-2","title":"10.4.2. Guidance on the data analysis methods: An example with QIIME 2","text":"<p>QIIME 2 (Bolyen et al., 2019) and its community (QIIME 2 forum; https://forum.qiime2.org/)) offer standardized pipelines for the analysis of microbial communities. QIIME 2 core concepts, hardware/software/metadata requirements, installation, (re)activation, and core applications are easily accessible in Qiime2 documentation (QIIME 2 docs), and not explained in this protocol. Keeping track of the official QIIME 2 docs is recommended since it will reflect the latest QIIME 2 release. Herein, we will only present the ITS-specific steps as an example. We will follow the Casava 1.8 protocol for paired-end demultiplexed sequences.</p>"},{"location":"Section_10_4/#10421-importing-data","title":"10.4.2.1. Importing data","text":"<p>Data importation in QIIME 2 is dependent on the data format. FASTQ documents containing single-end or paired-end sequences are the most common raw data. Forward and reverse sequences are usually referred to as R1 and R2, respectively, while barcode sequences are named I1 (index). FASTQ documents can be either multiplexed (one file per sequence \u201ctype\u201d, I1, R1, and/or R2) or demultiplexed (one file per sample, with its corresponding R1 and/or R2 sequences). The most common demultiplexed format is Casava, obtained through Illumina\u2019s Casava software. Although QIIME 2 has implemented commands for the easy importation of the most common data formats, any other type of data format (supported by QIIME 2) will have to be imported through \u201cFastq manifest\u201d (https://docs.qiime2.org/2021.8/tutorials/importing/?highlight=casava)) or similar pipelines.</p> <p>Step 1. To import the data, enter the following commands into the terminal:</p> <pre><code>qiime tools import \\\n  --type 'SampleData[PairedEndSequencesWithQuality]' \\\n  --input-path casava-18-paired-end-demultiplexed \\\n  --input-format CasavaOneEightSingleLanePerSampleDirFmt \\\n  --output-path demux-paired-end.qza\n</code></pre>"},{"location":"Section_10_4/#10422-non-biological-sequence-removal","title":"10.4.2.2. Non-biological sequence removal","text":"<p>Imported demultiplexed sequences contain \u201cnon-biological\u201d sequences (i.e., primers), which have to be removed. Hypervariable-length amplicons such as ITS can contain 4 non-biological sequences: F primer at the beginning of F sequences, reverse complementary sequence of the R primer at the end of F sequences, R primer at the beginning of R sequences, and reverse complementary sequence of the F primer at the end of R sequences.</p> <p>Step 2. To remove these non-biological sequences, execute the following commands:</p> <pre><code>qiime cutadapt trim-paired \\\n--i-demultiplexed-sequences demux-paired-end.qza \\\n--p-adapter-f GCATATCAATAAGCGGAGGA \\ #Reverse complementary sequence of Rp.\n--p-front-f  GTGARTCATCGAATCTTTG \\   #Forward primer (Fp) sequence: fITS7 \n--p-adapter-r CAAAGATTCGATGAYTCAC \\  #Reverse complementary sequence of Fp.\n--p-front-r TCCTCCGCTTATTGATATGC \\   #Reverse primer (Rp) sequence: ITS4\n--p-error-rate 0.1 \\   #Allowed error-rate (default)\n--o-trimmed-sequences trimmed.qza \\\n--verbose\n</code></pre>"},{"location":"Section_10_4/#10423-sequence-quality-control-denoising","title":"10.4.2.3. Sequence quality control (denoising)","text":"<p>Denoising in QIIME 2 can be performed through DADA2 (Callahan et al., 2016) or Deblur (Amir et al., 2017). DADA2 produces amplicon sequence variants (ASVs) while Deblur gives sub-operational-taxonomic-units (sub-OTUs or sOTUs). Herein, we will follow the DADA2 protocol, wherein paired-end reads are joined and denoised simultaneously. Two parameters are needed: trimming positions (starts of F and R reads) and truncating positions (ends of F and R reads). Both parameters can be determined by visualizing the demultiplexed data and checking the interactive quality plots, which contain quality score values per sequence base.</p> <p>Step 3. Determine trimming and truncating positions:</p> <pre><code>qiime demux summarize \\\n  --i-data trimmed.qza \\\n  --o-visualization trimmed.qzv\n</code></pre> <p>Optimal parameters result in merged reads of good quality. F and R have to be long enough to merge, and merged sequences have to be good enough to pass the filtering threshold of DADA2.</p> <p>Step 4. Trim primer sequences:</p> <pre><code>qiime dada2 denoise-paired \\ #Perform Dada2 denoising\n  --i-demultiplexed-seqs demux-paired-end_trimmed_def.qza \\\n  --p-trim-left-f 13 \\  #Trim Forward sequences in 13rd position\n  --p-trim-left-r 0 \\   #Do not trim Reverse sequences\n  --p-trunc-len-f 0 \\   #Do not truncate the end of Forward sequences\n  --p-trunc-len-r 220 \\ #Truncate Reverse sequences in 220th position\n  --o-table dada2/table.qza \\\n  --o-representative-sequences rep-seqs.qza \\\n  --o-denoising-stats denoising-stats.qza\n</code></pre> <p>Step 5. Visualize denoising results:</p> <pre><code>qiime metadata tabulate \\   \n--m-input-file denoising-stats.qza \\\n--o-visualization denoising-stats.qzv\n</code></pre> <p>From this point on, paired-end and single-end data are analyzed following the same steps, for all microbial communities. In order to assign taxonomy ID to fungal sequences, the UNITE database is used, which requires to be first trained. It is recommended to train the UNITE classifier as follows:</p> <ul> <li> <p>Use non-extracted full ITS sequences from the developer UNITE database (QIIME-compatible release).</p> </li> <li> <p>Use the q2-itsxpress plugin, which permits extraction of ITS domains from input data (sequences). Then, extracted sequences can be compared to the standard UNITE database.</p> </li> </ul> <p>Available tutorials for diversity and compositional analysis can be followed at the QIIME docs website (https://docs.qiime2.org/2022.11/) and a detailed pipeline can be found at (Estaki et al., 2020).</p>"},{"location":"Section_10_4/#10424-removing-biological-contamination","title":"10.4.2.4. Removing biological contamination","text":"<p>Despite best efforts, biological contamination of samples with microbes not belonging to the sample is still possible. Excluding suspected contaminants from downstream analyses is encouraged. For example, excluding suspected contaminants from downstream analyses is appropriate if, according to the sequencing of blank controls, contamination by laboratory reagents or the laboratory environment is suspected. If necessary, there are multiple softwares for removal of contaminant sequences, such as the R package decontam (Davis et al., 2018; Salter et al., 2014).</p>"},{"location":"Section_10_5/","title":"10. Microbiome analysis","text":""},{"location":"Section_10_5/#105-applications-and-limitations","title":"10.5. Applications and limitations","text":"<p>In a honey bee colony, each individual plays a specific yet adaptive role, and changes in the microbiome composition (dysbiosis) of even just some individuals may influence the colony's success or failure. Thus, the microbiome should be evaluated more often in bee health studies, as it is known to be affected by pesticides (Kakumanu et al., 2016), pathogens (Paris et al., 2020), food restrictions (Castelli et al., 2020), and even change in environmental cues (Hammer et al., 2021). The majority of the studies have focused efforts on characterizing worker bee gut microbiota, but it is important to incorporate investigations of other castes, tissues, developmental stages, and colony environments.</p> <p>The honey bee colony is ultimately a superorganism (Moritz &amp; Southwick, 2012), and the microbes harbored in different parts of the colony can also play a direct role in colony fitness or may serve as microbe reservoirs. The microbial community does not exist in isolation, and we encourage readers to consider not only the simple characterization of the communities, but their interactions with social evolution (Liberti et al., 2022; Vernier et al., 2020), development (Hammer &amp; Moran, 2019), diapause (Mushegian &amp; Tougeron, 2019; Santos et al., 2019), and the brain-microbiome axis (Zhang et al., 2022; Zhang et al., 2022).</p> <p>Amplicon sequencing approaches do, of course, have limitations, one of which is that analyzing hyper-variable regions is not equal sensitive for all bacteria (one hypervariable region is insufficient to differentiate all bacterial species). Most OTUs or ASVs will thus not have the sequence resolution to taxonomically identify the microbes to genus or species, much less strain (Callahan et al., 2017). Even so, this approach is still useful for microbial community characterization and for observing major changes in it.</p> <p>Different strains of microbes may fill different functional niches, and investigating patterns of strain variation is a growing area of interest. Primers for non-marker genes have already been developed to detect diversity at the bacterial strain level, including the genes minD(Powell et al., 2016), guaA, and gluS (Bobay et al., 2020) for Snodgrassella alvi strain composition, and pflA and rimM for Gilliamella spp. strain composition. This method was termed metagenomic amplicon strain typing (MAST). Although an interesting approach focused on specific members of the microbiome, there are no similar published studies for fungi. Otherwise, to describe the strain-level diversity of the entire microbial community, a shot-gun metagenomics approach would be more appropriate (Ellegaard &amp; Engel, 2019), but it is more expensive and time-consuming for analysis. However, those who utilize this method are rewarded with not only strain-level diversity, but also host genotypes and gene sequences of the microbes, potentially allowing for functional insights.</p> <p>Conversely, using the amplicon sequencing approach, there is limited knowledge to gain regarding the roles of microbiome members, since there is no information regarding their gene repertoire and metabolic activity. Of course, functions can be predicted based on general knowledge of the described species or sequenced genome using software as PICRUSt (Langille et al., 2013), Tax4Fun2 (Wemheuer et al., 2020), and FUNGuild (Nguyen et al., 2016), but strains may differ with regards to their functional abilities; therefore, these predictions are tenuous at best. One way to alleviate this concern would be to combine culture-dependent approaches to conduct in vitro and in vivo experiments - confirming a microbes' role and interactions. This kind of functional validation of predictions remains one of the field\u2019s biggest challenges.</p> <p>The field of honey bee microbiome analyses is still underway. In particular, the non-bacterial communities within honey bee guts are not well characterized, with a lack of consensus regarding fungal communities (Hroncova et al., 2015; Khan et al., 2020) and ubiquitous viral communities (Bonilla-Rosso et al., 2020; Kadle\u010dkov\u00e1 et al., 2022). And, despite the characterization of the bacterial profiles of honey bee guts, much is still unknown regarding its impact in honey bee colony fitness, such as how microbial communities influence host physiology or how spatial specialization of microbes within colonies occurs (Copeland et al., 2022; Powell et al., 2021; Zheng et al., 2017).</p>"},{"location":"Section_11_1/","title":"11. Data management and open access sharing","text":"<p>Past the excitement from the access to large amounts of sequencing data for numerous honey bee species, populations, individuals, and tissues, researchers may encounter challenges in determining how datasets were obtained. This problem is not inherent to the honey bee community and inconsistencies appear often in many organisms (Gon\u00e7alves &amp; Musen, 2019). In the context of honey bee omics research, we have identified two main challenges that hinder comparative studies: 1) the lack of details and access to bioinformatics scripts used and 2) the heterogeneity of metadata associated with open access data. These problems are avoidable with improved practices and standards. Addressing these challenges through standardization and transparency will promote reproducibility and facilitate data comparability and integration.</p> <p>There are several global and honey bee-specific databases that exist and provide platforms for data submission and search. These databases serve as valuable resources for researchers to access and contribute to the wealth of information available on honey bees. Across the tree of life, the core databases NCBI (National Center for Biotechnology Information), DDBJ (DNA Data Bank of Japan), and ENA (European Nucleotide Archive) are widely recognized as major repositories for biological data. Such databases are now fed by ambitious initiatives that aim to sequence and analyze the genomes of a vast number of species, including those beyond model organisms such as the Earth Biogenome Project, Darwin Tree of life, and i5K. These initiatives contribute to the growth of genetic data resources and can indirectly benefit honey bee research.</p> <p>In addition to the global databases mentioned earlier, several functional genetic databases play important roles in specific model organisms and functional genomics research. While they may not directly contain honey bee datasets, they can still be utilized as proxies for comparative analysis. Some relevant databases include: Flybase, Beetlebase, BUSCO/OrthoDB (Benchmarking Universal Single-Copy Orthologs) and Gene Ontology (GO).</p> <p>Apis-specific databases also exist and have been developed to specifically focus on honey bee microbiome research and provide curated sets of honey bee microbes and associated tools with Bee-exact and Holobee. Another example is the beenome100 project database which serves as a valuable genomic resource and establishes a comprehensive phylogenomic framework for Apis genus by aiming at generating reference genomes for 100 U.S. bee pollinators species.</p>"},{"location":"Section_11_1/#111-metadata-standardization","title":"11.1. Metadata standardization","text":"<p>While peer-reviewed journals require that any genetic data are shared in open-access, no rigorous quality control of the metadata submitted is ensured. Regardless of the reader's expertise level in submitting genomic data, we recommend following the best practices listed by the journal Scientific Data (\u201cPromoting best practice in nucleotide sequence data sharing,\u201d 2020) in submitting metadata to NCBI, DDBJ, ENA, and other databases. This section does not intend to replace the multiple and comprehensive resources available guiding data and metadata submission, and we urge to carefully adhering to these standards (i.e., for NCBI BioProject).</p>"},{"location":"Section_11_1/#1111-common-problems-with-apis-related-bioprojects","title":"11.1.1. Common problems with Apis-related BioProjects","text":"<p>Often, a single study can be associated with a BioProject (i.e., BioProject 1 = X individuals SNPs data, BioProject 2 = Y Transcriptomes) or eventually an umbrella project gathering several related projects (i.e., BioProject UMBRELLA [BioProject 3 = Proteomics data for 100 individuals + and BioProject 2 = Gene expression data for 50 individuals]). One common mistake is the absence of a clear, unique title and description.</p> <p>Among the 517 BioProjects strictly related to Apis honey bee available on NCBI, we found that most did not have associated publications or proper descriptions (Search: \"Apis mellifera\"[Organism] and manual sorting). This can make it difficult for the reader to know 1) how the data were generated and 2) which institute or team could be contacted to reach out on the origin of the data. Thus, we suggest that researchers follow the subsequent best practices for BioProject submission:11.1.2. Common problems with Apis-related BioSamples</p> <p>Best practices for BioProjects:</p> <ul> <li> <p>Title should be as explicit and descriptive as intended for publication.</p> </li> <li> <p>Description should include details regarding 1) the project aim, 2) a general overview of the Apis species, subspecies, populations, individuals, and sex targeted, 3) the material origin (e.g., tissue specific vs whole body, single individual vs pool), and 4) which sequencing platform and library approach were used.</p> </li> <li> <p>In case the data were released prior to publication, we recommend associating a link to the lab in charge with the institute/unit/team indicated as submitter.</p> </li> <li> <p>Indicate a data usage statement in case of early release to inform users about possible embargo.</p> </li> <li> <p>Contact database curator to give the DOI of the associated published report or paper.</p> </li> </ul>"},{"location":"Section_11_1/#1111-common-problems-with-apis-related-biosamples","title":"11.1.1. Common problems with Apis-related BioSamples","text":"<p>From our survey, most of the inconsistency and variability observed in metadata submitted for Apis honey bee projects was observed in BioSample (which contains important metadata regarding the source of the sample). A BioSample is essential for cross-scale comparative studies and data mining. Several studies in A. mellifera population genetics (see Section 4.6) have generated new genome-wide data but also compared with former studies from a different source in their analysis (Cridland et al., 2017; Dogantzis et al., 2021; P. Shi et al., 2020; Tihelka et al., 2020). Such integrative studies are predicted to increase in the future as they give a broader and global perspective on honey bee evolution and biology.</p> <p>We found that 16,855 BioSamples related to honey bees and Apis-associated environmental organisms (except Acari mites and hive insect pests) were registered in public databases. Among them only 60% had attribute fields about the specimen\u2019s sex, and 53% had geographic location details. Aside from incomplete data, in our survey we encountered problems related to variable orthograph even with fields as straight-forward as \u2018sex\u2019 attribute (Table 1). While the absence of such data can be understandable and common with historical or third-party sampling, we urge future submissions to include at least the following details for Apis standard research.</p> <p>Table 1. Survey results of BioSample attributes.</p> Orthographs for \u2018sex\u2019 attribute Number of SRA female 3629 femLE [sic] 1 male 1966 MISSING 79 None 6 not applicable 6 not collected 16 not determined 6 pooled male and female 418 sterile female 12 worker 22 (no entry) 7629 <p>Best practices for BioSamples:</p> <p>For Apis specimen data, use the invertebrate submission package (https://www.ncbi.nlm.nih.gov/biosample/docs/packages/Invertebrate.1.0/) which requires\u00a0the collection date, the geographical origin, and the tissue used for sequencing</p> <p>as mandatory attributes.</p> <p>For Apis environmental and metagenomic-transcriptomic data, use the MIMS: metagenome/environmental, host-associated; version 5.0 package (https://www.ncbi.nlm.nih.gov/biosample/docs/packages/MIMS.me.host-associated.5.0/).</p> <p>In the specific attributes field, we recommend researchers to include the following additional information, although it is not mandatory according to the NCBI submission system.</p> Attribute Recommendations Breed / Subspecies - Create an additional column for \"Subspecies\".  - Avoid using \"isolate\" for this purpose; instead, use it for the sample name.  - When known, include the subspecies or strain level (e.g., Apis mellifera unicolor, Apis cerana japonica, Apis mellifera \u2018Buckfast\u2019). biomaterial_provider / collected_by - Acknowledge the person responsible for sampling using Name + Affiliation. dev_stage - Indicate if the sample relates to an egg, larva, pupa, or adult bee. lat_lon / geo_loc_name - Provide details on the sampling location using geo-coordinates in decimal format for spatial studies or guiding future sampling.  - If exact coordinates are unavailable, use approximate ones (e.g., centroid of a city or locality). treatment - Include the various treatment conditions in the metadata for transcriptomics and epigenomics studies. host / tissue - For metagenomics, metatranscriptomics, and microbiomics, include the host species and the origin of the sampled tissue. <p>Ideally, a supplemental data table should be provided with the sample name, library ID, and all the aforementioned attributes. This would allow future users to cross-check the information with the analysis results, which may not be explicitly stated in the raw data deposited to the database. Examples of such information include population structure assignment, patriline, omic profile, and other relevant details.</p> <p>The retroactive correction and update of both BioProject and BioSamples content is often easy and requires the original submitter to contact a curator from the database of initial submission For instance, if you submit your Sequence Read Archive (SRA) data and metadata to DDBJ, you can provide a list of all corrections for each accession to a DDBJ curator. These changes will then be automatically transferred to other databases, such as NCBI, within a short period of time. Since these databases communicate on a daily basis, the changes can be implemented swiftly.</p>"},{"location":"Section_11_2/","title":"11. Data management and open access sharing","text":""},{"location":"Section_11_2/#112-sharing-pipelines-and-scripts","title":"11.2. Sharing pipelines and scripts","text":"<p>The burst and diversification in the development of software, R packages, pipeline and servers to analyze omics data can quickly lead users to go down a bioinformatic rabbit hole to make the \u201cbest\u201d choice. Additionally, the frequent emergence of comparative studies promoting new tools adds to the difficulty of decision-making. In this chapter, we have proposed up-to-date and efficient standard pipelines to guide users in their methodological workflows. However, we acknowledge that these pipelines may require future revisions, similar to how the present chapter updates information from Evans et al. (2013). We aim to provide a valuable resource that evolves alongside advancements in the field.</p> <p>As progress is made and new analytical workflows are adopted, we invite the honey bee research community to contribute to the data processing standardization by sharing their bioinformatics methods and custom scripts. While sharing sequencing data is mandatory in peer-reviewed journals, the same level of detail is often not required for downstream analysis. Minimal descriptions are often given in the \u201cMaterial and Methods\u201d sections regarding parameters for each software or script function. Depending on the journal's requirements, it may be necessary to share analysis output data (e.g., VCF files, LFMM, FASTA) and scripts through external repositories associated with a DOI.</p> <p>Noteworthy initiatives, such as the SeqApiPop population genomics study, have inspired changes by publishing detailed codes on collaborative platforms like GitHub (github.com/avignal5/SeqApiPop) alongside their results (Wragg et al., 2021). Similar initiatives using interactive R and shell markdowns have been carried out for honey bee microbiome (Kowallik &amp; Mikheyev, 2021; Liberti et al., 2022) and transcriptomics studies (Holman et al., 2019; Warner et al., 2019). In addition to enabling reproducibility and standardization, we advocate that open access to the code scripts (default and personalized) serves as a valuable teaching tool, particularly tailored to honey bees. To facilitate the growth of such resources, we recommend the following best practices:</p> <p>Best practices for sharing pipelines and scripts:</p> <ul> <li> <p>Whole genome sequencing and population genomics studies should strive to make their data freely available through international open-access repository such as Dryad or Zenodo.</p> <p>Content: VCF file, Demographic analysis, FASTA alignments</p> </li> <li> <p>Custom scripts (bash, Python, awk) and pipelines created with Workflow Management Systems (such as Snakemake, Nextflow, Galaxy) should be made freely accessible to a cloud-based platform with version control, such as GitHub (or alternatives: GitLab, Bitbucket, SourceForge, etc.) or Wiki.</p> <p>Content: Markdown, codes, notes, input files (small sizes)</p> </li> <li> <p>State clearly in publication the source and link to data and code availabilities</p> </li> </ul> <p>When selecting a community-curated pipeline, users should consider the following: 1) How often has this pipeline been cited and used? 2) Does the closed/open issues ratio or forum activity indicate strong developer technical support? 3) How frequently is the pipeline updated (consider the dates and number of releases)? 4) Is there an active user community providing support? Additionally, with the rise of package manager such as Conda or containerization technologies like Docker and Singularity, it\u2019s important to consider if the pipeline is available in a containerized format, as this can significantly improve the reproducibility and ease of its usage across different computing environments.</p>"},{"location":"Section_12/","title":"12. The future of Apis omics: Biological integration","text":"<p>In the coming decades, we anticipate the emergence of new methods driven by technological advances that will further reduce costs and expand omics applications beyond model species. At the moment, cutting-edge approaches, such as single-cell sequencing and atlas generation (Luecken &amp; Theis, 2019; Misra et al., 2022), spatialomics (Moffitt et al., 2022), and the use of machine learning for various omics analyses \u00a0(Arjmand et al., 2022; Li et al., 2022) have been developed and applied for clinical and forensic purposes. These advancements hold great promise for honey bee research, offering unprecedented insights into the evolution of phenotypic plasticity, behavioral profiling within a superorganism, and the origins of eusociality.</p> <p>However, immediate progress in our understanding of Apis honey bee biology, diversity, and evolution can be achieved by the layering of multi-omics data and interpretation (Toth &amp; Zayed, 2021). Genomics, epigenomics, and transcriptomics have seen remarkable growth in honey bee research and provided valuable insights. By integrating multi-omics data from the same honey bee sample (single cell, tissue, individual or colony), we can uncover the mechanistic and immediate causes behind behavioral changes, such as labor division, as well as responses to various stress factors like pathogen infections or chemical exposure. The combination of multiple omics approaches has been proposed as a toolkit to better characterize and improve honey bee health (Grozinger &amp; Zayed, 2020). Initiatives like the Canadian BeeCSI project are actively working on integrating multiple omics approaches to better understand and promote honey bee health.</p> <p>The integration of behavioral assays, chemical profiling and metagenomics has shed light on the significance of honey bee host-microbiome interactions in nestmate recognition (Vernier et al., 2020). Leveraging functional genomics and transcriptomics, based on knowledge gained from studying the honey bee microbiome could help engineer innovative pathogen control methods (Leonard et al., 2020). As a last example, new insights in A. mellifera social immunity via the discovery of transmissible RNA in shared royal jelly resource, was made possible by the combination of proteomics, transcriptomics and functional genomics (Maori et al., 2019; Maori et al., 2019). Encouraged by these achievements, further multi-omics surveys are anticipated to expand our knowledge to other Apis species.</p>"},{"location":"Section_2/","title":"2. Sample management","text":"<p>Sample management for honey bee samples is essentially the same as described for A. mellifera in BEEBOOK volume II (Evans et al., 2013). In cases where samples may need to be collected and handled differently before processing (e.g., museum samples), we indicate deviations at the beginning of each protocol.</p>"},{"location":"Section_3_1/","title":"3. Genome sequencing","text":""},{"location":"Section_3_1/#31-introduction","title":"3.1. Introduction","text":"<p>As for other species, the sequencing of Apis DNA has many applications that can be divided into three categories: de novo sequencing, resequencing, and transcript sequencing. While the last category technically relies on sequencing cDNA reads, its use is intended to inform the structure and expression of genes in honey bee genome, a topic that is covered in Section 6.</p> <p>De novo sequencing of Apis species started in 2006 but is punctually used to generate improved reference genomes and to represent new subspecies (see Figure 2) (Toth &amp; Zayed, 2021). To achieve successful de novo sequencing, the utilization of the most advanced technology available is necessary.The longest possible reads should be produced, possibly from one single sample, and these will be assembled into contigs based on partial sequence overlap (Figure 3A). In turn, these contigs will be assembled using other mapping methods such as optical maps or Hi-C, to reconstruct larger fragments (scaffolds), aiming at a chromosome-level assembly.</p> <p>Further analyses, such as population genomics or RNA-seq, may then use the reference genome produced by de novo sequencing. This is done by aligning reads produced with a high-throughput method, such as Illumina short-read parallel sequencing, to the reference. Using a single reference genome for a community of users allows the comparison of results by having a unique coordinate system. For instance, population genomics studies on whole genomes are conducted by a re-sequencing approach in which the reads from one sample are compared to a reference by alignment (Figure 3B). Re-sequencing with short reads will detect small differences such as single nucleotide polymorphisms (SNPs) or insertion-deletion mutations (indels), whereas a long-read approach will highlight larger structural variants. Alignment of sequence reads to a reference is also used for a variety of other analyses, such as the detection of DNA methylation (bisulfite sequencing) (Lyko et al., 2010), identifying regulatory regions linked to histone modifications (ChIP-seq) (Nakato &amp; Sakata, 2021) the analysis of the 3D conformation of chromosomes in the interphase nucleus (Hi-C) (Hoencamp et al., 2021; van Berkum et al., 2010), and many other applications.</p> <p>Different sequencing techniques exist, and the choice amongst the three main categories (Sanger sequencing, short read parallel sequencing, and long-read sequencing) will depend on the desired goal. Due to the broad applications of sequencing and the constant progress made by technology, we will only cover the most common ones as quick guides toward informed choices here. For reviews on the three main sequencing technologies, see (Heather &amp; Chain, 2016; Shendure et al., 2017).</p> <p></p>"},{"location":"Section_3_1/#figure-3-genome-sequencing-a-sequence-reads-are-assembled-into-contigs-by-partial-sequence-overlap-b-alignment-of-reads-to-a-reference-genome-these-can-be-whole-genome-sequencing-rna-seq-or-other-ideally-for-a-given-apis-species-only-one-reference-genome-should-be-used-by-the-community-allowing-for-a-unique-and-common-coordinate-system-for-comparing-results-sequencing-genomes-usually-refers-to-this-method-of-looking-for-differences-between-the-samples-under-study-and-the-reference-the-consequence-is-that-all-results-are-reference-biased-for-instance-a-gene-absent-in-the-reference-genome-cannot-be-analyzed-in-the-samples-even-when-reads-align-to-it","title":"Figure 3. Genome sequencing. A) Sequence reads are assembled into contigs by partial sequence overlap. B) Alignment of reads to a reference genome. These can be whole-genome sequencing, RNA-seq or other. Ideally, for a given Apis species, only one reference genome should be used by the community, allowing for a unique and common coordinate system for comparing results. Sequencing genomes usually refers to this method of looking for differences between the samples under study and the reference. The consequence is that all results are reference-biased. For instance, a gene absent in the reference genome cannot be analyzed in the samples, even when reads align to it.","text":""},{"location":"Section_3_2/","title":"3. Genome sequencing","text":""},{"location":"Section_3_2/#32-genome-sequencing-technologies","title":"3.2. Genome sequencing technologies","text":""},{"location":"Section_3_2/#321-sanger-sequencing","title":"3.2.1. Sanger sequencing","text":"<p>Until the mid-2000s, DNA sequencing primarily relied on the Sanger technique, which was invented in the 1970s and partially automated in the late 1980s with the introduction of sequencing machines. These first-generation sequencers represented great progress at the time and were based on the size fractionation of DNA fragments by electrophoresis and laser detection of the four possible bases by using four fluorochromes. However, for each 500 to 1000 bp read produced, separate sequencing reactions, based on the copy of a template DNA, had to be performed. This technique has become obsolete in favor of next-generation genome sequencing, but is still used for sequencing polymerase chain reaction (PCR) amplicons when targeting specific regions of one honey bee genome.</p>"},{"location":"Section_3_2/#322-next-generation-sequencing","title":"3.2.2. Next generation sequencing","text":"<p>The next major genome sequencing breakthrough was the advent of next-generation sequencing (NGS) techniques in the mid-2000s. Although these were proposed at first by three companies (Roche, Applied Biosystems, and Solexa/Illumina), today, the dominant platform is Illumina. The breakthrough came from the fact that the sequencing reactions were no longer performed individually, but simultaneously on a surface, or flow cell. This allows millions of DNA fragments to be amplified in parallel, with fluorescently labeled nucleotides added and detected sequentially. Parallel sequencing has a very high throughput and can currently produce up to billions of reads per run. However, these reads are short (150-250 bp, depending on the technology used), which can be a major limitation, especially for de novo sequencing. This inconvenience is partially overcome by the fact that two 150 bp reads (read pairs) can be produced from both ends of each DNA fragment. Before the advent of long-read sequencing, read pairs distant up to 10 kb could be produced (mate-pairs) to help in sequence assembly and scaffolding. Parallel sequencing is used, for instance, in population genomics or for generating a very high density of unbiased markers in a genome-wide association study.</p>"},{"location":"Section_3_2/#323-long-read-sequencing","title":"3.2.3. Long-read sequencing","text":"<p>Long-read sequencing, pioneered by Pacific Biosciences (PacBio) and Oxford Nanopore, is the newest sequencing approach. These innovative technologies can produce reads longer than 10 kb, but until recently, at the cost of a high sequence error rate. As of the time of writing, both parallel and long-read sequencing are the technologies of choice and are used either independently or in combination. Long-read sequencing is often used for producing new genome assemblies and for the detection of structural variants (SVs). For a detailed discussion on using long-read sequencing for transcriptomics, please refer to [Section 6.2.2].</p> <p>Today, sequencing is done via dedicated core facilities or private companies. Users submit their samples or DNA, and in return, are supplied with the sequencing files along with quality assessment of the sequenced data. Most of the work, then, consists of analyzing the data to extract biological meaning. However, depending on the biological question and perhaps also on budget considerations, the sequencing strategy (e.g., read depth, platform) will have to be defined in advance, and at least some basic knowledge of the advantages and limits of the current technologies are required. Sequencing platforms often provide tools to guide the new user (e.g., coverage calculator, sample pooling normalization calculator) but we do recommend consulting sequencing specialists as a very first step.</p>"},{"location":"Section_3_3/","title":"3. Genome sequencing","text":""},{"location":"Section_3_3/#33-the-reference-genome","title":"3.3. The reference genome","text":"<p>Genomic analyses, such as genome-wide association studies (GWAS), population genomics, and transcriptomics are virtually impossible to perform in the absence of a reference genome for the species studied. For instance, SNPs are detected by aligning sequence reads from samples to the reference and looking for the differences, transcriptome analyses align sequence reads from RNA samples to the reference genome, and transcript levels are determined by counting reads mapped onto the different annotated genes. Moreover, the accuracy of such analyses depends highly on the quality of the reference genome. A typical example in honey bees is the gene number estimation that went from a first Official Gene Set (OGSv1.0) of 10,157 protein-coding genes in version 2 of the assembly (Consortium &amp; Others, 2006) to a much larger 15,314 protein-coding OGSv3.2 gene set detected in Amel_4.5 (Elsik et al., 2014). Among many reasons for this difference are the progress in DNA sequencing techniques and assembly algorithms. However, Amel_4.5 remained a very fragmented assembly. More recently, the utilization of long-read sequencing technologies has led to the development of an updated and highly contiguous genome assembly (HAv3.1) which has corrected many errors in chromosome segment ordering (Wallberg et al., 2019). Such a gapless assembly is also essential for accurate gene annotation (Denton et al., 2014). Using a single reference genome for all subsequent analyses will allow having a consistent coordinate system, which is indispensable for comparing results.</p>"},{"location":"Section_3_3/#331-assembling-the-reference-genome","title":"3.3.1. Assembling the reference genome","text":"<p>The reference genome should be as perfect as possible, and maximum effort must be made to use state-of-the-art technologies and bioinformatics strategies. As of the time of writing, the current honey bee genome build, HAv3.1, was produced using PacBio long-read sequencing, and the reads were assembled into contigs with FALCON (version 0.5.0). The contigs were then merged using additional information, mainly genetic maps, BioNano optical maps, and Hi-C chromatin interaction data (Figure 4A) (Wallberg et al., 2019).</p> <p></p>"},{"location":"Section_3_3/#figure-4-genome-assembly-a-contigs-are-first-built-by-sequence-overlap-and-connected-together-into-scaffolds-with-linked-reads-usually-using-hic-andor-optical-maps-b-de-novo-assembly-decisions-can-be-influenced-by-polymorphism-present-in-the-sample-used-as-reference-when-reconstructing-a-haploid-consensus-sequence-from-a-diploid-individual-a-certain-proportion-of-mismatches-must-be-allowed-to-take-polymorphisms-into-account-however-the-presence-of-paralogous-sequences-in-the-genome-will-complicate-the-decision-process-sequencing-a-haploid-drone-solves-this-problem","title":"Figure 4. Genome assembly. A) Contigs are first built by sequence overlap and connected together into scaffolds with linked reads, usually using HiC and/or optical maps. B) De novo assembly decisions can be influenced by polymorphism present in the sample used as reference. When reconstructing a haploid consensus sequence from a diploid individual, a certain proportion of mismatches must be allowed, to take polymorphisms into account. However, the presence of paralogous sequences in the genome will complicate the decision process. Sequencing a haploid drone solves this problem.","text":""},{"location":"Section_3_3/#3311-hi-c-chromosome-conformation-capture","title":"3.3.1.1. Hi-C chromosome conformation capture","text":"<p>The Hi-C chromosome conformation capture method was developed for analyzing the 3D organization of the genome, including possible interactions between distant loci, either on the same chromosome or different chromosomes (van Berkum et al., 2010). However, most interactions involve relatively close loci, following the compaction of the DNA in the chromatin and topologically associated domains (TADs). Therefore, Hi-C is also used to detect read pairs that will map at distances in the order of 10 to 100 kb to help assemble contigs together in whole genome de novo sequencing. Hi-C method is particularly valuable in assembling regions of the genome that are challenging using conventional sequencing methods alone (e.g., due to inversions, large chromosomes, gaps and repetitive elements). To reveal the chromatin looping, Hi-C was utilized to compare the 3D genome structures of queen and worker larvae (Yong Zhang, He, et al., 2023). Hi-C and PacBio technologies are also used to generate the chromosome-scale assembly of the Apis cerana and A. mellifera genomes (Cao et al., 2021; Wallberg et al., 2019; Wang et al., 2020).</p>"},{"location":"Section_3_3/#3312-dna-source-selection","title":"3.3.1.2. DNA source selection","text":"<p>For technical reasons at first, and now for continuity reasons, all reference genome assemblies for the honey bee were done using inbred queens or drones from the DH4 strain; Bee Weaver Apiaries, Inc. (Consortium &amp; Others, 2006; Elsik et al., 2014; Wallberg et al., 2019). Indeed, to mitigate assembly problems related to repeated DNA and gene families, polymorphisms in the individual selected for sequencing must be as low as possible. In diploid species, this is addressed by selecting a highly inbred sample. Honey bees, however, have a haplodiploid sex-determination system, so the problem with intra-individual polymorphism is eliminated by sequencing a single haploid male (drone) (Figure 4B).</p>"},{"location":"Section_3_3/#332-annotating-the-reference-genome","title":"3.3.2. Annotating the reference genome","text":"<p>Much of the information used to annotate genes within reference genomes is derived from RNA-Seq gene expression studies, most of which are conducted using short-read sequencing. The annotation for new RefSeq genomes can be requested out at no cost for the user through the NCBI team, using the Eukaryotic annotation pipeline Gnomon (Thibaud-Nissen et al., 2013). However, short reads do not capture all the information, especially in large, complex genomes which may have highly repetitive sequences. Some genes may be falsely merged or split, exons can be missing, and overall, the information on alternative splicing is missing. Ideally, annotation-driven work should now be revised and performed with long reads such as Iso-seq (PacBio). Many tools computational tools exist for user to perform or curate their own annotation (Ejigu &amp; Jung, 2020). New annotation pipelines user-friendly like BRAKER3 (Gabriel et al., 2024) are now using long read RNA-Seq and protein data to improve gene prediction.</p>"},{"location":"Section_3_3/#333-high-molecular-weight-dna-extraction","title":"3.3.3. High molecular weight DNA extraction","text":"<p>HAv3.1, being based on the DH4 honey bee strain, cannot represent the full diversity existing in all honey bee subspecies. Therefore, de novo assemblies for other representative individuals may need to be produced. Regardless of the DNA sequencing and mapping techniques used, a critical step is to ensure the genomic DNA extracted is of high molecular weight (HMW), typically 10 kb or higher. This is particularly important for long-read sequencing since reads will be long only if the DNA molecular weight is sufficiently high. Achieving this requires careful sample handling and DNA extraction, which can be challenging at first. Most problems reside at the sampling stage and first stages of DNA extraction.</p> <p>To prevent quality issues related to contaminants such as cuticle and optical pigments, samples should be collected from larvae or white-eyed pupal stage. Co-purification of pigments with HMW DNA can lead to errors in spectrophotometric measurements and interfere with downstream DNA binding, as observed in other organisms (Adema, 2021; Fauchery et al., 2023). To preserve tissue integrity, these should either be fresh or flash-frozen in liquid nitrogen. To preserve high molecular weight DNA, the frozen sample can either be pulverized and the powder used for standard DNA extraction. Alternatively, a freshly sampled or thawed tissue can be gently ground in DNA extraction buffer. While there are many options for mechanical disruption, using a pestle is ideal to avoid fragmenting the DNA. DNA extraction can then be performed using standard procedures, for instance, the QIAGEN Genomic-tips 100G (Cat No/ID: 10243). The actual sequencing and genome assembly is a very specialized work, using ever-changing sequencing technology and bioinformatics pipelines (Childers et al., 2021; LaFlamme, 2021; Lawniczak et al., 2022; Rice &amp; Green, 2019).</p>"},{"location":"Section_3_4/","title":"3. Genome sequencing","text":""},{"location":"Section_3_4/#34-small-and-large-variant-detection","title":"3.4. Small and large variant detection","text":"<p>The technology most often used for small and large variant detection (SNPs and indels, respectively) is Illumina, due to its high throughput, cost-effectiveness, and low error rate. When short reads are produced for each individual and aligned on the reference sequence, sequence differences between the reads and the reference can be observed, indicating the presence of variants. The bioinformatics analyses concerning SNP detection are described further in Section 4.3. Small variant detection can also be performed by pool sequencing, in which DNA from multiple samples are mixed prior to indexing and sequencing. Pool sequencing helps in reducing library preparation time and sequencing cost for estimating allele frequencies in populations.</p> <p>To detect large variants, such as insertions or deletions of several hundred or thousands of base pairs (indels), either two de novo assembled genomes will have to be compared, as described further in Section 4.4 using the software LAST (Frith &amp; Kawaguchi, 2015), or long reads produced by PacBio or Nanopore sequencing are aligned onto the reference for breakpoint detection. A common alternative to using LAST is minimap (Heng Li, 2018) or LASTZ (Harris, 2007).</p>"},{"location":"Section_3_4/#341-rad-seq","title":"3.4.1. RAD-seq","text":"<p>Restriction site-associated DNA sequencing (RAD-seq) is a technology by which a reduced representation of the genome is selected using restriction enzymes and PCR. Typically, 10% of the genome is selected for analyses to reduce the volume of sequencing reads required for SNP detection. However, given the small size of the honey bee genome, the number of reads obtained in an Illumina sequencing run is not the limiting factor. From our experience, using RAD-seq in honey bees now will increase the cost of library preparation and, by extension, the overall cost of sequencing while producing data for only a fraction of the genome. Moreover, bioinformatics analyses are slightly more complex than whole genome sequencing, and polymorphisms within the restriction sites used can cause allelic drop-out.</p>"},{"location":"Section_3_5/","title":"3. Genome sequencing","text":""},{"location":"Section_3_5/#35-sequencing-museum-specimens","title":"3.5. Sequencing museum specimens","text":"<p>Ancient and historic specimens offer an excellent and powerful opportunity to study macro- or micro-evolutionary changes (Short et al., 2018). Museum collections in particular, are ideal, as they can provide a temporal series of honey bee samples from different areas of their natural range. Analyzing old specimens enables us to gain insight into past genetic diversity, selection, domestication, speciation, migration, and phylogenomics (Card et al., 2021; Raxworthy &amp; Smith, 2021). In fact, to study these processes directly, comparing historic and contemporary allele frequencies is the most direct and powerful method, in contrast to model-based approaches.</p> <p>The main caveat of old samples is the challenge in obtaining high-quality DNA for molecular analyses, but improvements in DNA extraction protocols and sequencing technology are overcoming these difficulties (Orlando et al., 2021). Until recently, most of the studies using museum collections were based on PCR-amplification of target genes or mitochondrial DNA. However, due to DNA degradation, fragments may be shorter than the target region and cannot be amplified. In contrast, high-throughput sequencing enables us to sequence even very short DNA fragments. In the field of human genetics, protocols for high-throughput sequencing applied to historic and ancient DNA from archeological sites are relatively well established, but fewer efforts have been made in the application to historical museum collections from animals (Card et al., 2021; Grewe et al., 2021; Mikheyev et al., 2015, 2017) and plants (Kistler et al., 2020). For honey bees, sequencing of historic collections has already been successfully performed to study signatures of selection, changes in ancestry composition, and genetic diversity pre- and post-parasite arrival (Cridland et al., 2018; Mikheyev et al., 2015; Parejo et al., 2020) (Figure 5). The approaches employed are also applicable to other Apis species.</p> <p></p>"},{"location":"Section_3_5/#figure-5-left-single-dried-pinned-honey-bee-worker-museum-specimens-right-collection-box-with-multiple-museum-specimens-to-avoid-cross-contamination-with-other-samples-especially-with-present-day-specimens-dedicated-rooms-special-personal-protective-equipment-and-a-cleaning-workflow-must-be-adopted-credit-m-parejo","title":"Figure 5. Left: Single dried, pinned honey bee worker museum specimens, Right: collection box with multiple museum specimens. To avoid cross-contamination with other samples, especially with present-day specimens, dedicated rooms, special personal protective equipment, and a cleaning workflow must be adopted. (Credit: M. Parejo)","text":""},{"location":"Section_3_5/#351-considerations","title":"3.5.1. Considerations","text":"<p>The following recommendations are not limited to ancient or museum-grade specimens. We suggest adhering to similar guidelines for handling Apis samples targeted for genomic material extraction to reduce contamination.</p> <ul> <li> <p>Reducing contamination: It is imperative to take the highest precautions and implement stringent measures to avoid any cross-contamination between samples, especially between contemporary and historical samples. We recommend strict separate handling of old and new samples, working under a hood or PCR workstation-type cleaned with UV light. The usage of filter tips for all steps should be seen as mandatory. Reliable DNA extraction from museum samples requires a clean and separated space where no previous bee material have been introduced. It is almost certain that such details will be demanded, and quality checked by reviewers of Apis museum genomics studies.</p> </li> <li> <p>Method choice: The DNA extraction protocol described below is based on phenol-chloroform separation, as it typically yields the highest amount of DNA. This is crucial because only limited tissues may be available, such as legs. Whenever enough tissue is available and samples are less degraded, commercial DNA extraction kits (e.g. DNeasy Blood and Tissue kit from QIAGEN on honey bees from 1910-1999) also produce adequate DNA quantity and quality (Cridland et al., 2018).</p> </li> <li> <p>Hazardous agent: Please note that phenol and chloroform are hazardous agents. It is of utmost importance that you work cleanly and safely. In addition to following basic laboratory safety precautions, perform all procedures in a chemical fume hood, wash hands thoroughly immediately after working with these chemicals, and use sealed safety tubes (e.g., Eppendorf Safe-Lock tube) when centrifuging.</p> </li> <li> <p>Material choice: The bulk tissue material used influences the success of DNA extraction and sequencing in chitinous organisms such as Apis honey bees. In some cases, there is no choice, as only non-destructive sampling is allowed by the curator for valuable museum specimens. While thorax sampling is typical for modern samples, thoraxes may contain a larger fraction of non-target DNA, such as contaminating fungi or bacteria (albeit far less than found in bee abdomens), and thus not represent the most suitable sample type. In contrast, hind legs have been shown to contain sufficient honey bee DNA with limited contamination (Parejo et al., 2020).</p> </li> <li> <p>Protocol optimization: We recommend conducting initial protocol testing on less valuable samples, if available, and changing or adapting the protocols accordingly. Apis honey bee species vary in body size while the anatomical structure remains similar. Thus, it is easy to understand the yield difference of ancient DNA obtained from a leg of the giant honey bee A. dorsata compared to a leg of the small A. florea honey bee. Not only species, but also the conditions of collection and preservation will affect the quantity and quality of the DNA fragments. Remember that a large proportion of your samples will not yield enough DNA of sufficient quality for subsequent sequencing.</p> </li> <li> <p>DNA degradation: It is not recommended to use a vortex to mix samples, as it can mechanically degrade DNA. Instead, a gentle and careful manual inversion of the tube several times to mix its content is advised.</p> </li> </ul>"},{"location":"Section_3_5/#352-materials","title":"3.5.2. Materials","text":"<ol> <li> <p>Large equipment: thermoblock and cooling benchtop centrifuge</p> </li> <li> <p>Dissection tools (cleaned with bleach and rinsed with ethanol)</p> </li> <li> <p>Pipettes</p> </li> <li> <p>Microtubes (1.5 ml and 2 ml, Eppendorf)</p> </li> <li> <p>Saline solution for initial cleaning</p> <ul> <li> <p>Ringer solution (0.125M sodium chloride, 1.5mM calcium chloride dihydrate, 5mM potassium chloride, 0.8mM sodium phosphate dibasic, pH 7.4)</p> </li> <li> <p>Alternatively, PBS (137 mM NaCl, 2.7 mM KCl, 10 mM Na~2~HPO~4~, and 1.8 mM KH~2~PO~4~, pH 7.4) or Tris solution (150 mM NaCl, 50 mM Tris-HCl, pH 7.6) can be used</p> </li> </ul> </li> <li> <p>Lysis buffer: ATL (QIAGEN or alternatively other commercial lysis buffers can be used)</p> </li> <li> <p>Proteinase K (20 mg/ml)</p> </li> <li> <p>Phenol-chloroform-isoamyl alcohol (25:24:1)</p> </li> <li> <p>Chloroform</p> </li> <li> <p>Molecular grade glycogen (10 mg/ml)</p> </li> <li> <p>Ethanol (72% and 100% solutions)</p> </li> <li> <p>Sodium acetate (0.3 M final concentration, pH 5.2)</p> </li> <li> <p>Ultra pure water (Milli-Q)</p> </li> </ol>"},{"location":"Section_3_5/#353-procedure","title":"3.5.3. Procedure","text":""},{"location":"Section_3_5/#3531-preparation-and-lysis","title":"3.5.3.1. Preparation and lysis","text":"<ol> <li> <p>Clean 3-10% bench surface with bleach and rinse with 72% ethanol.</p> </li> <li> <p>Take the museum specimen, carefully cut the hind leg(s) and place them into a 1.5-2 ml Eppendorf tube filled with 1,000 \u03bcl Ringer solution.</p> </li> <li> <p>Gently invert for 20 min to clean and rehydrate.</p> </li> <li> <p>Take out the leg(s) and place on a new paper tissue to dry.</p> </li> <li> <p>Add 180 \u03bcl lysis buffer to a new 1.5 ml Eppendorf tube.</p> </li> <li> <p>Add leg(s).</p> </li> <li> <p>Add 20 \u03bcl of proteinase K, invert and quick spin.</p> </li> <li> <p>Incubate overnight at 56\u00b0C.</p> </li> </ol>"},{"location":"Section_3_5/#3532-dna-extraction","title":"3.5.3.2. DNA extraction","text":"<ol> <li> <p>After incubation, centrifuge and quick spin.</p> </li> <li> <p>Transfer supernatant (\\~190 \u03bcl) to a new tube (leaving the solid part of the tissue at the bottom).</p> </li> <li> <p>Add 190 \u03bcl (equal amount) of phenol:chloroform:isoamyl alcohol to the supernatant.</p> </li> <li> <p>Invert carefully for 5 min.</p> </li> <li> <p>Centrifuge at 12,000 g for 5 min.</p> </li> <li> <p>Pipette upper aqueous phase (\\~100 \u03bcl) into a new tube, making sure not to touch the interphase (Figure 6).</p> </li> <li> <p>Add 190 \u03bcl H~2~O (Milli-Q) to the remaining interphase and organic phase (back extraction).</p> </li> <li> <p>Invert carefully for 5 min.</p> </li> <li> <p>Centrifuge at 12,000 g for 5 min.</p> </li> <li> <p>Pipette upper aqueous phase (\\~200 \u03bcl) into the same tube containing previously pipetted aqueous phase, making sure not to touch the interphase.</p> </li> <li> <p>Add 300 \u03bcl of chloroform to the tube with aqueous phase (equal volume) to remove remaining phenol.</p> </li> <li> <p>Invert carefully for 5 min.</p> </li> <li> <p>Centrifuge at 12,000 g for 5 min.</p> </li> <li> <p>Pipette supernatant into a new tube, making sure not to touch the interphase.</p> </li> </ol> <p></p>"},{"location":"Section_3_5/#figure-6-sample-appearance-during-phase-separation-and-precipitation-steps-during-the-extraction-created-with-biorendercom","title":"Figure 6. Sample appearance during phase separation and precipitation steps during the extraction. Created with Biorender.com.","text":""},{"location":"Section_3_5/#3533-precipitation","title":"3.5.3.3. Precipitation","text":"<ol> <li> <p>Add 1 \u03bcl of 10 mg/ml glycogen solution to help make the pellet visible upon precipitation.</p> </li> <li> <p>Invert for 2 min.</p> </li> <li> <p>Add 20 \u03bcl sodium acetate (10% of the volume).</p> </li> <li> <p>Add 2.5 \u2013 3 volumes of ice-cold 100% ethanol (\\~600 \u03bcl).</p> </li> <li> <p>Place the tube at -80\u00b0C for 1.5 \u2013 2 h.</p> </li> </ol>"},{"location":"Section_3_5/#3534-washing","title":"3.5.3.4. Washing","text":"<ol> <li> <p>Centrifuge at 13,000 g at 4\u00b0C for 30 min.</p> </li> <li> <p>Identify the pellet, and pipette away liquid.</p> </li> <li> <p>Add 850 \u03bcl 72% ice-cold ethanol.</p> </li> <li> <p>Invert carefully 1-3 times making sure not to detach the pellet.</p> </li> <li> <p>Centrifuge at 13,000 g at 4 \u00b0C for 10 min.</p> </li> <li> <p>Identify the pellet, and pipette away liquid.</p> </li> <li> <p>Repeat the wash steps 30-33.</p> </li> <li> <p>Quick spin.</p> </li> <li> <p>Pipette away the last drops of ethanol and let it dry for 30 min at 37\u00b0C to let it dry.</p> </li> </ol>"},{"location":"Section_3_5/#3535-final-solubilization","title":"3.5.3.5. Final solubilization","text":"<ol> <li> <p>Add 40 \u03bcl of H~2~O (Milli-Q).</p> </li> <li> <p>Carefully mix by pipetting up and down several times (do not vortex).</p> </li> <li> <p>Incubate at 4\u00b0C overnight for full solubilization.</p> </li> </ol> <p>TIP: A final, optional DNA purification step can be performed using magnetic beads (e.g. QIAGEN's EZ1\u00ae DNA Tissue Kit). This step will remove co-extracted small molecules that could act as inhibitors in downstream enzymatic reactions. However, it will also yield less total extracted DNA.</p>"},{"location":"Section_3_5/#354-sequencing-of-museum-and-ancient-genomes","title":"3.5.4. Sequencing of museum and ancient genomes","text":"<p>Depending on the age and storage conditions of your samples, the DNA will be more or less degraded and different subsequent sequencing strategies might be used. If sufficiently high-quality DNA is extracted, standard whole-genome sequencing libraries can be prepared (see Section 4). In fact, most of the historic and ancient DNA sequence data have been produced using Illumina technology due to the high data output, cost-effectiveness, and relatively low error rates. It works well on short sequences and is thus particularly well suited to sequence DNA in the range of 50\u2013150 bp, which characterizes most degraded old DNA. Specific protocols for library preparation of ultra-low quantity DNA exist from a variety of companies (e.g., Nextera DNA Library Preparation Kit (Illumina); NEBNext Ultra II kit (New England Biolabs, Inc). For degraded DNA it is not recommended to perform any size selection during the library preparation. We recommend to check with your local sequencing facility for recommendations. Before sequencing, we suggest to evaluate degradation levels and identify possible pollutants, such as formaldehyde, in the prepared libraries with a fragment analyzer (e.g. Bioanalyzer or 4200 TapeStation System (Agilent Technologies Inc.)).</p> <p>As an alternative to whole-genome shot-gun sequencing, it is also possible to utilize hybridization capture methods. In particular, for samples with low endogenous DNA content, shot-gun sequencing is inefficient and expensive. For such samples, hybridization enrichment provides an approach to enrich a DNA sample for specific (and larger) genomic regions (for example, targeted genes, the exome or mitogenome). These approaches not only reduce analytical costs but also maximize the chances of identifying DNA present even in limited abundance. A typical limitation of hybridization-based genome reduction techniques is that custom probe design and synthesis are rather laborious and costly. Recently, a new and cost-effective method, hybridization restriction-associated-DNA (HyRAD) has been developed that uses double enzymatic restriction of fresh DNA extracts to build RNA probes that cover only a fraction of the genome and can serve as baits for capturing homologous fragments from old DNA libraries (Suchan et al., 2021). This can be a suitable, cost-effective approach for non-model organisms, such as Apis species.</p> <p>For A. mellifera, which has well-established genomic resources, an alternative approach is to use SNP panels. These panels target specific SNPs, that can provide information on population structure, diversity and ancestry, or can be used to investigate functional genes or alleles that may be associated with particular phenotypes. Custom genotyping panels can be created, but a number of pre-designed SNP arrays are available as ready-to-use assays for the western honey bee (Chapman et al., 2017, 2015; Henriques et al., 2021; Momeni et al., 2021; Mu\u00f1oz et al., 2015). A caveat to keep in mind for both targeted enrichment and SNP panel approaches is the ascertainment bias that can be introduced by the selection of particular probe sets, which can affect downstream estimates of population genetic statistics.</p> <p>Finally, novel sequencing techniques are constantly being developed. We recommend following the latest research of human ancient genomics for an overview on the latest developments (Orlando et al., 2021).</p>"},{"location":"Section_3_5/#355-guidance-on-the-data-analysis-methods","title":"3.5.5. Guidance on the data analysis methods","text":"<p>Sequence data clean-up and strict filtering is crucial for reliable variant calling and subsequent analyses and interpretation of the data. Ancient DNA has \u201cmistakes\u201d at the ends caused by deamination of cytosine, which are converted into uracil and thereafter sequenced as thymine analogues. This process is responsible for the sequencing artifacts observed as misincorporations of G\u2192A at the 5\u2032 and C\u2192T at the 3\u2032 ends. The frequency of this DNA damage increases with the age of a sample and can be statistically evaluated and taken into account during bioinformatic analysis. To evaluate DNA damage, it is recommended to perform a quality check of raw sequence reads using (e.g. DamageProfiler or mapDamage2. The latter program also enables users to rescale quality scores of likely damaged positions in the reads. In this way, \u201cdamaged\u201d positions will have less weight for mapping and subsequent variant calling. A critical step is to use strict read trimming to remove adapters and low-quality terminal sequences (as identified for instance by DamageProfiler). Also overlapping read pairs, resulting from shorter DNA fragments than sequencing read length, may be collapsed into consensus sequences (e.g. by using BBmerge).</p> <p>Once the raw sequence data has been sufficiently cleaned, standard variant calling pipelines and analyses can be followed (see Section 3.4 and Section 4.3). Some tips include adjusting parameters for mapping specificity and sensitivity. Moreover, rather than actual variant calling, it is possible to use genotype likelihoods instead, and in this way account for the uncertainties and lower base qualities of ancient DNA bases. This can be done within the framework of The Genome Analysis Toolkit (GATK) or Analysis of Next Generation Sequencing Data (ANGSD) that covers a wide range of analytical population genetics statistics.</p>"},{"location":"Section_3_5/#356-applications-and-limitations","title":"3.5.6. Applications and limitations","text":"<p>Any ancient historic DNA study is only as good as the sampling and careful interpretation of results. For instance, low genetic diversity in historic samples could result from the fact that all honey bees were from the same colony. Often in ancient and museum specimens, limited knowledge of sampling conditions is available, and it may not be known whether the samples were collected from managed hives or in the wild. Cautious interpretation is thus crucial. Nevertheless, ancient honey bee genomics of museum samples has a great potential to illuminate the evolutionary history of species and different subspecies, to identify the timing of population splits, and investigate signatures of natural selection (Cridland et al., 2018; Mikheyev et al., 2015; Parejo et al., 2020). Moreover, the approaches can not only be applied to study the past diversity of bees but also their historically associated pathogens and microbiomes. Thus, new lines of investigation could be the study of the evolution and spread of pathogens and the genetic responses of hosts, as well as past bee health related to its microbiome.</p>"},{"location":"Section_4_1/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_1/#41-introduction","title":"4.1. Introduction","text":"<p>When considering whole-genome analyses, one major advantage of working with A. mellifera, A. cerana or even A. dorsata is that their genomes are very compact, only ~223-228 Mb long (Oppenheim et al., 2020; Wallberg et al., 2019; Wang et al., 2020). In comparison, the honey bee parasite Varroa harvest a larger genome size of 368 Mb (Cornman et al., 2010; Techer et al., 2019) while the human genome, for instance, is even larger with 3055 Mb (Nurk et al., 2022). As a result, it quickly became evident that the cost-to-benefit ratio of using whole genome sequencing for honey bee applications was excellent, as compared to other approaches. For instance, SNP chips only allow the study of between 10,000 and 100,000 markers for a price that will not be much lower than whole genome sequencing (between one third and half the price at the time of writing), whereas the latter approach enables the detection of several million markers. Other disadvantages of using SNP chips are that the choice of markers is biased, and that the high density of SNPs and indels in the A. mellifera genome complicates the chip design (allele drop-out can often happen due to neighboring polymorphism).</p> <p>Nevertheless, the whole-genome sequencing approach has its drawbacks, with complex and intricate analysis pipelines and longer computational times. While bioinformatics is included in most molecular biology and ecology related curriculum, the steep learning curve can be discouraging for new users without proper guidance (Carvalho &amp; Rustici, 2013). Additionally, whole genome computations should really be carried on remote access high performance clusters (HPC) or local workstations. It may thus not be ideal if rapid answers to questions such as parentage testing or subspecies assignment are needed. Moreover, data storage can be a critical issue, with an average of 2-3 Gb needed per sample for the raw sequencing files (FASTQ: text-based file that contains the nucleotide sequence and associated quality score), 3-4 Gb for the corresponding alignment files (BAM: binary alignment map files) and files up to one terabyte for reporting genomic sequence variation (VCF: variant calling files) depending on the dataset size.</p> <p>Until now, most sequencing results were obtained with paired-end Illumina sequencing. With the recent progress made in long-read sequencing, having reference-quality assemblies for several individuals, ideally from different subspecies within a targeted Apis species can become a future standard. This will allow the construction of pan-genome graphs, taking inter-individual variation into account at the reference genome level. Long-read sequencing of individual samples will also allow the detection of large structural rearrangements and repeat landscapes that cannot be analysed accurately with short reads.</p>"},{"location":"Section_4_10/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_10/#410-applying-population-genomics-to-conservation-reduced-snp-analysis","title":"4.10. Applying population genomics to conservation: Reduced SNP analysis","text":"<p>Whole genomes provide important insights into the processes that shape diversity patterns (Chen et al., 2016; Cridland et al., 2017; Fuller et al., 2015; Harpur et al., 2014; Henriques et al., 2018; Nelson et al., 2017; Parejo et al., 2017; Parejo et al., 2020; Wallberg et al., 2014) and are offering unprecedented power for delving into fundamental apicultural questions (e.g., tolerance and resistance to the ectoparasite Varroa destructor, introgression, etc.) (Harpur et al., 2019, 2020; Parejo et al., 2016; Saelao et al., 2020)), with potential implications for sustainable honey bee management. However, the adoption of whole genome approaches is hindered by the requirement for sophisticated laboratory and computational resources, as well as advanced bioinformatics expertise. Many molecular biology laboratories, conservation centers, and breeding facilities lack access to these resources, limiting the value of genomic data in these contexts. To address this challenge, experts can leverage whole genome data to develop reduced SNP-based tools, and these can be more easily employed by the broader honey bee community.</p> <p>Panels containing a reduced number (&lt; 160) of highly informative markers have been designed from genome-wide SNPs (Mu\u00f1oz et al., 2017) or from whole-genome data (Chapman et al., 2015; Henriques, Browne, et al., 2018) to address different goals such as (i) identifying Africanized honey bees (Chapman et al., 2015), (ii) estimating C-lineage introgression into the M-lineage A. m. mellifera and A. m. iberiensis subspecies (Henriques et al., 2018; Henriques et al., 2018; Mu\u00f1oz et al., 2017) or (iii) monitoring diversity in immune genes (Henriques et al., 2021). All these reduced SNP panels have been tailored for genotyping in the MassARRAY MALDI-TOF platform, a cost-effective technology for a relatively small number of markers and a large number of samples. For example, in a single 384 SpectroCHIP array, it is possible to genotype 384 samples with one SNP-plex (containing a maximum of 40 SNPs), 192 samples with two SNP-plexes, 128 samples with three SNP-plexes, 96 samples with four SNP-plexes, or other possible combinations of markers and samples to a maximum of 384, all for the same price. Additional technologies, such as Fluidigm microfluidic array, SNaPshot, and capture-based target enrichment methods, are also appealing for the development of genotyping tools because they also allow screening dozens to hundreds of SNPs in a cost-effective manner (Daca-Roszak et al., 2016; Emerman et al., 2017; von Thaden et al., 2020).</p> <p>When the number of selected SNPs is in the order of thousands to tens of thousands, other technologies such as Affymetrix or Illumina Infinium are better suited for genotyping. These technologies have been used for genotyping highly dense SNP panels with varying purposes, including genome-wide association screening for hygienic behavior (~44,000 SNPs) (Sp\u00f6tter et al., 2016), identification of honey bee subspecies (~4,000 SNPs) (Momeni et al., 2021), or genomic selection (~100,000 SNPs) (Jones et al., 2020).</p> <p>When developing a panel, the first step is to establish a clear goal that will guide the choice of SNPs to be included. For instance, if one wants to create a panel for screening populations for local adaptation, a selection analysis such as LFMM should be performed. However, if the goal is to identify introgressed populations, an admixture analysis with the focal subspecies should be performed. To develop a reliable molecular tool, it is important to start out with a powerful discovery panel, which should include a reasonable number of individuals that capture, as much as possible, the entire population diversity. Using A. m. iberiensis as the model organism (Henriques et al., 2018) demonstrated that, when employing a sample size &lt; 10 in the panel design and a sample breadth representing only a fraction of a population's genetic diversity, a bias is introduced in the informativeness of the markers. This finding implies that to develop a reliable reduced SNP panel, one must first understand the diversity patterns of the target population.</p> <p>This section shows all the steps involved in developing a reduced panel tailored to distinguish M- from C-lineage subspecies. In this tutorial, the panel contains only 40 highly informative SNPs, the maximum plex size of the MassARRAY MALDI-TOF technology.</p>"},{"location":"Section_4_10/#4101-materials","title":"4.10.1. Materials","text":"<p>This section requires PLINK (see Section 4.7), CLUMPAK, ADMIXTURE (version 1.3; see Section 4.8), snpEff from Galaxy (see Section 4.9), and the R package chromoMap. The dataset used herein will be pop_gen_MD_maf005, which was created in Section 4.7.</p>"},{"location":"Section_4_10/#4102-methods","title":"4.10.2. Methods","text":"<p>Step 1. Divide the dataset into training and holdout subsets, following Anderson\u2019s method (Anderson, 2010). This is a critical step because if the informative SNPs are chosen and validated on the same individuals, an upward bias will be introduced. The training subset should contain 75% of randomly chosen individuals, which will be used to select the most informative SNPs. The remaining 25% of the individuals will make the holdout subset, which will be used to validate the SNP panel.</p> <p>1. Create a file with the holdout subset. The individuals should be chosen at random, but to follow the tutorial we provide the file called holdout.</p> <p>2. Create the holdout subset containing only the individuals listed in the holdout file:</p> <pre><code>plink --bfile pop_gen_MD_maf005 \\\n--keep holdout `#list of individuals to keep` \\\n--make-bed \\\n--out pop_gen_MD_maf005_holdout\n</code></pre> <p>3. Create the training subset excluding the individuals listed in the holdout file:</p> <pre><code>plink --bfile pop_gen_MD_maf005 \\\n--remove holdout `#list of individuals to remove` \\\n--make-bed \\\n--out pop_gen_MD_maf005_training\n</code></pre> <p>Step 2. Select the most informative SNPs from the training dataset. The main goal of the panel designed herein is to distinguish M- from C-lineage subspecies. Given that these two lineages are very divergent, it is expected to find many fixed SNPs (F~ST~= 1), which are the most informative ones.</p> <p>1. Calculate the F~ST~ values between C- and M- lineage for each SNP in the training subset (see Section 4.7 for further details).</p> <pre><code>plink --bfile pop_gen_MD_maf005_training \\\n--fst --within within_M_C_ind_training \\\n--out pop_gen_MD_maf005_training\n</code></pre> <p>2. Select the SNPs with F~ST~ = 1. First, the awk command will select the lines that have a value equal to one in the fifth column and, from these values, only the second column will be printed in the file pop_gen_MD_maf005_training.fst_1.</p> <pre><code> awk '{if($5 == 1){print}}'  \n pop_gen_MD_maf005_training.fst | \\\n awk '{ print $2 }' &gt; \n pop_gen_MD_maf005_training.fst_1\n</code></pre> <p>Step 3. Apply filters to narrow down the number of discovered SNPs. In this tutorial example, a total of 416,123 SNPs exhibit an F~ST~ = 1. To narrow down this massive number, filters related to the panel goal must be applied. Here, only SNPs classified as having a high impact by snpEff will be retained. Other filtering criteria include linkage (SNPs that are physically linked may contain redundant information and can therefore be eliminated) and coverage of the 16 honey bee chromosomes. To investigate how the SNPs are distributed across the chromosomes, the R package chromoMap will be used. This package requires two files: the chromosome_file.txt, containing the chromosome coordinates, and the high_impact.txt, containing the genomic coordinates of the SNPs.</p> <p>1. Convert the pop_gen_MD_maf005_training PLINK 1 binary file to VCF format:</p> <pre><code>plink --bfile pop_gen_MD_maf005 \\\n--extract pop_gen_MD_maf005_training.fst_1 \\\n--recode vcf --out FST1snps\n</code></pre> <p>2. Using the methodology described in Step 17 of the LFMM section (Section 4.9), annotate the file FST1snps.vcf with snpEff.</p> <p>3. Download the annotated VCF file from Galaxy, here named Galaxy21.vcf.</p> <p>4. Create the annotation file to be used by chromoMap. The command grep will search and retrieve the lines that contain the string \u2018HIGH\u2019. From these lines, the command awk will print the third column (SNP name) followed by the first column (chromosome name) and the second one (genomic position) two times.</p> <pre><code>grep 'HIGH' Galaxy21.vcf | \\\nawk '{ print $3\"\\t\" $1\"\\t\" $2\"\\t\"$2 }' &gt; high_impact.txt\n</code></pre> <p>5. Visualize the SNPs distribution using chromoMap in R.</p> <pre><code>install.packages(\"chromoMap\")\nlibrary(chromoMap)\nchromoMap(\"chromosome_file.txt\", \"high_impact.txt\", ploidy = 1)\n</code></pre> <p>6. As depicted in Figure 13, some SNPs are located in close proximity to each other. Use PLINK to remove one of these linked SNPs by running the following commands:</p> <p>a. Create a SNP list with the SNPs annotated with a high impact</p> <pre><code>grep 'HIGH' Galaxy21.vcf | \\\nawk '{ print $3}' &gt; high_impact_list\n</code></pre> <p>b. Create a PLINK 1 binary file containing only the high impact SNPs.</p> <pre><code>plink --bfile pop_gen_MD_maf005 \\\n--extract high_impact_list \\\n--make-bed \\\n--out pop_gen_MD_maf005_high_impact_list\n</code></pre> <p>c. Create a file excluding SNPs that are in the same genomic region. To have a final list of 40 SNPs, only loci that are at least 1,500 Kb apart will be selected (using the flag --bp-space).</p> <pre><code>plink --bfile pop_gen_MD_maf005_high_impact_list \\\n--bp-space 1500000 \\\n--make-bed \\\n--write-snplist --out pop_gen_MD_maf005_high_impact_list_prunned\n</code></pre> <p>Step 4. Assay validation. Using the holdout subset, it is possible to assess whether the admixture proportions inferred from whole-genome data are similar to those obtained with the reduced SNP panel.</p> <p>1. Run ADMIXTURE following the steps detailed in Section 4.8 using all the SNPs in the holdout subset (file pop_gen_MD_maf005_holdout)</p> <p>2. Run ADMIXTURE for the holdout subset using only the highly informative SNPs (file pop_gen_MD_maf005_high_impact_list_pruneddata)</p> <p>3. Compare the results obtained in 1) and 2) by calculating, for instance, Pearson\u2019s correlation (r).</p> <p>In the tutorial example, all tested individuals were revealed to be pure (with no signs of introgression) and r = 1. If one wants to develop a reduced SNP panel for estimating introgression proportions, the panel should also be validated in admixed individuals.</p> <p></p>"},{"location":"Section_4_10/#figure-13-chromosome-map-showing-the-positions-green-line-of-the-highly-informative-snps-a-before-and-b-after-linkage-disequilibrium-pruning","title":"Figure 13. Chromosome map showing the positions (green line) of the highly informative SNPs A) before and B) after linkage disequilibrium pruning.","text":""},{"location":"Section_4_2/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_2/#42-ploidy-and-sampling-considerations","title":"4.2. Ploidy and sampling considerations","text":"<p>Since male bees are haploid and female bees are diploid, the genetic information derived from these samples will be different, and the best sample type will vary depending on the study\u2019s goals. Additionally, sampling individuals versus groups of individuals will change the types of questions that can be answered with the resulting genomic data. Below, we outline some information to help determine what type of sample to work with.</p>"},{"location":"Section_4_2/#421-individual-sampling","title":"4.2.1. Individual sampling","text":"<p>Genotypic information for workers and queens match standard polymorphism data showing three genotypes: homozygous for the reference allele, heterozygous, and homozygous for the alternative allele. Drones, being haploid, only two genotypes: the reference or the alternative allele. Workers provide twice as much data as drones due to their diploid nature, offering better insights into population structure and admixture. However, drone analysis requires less sequencing coverage and is more cost-effective.</p>"},{"location":"Section_4_2/#422-pooled-sampling","title":"4.2.2. Pooled sampling","text":"<p>In addition to individual samples, depending on the goal of the experiment, pooled sampling may be necessary. Since workers carry both queen\u2019s and inseminating males\u2019 genetics, a pooled worker sample may capture the entire allelic diversity within a colony at a more affordable cost than individual analysis. In this case, 50% of the pooled workers\u2019 genetics are derived from the queen, whereas the remaining 50% is representative of the patrilines (the cohort of drones that inseminated the queen) of the colony (see Section 4.3.7 for a brief discussion on handling pooled data). Pools can be made from honey bee tissue (e.g., thoraces, flight muscles, heads with compound eyes removed, legs, antennae) or from multiple specimen DNA.</p>"},{"location":"Section_4_2/#4221-groups-of-workers","title":"4.2.2.1. Groups of workers","text":"<p>To represent the complete genetic makeup of the meta organism that is a honey bee colony, a large number of individuals should be sampled. This requirement is a consequence of the polyandrous mating system in Apis bees with variable degrees across species (Kraus et al., 2005; Palmer &amp; Oldroyd, 2000). While extreme polyandry levels were reported in the giant honey bee A. dorsata (up to 102 detected patrilines (Wattanachaiyingcharoen et al., 2003)) the following advices relates A. mellifera mating frequency (averaging around 13.8 \u00b1 2.5 males (Palmer &amp; Oldroyd, 2000)). The number of pooled individuals has ranged from n = 12 to 500 (Guichard et al., 2021; Momeni et al., 2021; Rizwan et al., 2020; Saelao et al., 2020), and we recommend sampling and sequencing in the order of hundreds of individuals. For example, if 15 males inseminated the queen and a targeted sequencing depth is 30-fold per patriline is desired, pooling approximately 500 related workers would be necessary. Each worker in the pool would then represent 1/15th of the male genetic contribution of the colony, assuming equal representation of all patrilines.</p>"},{"location":"Section_4_2/#4222-groups-of-drones","title":"4.2.2.2. Groups of drones","text":"<p>Alternatively, a group of drones can also be sampled. Pooling drones into the same genotyping experiment will allow indirect inference of the queen\u2019s genetic information, as drones carry the queen\u2019s genetics exclusively. However, to obtain a complete representation of the queen\u2019s genetics, it is still necessary to pool a significant number of drone offspring together (Jones et al., 2020).</p>"},{"location":"Section_4_3/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_3/#43-snp-and-indel-detection","title":"4.3. SNP and indel detection","text":"<p>Here we provide a primer on the bioinformatics involved in detecting sequence variants from Illumina data, as it is often very difficult to know how to start. The software tools chosen here result from the authors\u2019 positive experience in their application of A. mellifera genomics workflow but do not reject the validity and rapidity of alternative algorithms and pipelines. We recommend the review by Bourgeois and Warren (2021) listing the most common software and methods applicable to comparative and population genomics in eukaryotes. For further details on each parameter, future users will have to go to the dedicated websites for BWA-MEM, SAMtools, GATK, Picard, VCFtools, and BCFtools (Danecek et al., 2011, 2021; McKenna et al., 2010).</p>"},{"location":"Section_4_3/#431-mapping-reads-with-bwa-mem-from-fastq-files-to-bam-files","title":"4.3.1. Mapping reads with BWA-MEM: From FASTQ files to BAM files","text":"<p>The first step is to map the short reads to the reference genome to produce a BAM file. Typically, for SNP detection, sequencing is performed paired-end with an Illumina instrument, giving millions of \\~150 bp reads in which 300-500 bp will separate the beginning of Read 1 (first mate or forward read) and the end of Read 2 (second mate or reverse read), according to the size specification of the sequencing library. For each sample, the sequencing instrument will produce two files in compressed FASTQ format containing the reads. These will have names in the form \u201cAOC5_TAGCTT_L002_R1.fastq.gz\u201d and \u201cAOC5_TAGCTT_L002_R2.fastq.gz\u201d, which includes the sample name (AOC5), the sample identification in the sample sheet (TAGCTT), the lane number on the sequencing machine (L002) and the Read (R1 or R2). One file will contain all Read 1 sequences and another will contain all Read 2 sequences.</p> <p>In honey bee genomics, there is currently no consensus on a single best mapping software. However, based on our literature survey, we found that BWA-MEM (Burrows\u2013Wheeler Aligner), Bowtie2 and Stampy have been used for A. mellifera and A. cerana short DNA read mapping. However, we noted that BWA-MEM was the most commonly used, and it was also reported as one of the top performing short reads aligners (Musich et al., 2021). Therefore, we have chosen BWA-MEM as our current standard software for mapping honey bee genomes.</p> <p>Step 1. Mapping the reads to the reference genome is done here with BWA-MEM (Li, 2013) and parsing with SAMtools using the following commands:</p> <pre><code>bwa mem -M GCF_003254395.2_Amel_HAv3.1_genomic.fna \\\nAOC5_TAGCTT_L002_R1.fastq.gz \\\nAOC5_TAGCTT_L002_R2.fastq.gz | \\\nsamtools view -bh -o AOC5_TAGCTT_L002_aligned.bam -\n</code></pre> <p>The -M command marks shorter split reads as secondary. As BWA-MEM will output a very large file in SAM format, its output is piped (|) directly into the samtools view -bh command, that will compress directly in the compact BAM format (-b), while including the header (-h).</p> <p>The full description of the SAM format can be found online, and is updated on a regular basis. Briefly, a SAM/BAM file will contain a header with diverse information, such as if the file was sorted, the name of the reference sequence used, and the programs that were used to process the data (alignment and other subsequent analyses).</p> <p>Special considerations: If a sample was sequenced in two separate runs, lanes or from two different libraries, the best practice is to require the mapping to be done separately and the BAM files produced to be subsequently merged. This is important for backwards traceability and for downstream analyses, as reads from different runs may have specific biases affecting base or mapping quality estimations. In this scenario, sample \u201cBER15\u201d was sequenced in two separate lanes of an Illumina instrument. Alignment was done separately, giving two BAM files, to be merged with samtools merge.</p> <p>Step 2. Merge BAM files with mapped reads using SAMtools:</p> <pre><code>samtools merge -o BER15_ATCACG_merged_aligned.bam \\\nBER15_ATCACG_L002_aligned.bam \\\nBER15_ATCACG_L005_aligned.bam\n</code></pre> <p>This information is passed on to the BAM file in the mandatory ID tag of the read group (\\@RG) lines in the header, and each mate-pair read in the BAM file will be assigned to one or the other ID tag:</p> <pre><code>samtools view -H BER15_ATCACG_merged_aligned.bam | grep ^@RG\n@RG     ID:BER15_ATCACG_L002\n@RG     ID:BER15_ATCACG_L005\n</code></pre> <p>Step 3. Sort the BAM file using the following commands with Picard:</p> <pre><code>java -jar picard.jar SortSam \\\n    I=AOC5_TAGCTT_L002_aligned.bam \\\n    O=AOC5_TAGCTT_L002_sorted.bam \\\n    SORT_ORDER=coordinate\n</code></pre>"},{"location":"Section_4_3/#432-marking-duplicate-reads-with-picard","title":"4.3.2. Marking duplicate reads with Picard","text":"<p>During sample preparation and sequencing, DNA amplification steps will be performed, in which case a single DNA fragment can produce duplicate reads. It is important to tag such reads in the BAM file, so that they will be ignored when calling variants with GATK HaplotypeCaller.</p> <p>Step 4. Tag the duplicate reads using Picard option MarkDuplicates:</p> <pre><code>java -jar picard.jar MarkDuplicates \\\n    I=AOC5_TAGCTT_L002_sorted.bam \\\n    O=AOC5_TAGCTT_L002_dedup.bam \\\n    M=marked_dup_metrics.txt\n</code></pre> <p>Step 5. The reads can then be sorted and indexed with SAMtools:</p> <pre><code>samtools sort -T AOC5_TAGCTT_L002_dedup.bam \\\n-o AOC5_TAGCTT_L002_sort.bam\nsamtools index AOC5_TAGCTT_L002_sort.bam\n</code></pre>"},{"location":"Section_4_3/#433-base-quality-score-recalibration-bqsr-with-gatk","title":"4.3.3. Base quality score recalibration (BQSR) with GATK","text":"<p>Sequence reads in the FASTQ format have a quality score associated to each base called by the sequencing machine, which are based on the manufacturer\u2019s algorithms. These express the confidence of the base calling and will greatly influence the algorithms used for variant calling as well as deciding between sequencing errors and real biological differences.</p> <p>BQSR models non-random technical errors in the data using a machine learning approach and adjusts the scores accordingly. A set of known variants in the VCF file format is provided to mask bases at sites of expected variation. Mismatches outside these sites are counted as errors.</p> <p>Step 6. Use the following GATK commands to generate the recalibration table:</p> <pre><code>gatk BaseRecalibrator \\\n  -I AOC5_TAGCTT_L002_sort.bam \\\n  -R GCF_003254395.2_Amel_Hav3.1_genomic.fna \\\n  --known-sites sites_of_variation.vcf \\\n  --known-sites another/optional/setOfSitesToMask.vcf \\\n  -O recal_data.table\n</code></pre> <p>Step 7. Recalibrate base qualities:</p> <pre><code>gatk ApplyBQSR \\\n  -R GCF_003254395.2_Amel_Hav3.1_genomic.fna \\\n  -I AOC5_TAGCTT_L002_sort.bam \\\n  --bqsr-recal-file recal_data.table \\\n  -O AOC5_TAGCTT_L002_BQSR.bam\n</code></pre>"},{"location":"Section_4_3/#434-calling-variants-with-gatk","title":"4.3.4. Calling variants with GATK","text":"<p>Step 8. Variants can be called for each sample individually using the following GATK commands:</p> <pre><code>gatk HaplotypeCaller \\\n  -R GCF_003254395.2_Amel_Hav3.1_genomic.fna \\\n  -I AOC5_TAGCTT_L002_BQSR.bam \\\n  -O AOC5.g.vcf.gz\n  -ERC GVCF \\\n  -ploidy 2\n</code></pre> <p>Special considerations: The option \u201c-ploidy\u201d is set to 2 (diploid) in the example, which fits for a honey bee worker or queen sample. The option \u201c-ploidy 1\u201d can be used for haploid drones, but in our experience, this leads to false positive SNP detection. A better option is to analyze haploid samples using the diploid model and to filter out SNPs with heterozygote calls in the drones after the genotyping step.</p>"},{"location":"Section_4_3/#435-combining-all-samples-and-genotypes-with-gatk","title":"4.3.5. Combining all samples and genotypes with GATK","text":"<p>At this stage, all individual genotype files will be combined into a single file. If more than hundred samples are processed, this may require a large amount of memory, which can be specified (<code>--java-options \"-Xmx10g\"</code>).</p> <p>Step 9. Combine genotype files:</p> <pre><code>gatk --java-options \"-Xmx10g\" CombineGVCFs \\\n  -R GCF_003254395.2_Amel_Hav3.1_genomic.fna \\\n  --variant AOC1.g.vcf.gz \\\n  --variant AOC2.g.vcf.gz \\\n  --variant AOC3.g.vcf.gz \\\n  --variant AOC4.g.vcf.gz \\\n  --variant AOC5.g.vcf.gz \\\n  --o all_samples.g.vcf.gz\n</code></pre> <p>Step 10. Once combined in a large file, joint genotyping can be performed:</p> <pre><code>gatk --java-options \"-Xmx10g\" GenotypeGVCFs \\\n  -R GCF_003254395.2_Amel_Hav3.1_genomic.fna \\\n  -V all_samples.g.vcf.gz \\\n  --use-new-qual-calculator \\\n  -O all_samples_genotyped.vcf.gz\n</code></pre>"},{"location":"Section_4_3/#436-filtering-variants-with-gatk-technical-filters","title":"4.3.6. Filtering variants with GATK: Technical filters","text":"<p>Step 11. The following commands will retain only site variants coded as SNPs:</p> <pre><code>gatk SelectVariants \\\n  -R GCF_003254395.2_Amel_Hav3.1_genomic.fna \\\n  -V all_samples_genotyped.vcf.gz \\\n  --select-type-to-include SNP \\\n  -O all_samples_genotyped_SNPs.vcf.gz\n</code></pre> <p>Step 12. Variants can then be filtered based on quality scores. First, mark the SNPs in the VCF file that do not pass quality score thresholds:</p> <pre><code>gatk VariantFiltration \\\n  -R GCF_003254395.2_Amel_Hav3.1_genomic.fna \\\n  --filter-expression \u00ab QD &lt; 2.0 || FS &gt; 60.0 || MQ &lt; 40.0 \u00bb\n  --filterName \u201cquality_filters\u201d\n  -V all_samples_genotyped_SNPs.vcf.gz \\\n  -O all_samples_genotyped_SNPs_filter_tagged.vcf.gz\n</code></pre> <p>Here, we adopted the recommended and generic hard-filtering parameters of all SNP with a variant confidence (QD) below 2, a strand bias (FS) over 60 and a mapping quality (MQ) below 40. However, we recommend readers to always plot these statistics distribution using R and ggplot2 and verify that the thresholds is adapted to their dataset.</p> <p>Step 13. Then, the SNPs that passed the filters can be extracted:</p> <pre><code>gatk SelectVariants \\\n  -R GCF_003254395.2_Amel_Hav3.1_genomic.fna \\\n  --exclude-filtered\n  -V all_samples_genotyped_SNPs_filter_tagged.vcf.gz\n  -O all_samples_genotyped_SNPs_filter_passed.vcf.gz\n</code></pre> <p>Special considerations: If variants were detected in haploid drones using the diploid model, markers having heterozygote calls can now be removed.</p>"},{"location":"Section_4_3/#437-filtering-variants-with-vcftools-data-quality","title":"4.3.7. Filtering variants with VCFtools: Data quality","text":"<p>To ensure a high-quality dataset, SNPs should be filtered using not only quality scores, but also, for instance, the mean depth and missing data. Here, the software VCFtools (Danecek et al., 2011) is used to include biallelic SNPs (--max-alleles) with at least 5 read depth (--min-meanDP). Further information about SNP filtering, such as the correlation between markers or linkage disequilibrium (LD), can be found in Section 4.7.</p> <pre><code>vcftools \\\n--gzvcf all_samples_genotyped_SNPs_filter_passed.vcf.gz \\\n--max-alleles 2 \\\n--min-meanDP 5 \\\n--out all_samples_filter_2.vcf.gz\n</code></pre>"},{"location":"Section_4_3/#438-genotype-phasing","title":"4.3.8. Genotype phasing","text":"<p>Phasing refers to the process of statistical estimation of haplotypes from genotype data. While drone sequencing generates directly phased data, worker or queen sequencing requires an extra step in the analysis for phasing the diploid data. There are several freely available programs for this purpose, such asBeagle 5.4 (Browning et al., 2021),fastPHASE(Scheet &amp; Stephens, 2006),IMPUTE2 (Howie et al., 2009), and SHAPEIT4 (Delaneau et al., 2019). SHAPEIT4 is highly accurate, simple, and computationally fast in large datasets (De Marino et al., 2022). The program can be implemented using the following command line:</p> <pre><code>shapeit4.2 --input all_samples_filter_2.vcf.gz \\\n--map genomic_map.gmap.gz \\\n--output phased.vcf.gz\n</code></pre>"},{"location":"Section_4_3/#439-snp-annotation-with-snpeff","title":"4.3.9. SNP annotation with SnpEff","text":"<p>SnpEff is a toolbox to annotate the variants and to calculate their effects (Cingolani et al., 2012). SnpEff can be implemented on the Galaxy analysis platform or by using the following command line:</p> <pre><code>java -Xmx8g -jar snpEff.jar Apis_mellifera all_samples_filter_2.vcf.gz &gt; all_samples_filter_2_annotated.vcf.gz\n</code></pre>"},{"location":"Section_4_3/#4310-snp-analysis-by-sequencing-pooled-samples","title":"4.3.10. SNP analysis by sequencing pooled samples","text":"<p>Pooling offers an alternative for screening populations or subspecies using genome-wide markers and high-throughput technologies. Group-level data obtained from genotyping experiments will deviate from individual-level data in the sense that frequencies of the different alleles observed in the pool, rather than genotype polymorphisms, will be obtained (see Section 4.2). Allele frequencies can be used directly or transformed into mean genotype using PLINK (see Section 4.5), or dedicated genotype reconstruction methods. Such methods are currently available to use such allele frequencies, from drone offspring or from a worker pool (Eynard et al., 2022) to obtain queen genotypes. The procedure described here allows the estimation of allele frequencies in pooled samples by using the PoPoolation software (Kofler et al., 2011).</p>"},{"location":"Section_4_3/#43101-from-fastq-files-to-bam-files","title":"4.3.10.1. From FASTQ files to BAM files","text":"<p>Mapping reads and duplicate reads detection are performed as described above (see Section 4.3).</p>"},{"location":"Section_4_3/#43102-snp-selection-and-pileup-files","title":"4.3.10.2. SNP selection and pileup files","text":"<p>Each line in a PILEUP file describes a single position in the genome. It contains information on the number of reads \u201cpiled up\u201d at the position, together with the base called for each read, if the reads mapped to the forward or the reverse strand and quality scores for the base called for each read. PILEUP files are very large and the detection of SNPs in pooled sequencing is not very effective, so it is best to work on a list of high-quality SNPs that were detected in a previous experiment.</p> <pre><code>samtools mpileup -I -l snp.list \\\n    -f reference_genome.fa \\\n    -C 50 -q 20 -Q 20 sample.bam \\\n    -o sample.pileup\n</code></pre> <p>The option -I is for skipping indels. The list snp.list is in the form of chromosome position (tab separated). This will generate one PILEUP file per sample. A list of BAM files can be provided (option -l), to make a mpileup file containing multiple samples.</p> <pre><code>samtools mpileup -I -l snp.list \\\n    -f reference_genome.fa \\\n    -C 50 -q 20 -Q 20 -b bams.list \\\n    -o multiple_samples.mpileup\n</code></pre>"},{"location":"Section_4_3/#43103-counting-reads-per-allele-with-popoolation","title":"4.3.10.3. Counting reads per allele with PoPoolation","text":"<p>PoPoolation (Kofler et al., 2011) takes PILEUP files as entries and generates read counts for each possible nucleotide base (A, C, G, or T) at each SNP position reported in the PILEUP file.</p> <pre><code>java -ea -Xmx10g -jar mpileup2sync.jar \\\n                        --input sample.pileup \\\n                        --output sample.sync \\\n                        --fastq-type sanger\n</code></pre> <p>The sample.sync files present the results in the form of one line per SNP position, with a count of reads for each of A:T:C:G:N:del. The PoPoolation suite provides some perl scripts to calculate allele frequency differences or F~ST~ (fixation index) values between pairs of pooled DNA sequences.</p>"},{"location":"Section_4_4/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_4/#44-comparing-whole-genomes","title":"4.4. Comparing whole genomes","text":"<p>Comparing different versions of whole-genome assemblies can help assess their quality and identify major structural rearrangements occurring between individuals of the same species, from different subspecies, or different species. The rearrangements thus detected will be large deletions, insertions, inversions, or translocations. There are many software options for pairwise alignments, including LAST (Frith &amp; Kawaguchi, 2015), MUMmer (Mar\u00e7ais et al., 2018) or, minimap (Heng Li, 2018), among others. These tools can also be used to align long-reads from PacBio SMRT (single-molecule real-time) sequencing technology or Oxford Nanopore Technologies (ONT) on reference genomes, thus enabling rearrangements to be detected directly after the assembly process. The case of simultaneous and multiple alignments is more complex and will not be described here (see currently developed methods (Armstrong et al., 2020; Kille et al., 2022) and large eukaryote dataset applications (Feng et al., 2020; Zoonomia Consortium, 2020)).</p>"},{"location":"Section_4_4/#441-conducting-a-pairwise-genome-comparison-with-last","title":"4.4.1. Conducting a pairwise genome comparison with LAST","text":"<p>The example of pairwise whole-genome comparison given here, using LAST, describes the main steps with default values for the options proposed being used as much as possible. Detailed information on the numerous options proposed by the software that can affect sensitivity, speed and other aspects are described in the software documentation. In the following example, we will compare the AMelMel genome assembly of the black bee A. mellifera mellifera (query sequence), to the reference genome HAv3.1 (target sequence).</p> <p>Step 1. Both the target (HAV3_1.fa) and query (AMelMel_1.fa) sequences must be in FASTA format, in the form:</p> <pre><code>cat AMelMel_1.fa\n&gt;Chromosome1\nACTACAGGATATCCATAGACAT\u2026\n&gt;Chromosome2\nGTCAGGATAGACAGGTAGACAT\u2026\n</code></pre> <p>Use basic Unix commands such as cat or less to print the content of your target.fa and query.fa.</p> <p>Step 2. Prepare index files for the target sequence with the command lastdb:</p> <pre><code>lastdb -uNEAR HAV3_1Db HAV3_1.fa\n</code></pre> <p>Note: The option -uNEAR specifies a seeding scheme that is good for finding strong similarities. It is used here instead of the default YASS seeding scheme, as we are comparing two subspecies and therefore very similar sequences.</p> <p>Step 3. Define an optimal scoring matrix. This is optional, as LAST can work with a default matrix or with one of the matrices provided. The command last-train will find suitable substitution and gap scores for aligning the two sequences provided by using an iterative procedure:</p> <pre><code>last-train HAV3_1Db AMelMel_1.fa &gt; score_matrix.mat\n</code></pre> <p>Step 4. Align the query to the target:</p> <pre><code>lastal -p score_matrix.mat HAV3_1Db AMelMel_1.fa &gt; HAv_Amel.maf\n</code></pre> <p>Note: The option -p score_matrix.mat specifies the score matrix prepared with last-train. Any built-in score matrix proposed by LAST can be used.</p> <p>Step 5. Plot the original alignment results.We will only plot the alignment of chromosomes 7 (NC_037644.1 in the HAv3.1 genome and CM010325.2 in the AMelMel genome) (Figure 7A). The next steps will aim at finding a unique best alignment.</p> <pre><code>last-dotplot -1 NC_037644.1 -2 CM010325.2 HAV3_1_AMelMel1_1.maf plot_chr7.png\n</code></pre> <p>Step 6. Finding unique best hits for the query. At this point, any sequence segment in the query can have several alignments in the target. The command last-split will read the candidate alignments of the query sequences, and looks for a unique best alignment for each part of each query.</p> <pre><code>last-split HAV3_1_AMelMel1_1.maf &gt; HAV3_1_AMelMel1_1_split1.maf\n</code></pre> <p>Step 7. Finding unique best hits for the target. As the sequence segments in the target HAv3.1 genome can also have several alignments in the query, query and target are inverted in the file, and last-split is run again:</p> <pre><code>maf-swap HAV3_1_AMelMel1_1_split1.maf | last-split &gt; HAV3_1_AMelMel1_1_split2.maf\n</code></pre> <p>Step 8. Plot the polished alignment results (Figure 7B).</p> <pre><code>last-dotplot -2 CM010325.2 -1 NC_037644.1 HAV3_1_AMelMel1_1_split2.maf plot_chr7.png\n</code></pre> <p></p>"},{"location":"Section_4_4/#figure-7-example-plots-a-one-major-inversion-is-detected-between-the-two-assemblies-the-many-dots-off-the-diagonal-are-due-to-sequences-that-are-repeated-and-having-therefore-several-reciprocal-hits-b-each-region-of-one-genome-is-now-aligned-to-at-most-one-region-of-the-other","title":"Figure 7. Example plots. A) One major inversion is detected between the two assemblies. The many dots off the diagonal are due to sequences that are repeated and having therefore several reciprocal hits. B) Each region of one genome is now aligned to at most one region of the other.","text":""},{"location":"Section_4_5/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_5/#45-genome-wide-association-studies","title":"4.5. Genome-wide association studies","text":"<p>Genome-wide association studies (GWAS) are conducted to detect genetic markers that contribute to phenotypic variation between individuals by analyzing phenotypic and genomic information in a unified statistical model (Figure 8). This type of analysis is commonly conducted in livestock species and plants, and an extensive literature and collection of tools, software, and methodologies are available for this purpose (for a review in animal genetics, see Hayes &amp; Goddard (2010)). In this section, we will discuss GWAS in the context of honey bee studies, considering the unique attributes of this species.</p> <p></p>"},{"location":"Section_4_5/#figure-8-generic-structure-of-a-gwas-model-adapted-from-yu-et-al-2006","title":"Figure 8. Generic structure of a GWAS model (adapted from (Yu et al., 2006)).","text":""},{"location":"Section_4_5/#451-considerations-for-phenotypic-data","title":"4.5.1. Considerations for phenotypic data","text":"<p>Many different phenotypes or observations are compatible with GWAS. Examples for Apis honey bees include, but are not limited to:</p> <ul> <li> <p>Traits of agronomic interest, such as honey production, gentleness, or low propensity to swarm</p> </li> <li> <p>Traits linked to phenotypic plasticity and social behavior, such as precocious forager age</p> </li> <li> <p>Traits linked to morphology, such as pigmentation or wing venation</p> </li> <li> <p>Traits linked to survival, such as resistance to parasites (Varroa spp., Tropilaelaps spp., small hive beetle), to viruses, or to specific environmental conditions</p> </li> <li> <p>Traits linked to the colony or individual health, such as viral or bacterial load</p> </li> <li> <p>Traits focusing on genome structure, such as variable recombination rate</p> </li> </ul> <p>Ideally, these characteristics should be measured in a standard way across all the \u2018individuals\u2019 or \u2018units\u2019 (e.g., colony, caste, or single bee specimen). Measuring traits at the superorganism unit (colony) or at individual levels can be more or less relevant depending on the trait of interest. Traits can be binary, as in a case/control association study (e.g., survival, presence or absence of a virus, performance or not of behavior, etc.), categorical (e.g., gentleness scored in classes), or continuous (e.g. honey production measured in kilograms). If focusing on a continuous phenotype, it is necessary to analyze individuals representing the whole expected spectrum to distinguish markers impacting the phenotype.</p>"},{"location":"Section_4_5/#452-considerations-for-sample-selection","title":"4.5.2. Considerations for sample selection","text":"<p>GWAS can be performed on individual samples or composite samples of individuals from the same colony (see Section 4.2 for details on ploidy considerations). Individual samples can represent different colonies or, when more than one individual per colony is sampled, individuals within a colony. These samples may be workers, queens, or drones. For any sample type, an appropriate sample size should be estimated to ensure the analysis has sufficient power to detect associations.</p>"},{"location":"Section_4_5/#4521-power-analysis","title":"4.5.2.1. Power analysis","text":"<p>Prior to performing a case/control association study, it is useful to estimate the power needed to detect significant markers given a specific experimental design. Such power of detection is linked to the number of individuals in the case versus control group, the number of markers tested and the difference in allele frequency between the two groups. The R package pwr is strictly dedicated for power analysis functions (Champely et al., 2017, 2018).</p>"},{"location":"Section_4_5/#453-materials","title":"4.5.3. Materials","text":""},{"location":"Section_4_5/#4531-computational-resources","title":"4.5.3.1. Computational resources","text":"<p>GWAS requires at least a computer (for small studies), up to a high-performance cluster (for large studies). Specific informatic tools such as R or other dedicated software programs (discussed below) for data manipulation, statistical analysis, and visualization are also needed.</p>"},{"location":"Section_4_5/#4532-genotypic-and-phenotypic-data","title":"4.5.3.2. Genotypic and phenotypic data","text":"<p>Genomic information can be found traditionally in the form of a genotype matrix extracted from VCF files, where different genotypes are specified as 0, 1 and 2. Alternative formats, such as allele frequencies, are also becoming more and more common and highly useful for honey bee genomic studies. A matrix linking phenotypic observations to sample identifiers will also be needed.</p>"},{"location":"Section_4_5/#454-methods","title":"4.5.4. Methods","text":""},{"location":"Section_4_5/#4541-preparation-of-phenotypic-data","title":"4.5.4.1. Preparation of phenotypic data","text":"<p>Classical GWAS methods rely on the assumption that the phenotype of interest follows a normal distribution. Therefore, depending on the trait, corrections such as log, logit, square-root, cube root or, empirical Bayes might be needed to adjust the phenotype distribution to the assumed normality. Unfortunately, as corrections need to be tested independently, no standard protocol can be described here.</p> <p>We present below an example of an R script to perform empirical Bayes correction with beta distribution (Figure 9A). The beta distribution is often used for empirical Bayes correction as the variety of alpha and beta parameters defining the distribution allow for a large range of probability density functions representing most of the observed distribution for ratios and proportions (Figure 9B).</p> <pre><code>library(MASS) #Load library\ndf$pheno = df$num / df$den #estimation of the phenotype as a ratio of num (numerator) on den (denominator)\neb_fit = fitdistr( x = df$pheno[ !is.na(df$pheno) &amp; df$pheno &gt; 0 &amp; df$pheno &lt; 1 ], densfun = \"beta\", start = list(shape1 = 1, shape2 = 1), method = \"L-BFGS-B\" ) #fit of beta distributions to the estimated phenotype\naprior = eb_fit$estimate #alpha parameter for the beta distribution estimate for our phenotype\nbprior = eb_fit$estimate #beta parameter for the beta distribution estimate for our phenotype\ndf$pheno_eb = (aprior + df$num) / (aprior + bprior + df$den) #corrected phenotype\n</code></pre> <p></p>"},{"location":"Section_4_5/#figure-9-correcting-phenotypic-parameters-a-example-distribution-of-phenotypic-values-before-and-after-correction-using-the-empirical-bayes-method-b-example-of-the-histogram-for-a-phenotype-before-and-after-empirical-bayes-transformation-note-the-improved-distribution-after-transformation","title":"Figure 9. Correcting phenotypic parameters. A) Example distribution of phenotypic values before and after correction using the empirical Bayes method. B) Example of the histogram for a phenotype before and after empirical Bayes transformation. Note the improved distribution after transformation.","text":""},{"location":"Section_4_5/#4542-preparation-of-genotypic-data","title":"4.5.4.2. Preparation of genotypic data","text":"<p>Prior to running a GWAS analysis, we recommend performing a quality control analysis on the genotypes (Wragg et al., 2021). Depending on your data, these quality controls can be based on:\\</p> <ul> <li> <p>Technical and sequencing characteristics such as genotyping quality (QUAL &gt; 200 and QD &gt; 20), depth (20x), or even calling rate (&gt; 95%).</p> </li> <li> <p>Minor allele frequencies (MAF &gt; 0.05), or rare variants, are much harder to test accurately than common ones. Depending on the read coverage, rare variants are likely associated with genotyping errors and are often removed without further considerations.</p> </li> <li> <p>Linkage disequilibrium (LD), as assumed for the GWAS models, relies on the independence of the tested markers; therefore, one might want to filter on a LD threshold. Doing so will remove redundancy in the genomic information and might strengthen the signal for some markers of interest.</p> </li> </ul>"},{"location":"Section_4_5/#4543-performing-gwas-methods-and-software","title":"4.5.4.3. Performing GWAS: Methods and software","text":"<p>Multiple software and packages are available to perform GWAS easily from genomic data (for a partial listing, see in GWAS tools platform). One standard and popular software is PLINK (Purcell et al., 2007). It contains a large panel of functions from data manipulation and filtering to GWAS analysis, making it a preferred tool for analyzing individual diploid data. PLINK is compatible with binary phenotype variables (case/control) as could be expected for, e.g., survival. In such a case, standard chi-square analysis on each marker individually can be used. This test gives test statistics and p-values for the difference in allele frequency between the case and control group. See Section 4.7 for more information on using PLINK.</p> <p>However, in Apis honey bee colonies, traits are often measured at the group level, making pooled-sample genotype information (e.g. allele frequencies or mean genotypes) more relevant. To deal with such data types, we list some tools that have been adapted to be able to analyze pooled data. We recommend using GEMMA for analyzing pooled-sample data (Zhou &amp; Stephens, 2012), which allows for mixed linear models as well as Bayesian inference. For small datasets (hundreds of samples), the LDAK (Speed et al., 2012) software might be more suitable for performing GWAS. Additionally, LDAK also offers potential GWAS computation based on gene annotation rather than genotypes. This allows a straightforward interpretation of the functional effect, since only differences within annotated genes are detected, and reduces the number of statistical tests performed. While new tools are continuously developed to perform GWAS with different settings and data types, the field still lacks dedicated methods that can deal specifically with honey bees and haplodiploidy.</p>"},{"location":"Section_4_5/#4544-detecting-signatures-of-selection","title":"4.5.4.4. Detecting signatures of selection","text":"<p>Although it is not solely restricted to association studies, detecting selection signals (i.e. stabilizing selection, directional selection, and diversifying selection) is of significant interest in honey bee genetic analysis to assign selection signals along the genome for specific traits (also known as phenomics). Several software options are available for this purpose, such as FLK and hapFLK (Bonhomme et al., 2010; Fariello et al., 2013). The use of such methods has helped characterize soft selective sweep in Africanized honey bees in invasive areas (Avalos et al., 2017), through a temporal sampling in native Swiss populations (Parejo et al., 2020) and in association with beekeeping practices (Wragg et al., 2016). Avalos et al., (2017) have curated customs bash and R scripts available as supplemental notes, which we recommend as a reproducible workflow using RsB for any users who want to start such analysis with honey bee samples (Tang et al., 2007).</p>"},{"location":"Section_4_5/#455-sources-of-variation","title":"4.5.5. Sources of variation","text":"<p>Population structure might need to be accounted for by adding covariates in the GWAS model. Such covariates can come from genetic background information (vectors of genetic admixture, commonly called Q vectors), principal component analysis eigenvalues for population structure, environmental effects such as the apiary, effects linked to the beekeeping practice (see Section 4.6 on population genomics). In addition, a kinship matrix (the relationship between individuals) can be included in the model. This matrix can be estimated based on pedigree records (Brascamp &amp; Bijma, 2014), though it is often challenging for honey bees to have complete genetic records. In Apis honey bees, it is especially interesting to consider such a matrix, as relationships across individuals within a colony deviate from standard estimates in diploid livestock species. The software LDAK offers additional features. One such feature is the possibility of computing genetic relationship matrices (GRMs) from weighted polymorphisms, which is equivalent to trimming our genomic information based on linkage disequilibrium, as suggested in Section 4.5.4.2.</p> <p>In case/control association studies, rigorous experimental design is advantageous, in the sense that matching case and control individuals according to environmental conditions, genetic background, etc., will authorize the researcher to ignore these variables in the analysis.</p>"},{"location":"Section_4_5/#456-quality-control-and-data-interpretation","title":"4.5.6. Quality control and data interpretation","text":"<p>To validate that the GWAS performed matches the model hypotheses, we recommend running multiple diagnostic analyses. The most common diagnostic is to draw the Q-Q plot for p-values of the GWAS using R. This method allows us to check for an agreement between expected and observed p-values. If a deviation from the expectation is observed, this is a sign of improper fit of the model to the data. This generally indicates that either the phenotype is not properly modeled or that population stratification or structure is not accounted for in the GWAS model. A strong deviation from the diagonal in Q-Q plot (Figure 10A) should lead to further investigation and repetition of the GWAS. Another diagnostic approach can be performed on p-values, as they are expected to follow a uniform distribution. Therefore, checking the histogram of p-values is a relevant diagnostic plot for a good fit of the model (Figure 10B). Finally, checking for unexpected correlations between SNP effects and allele frequencies can inform on misfit of the model or of errors in our data set (Figure 10C).</p> <p></p>"},{"location":"Section_4_5/#figure-10-example-diagnostic-plots-for-gwas-study-a-q-qplot-and-associated-inflation-factor-b-histogram-of-the-p-values-and-c-plot-of-snp-effects-as-a-function-of-allele-frequencies","title":"Figure 10. Example diagnostic plots for GWAS study. A) Q-Qplot and associated inflation factor \u03bb, B) histogram of the p-values and C) plot of SNP effects as a function of allele frequencies.","text":"<p>After validation of the study based on the diagnostic plots presented above, we recommend looking into the markers\u2019 p-values and effects. The decision on the significant threshold cut-off for the markers associated with a trait of interest is crucial (often between 1 and 5%). Traditional corrections for multiple testing, such as Bonferroni, can be used but are often too stringent and might cause one to ignore relevant markers. For GWAS, controlling the false discovery rate (FDR) is a standard approach. Recently more methods, like ash (Stephens, 2016), are less conservative and better adapted to complex phenotypes. This method expects phenotypes to be highly polygenic with most markers having a negligible effect on the phenotype itself, as can be anticipated for complex honey bee traits. Recent developments have also made it possible to combine multiple analyses on different populations or even phenotypes using the software Mantra and Mr Mega (Morris, 2011) or Mash (Urbut et al., 2019).</p> <p>Once diagnostic tests are completed, it is time to interpret the effects of the markers, if identified, to describe the genotype/phenotype association. In some studies, a few markers may be detected with large and highly significant effects. In this case, the markers are strong candidates to explain the causal mutation underlying the trait. More often, many markers are detected, having small but significant effects. This is often the case in complex traits that tend to be highly polygenic. If markers are identified, the final step is to inspect the genomic regions of interest and identify candidate causal genes to try to interpret the biological pathways involved.</p>"},{"location":"Section_4_5/#457-applications-and-limitations","title":"4.5.7. Applications and limitations","text":"<p>The pinnacle goal of GWAS is to identify genetic underpinnings of specific characteristics. The possibilities of traits to focus on are endless, but to date, association studies in honey bees have focused mostly on traits linked to beekeeping practices (Guichard et al., 2021), disease or parasite resistance (Sp\u00f6tter et al., 2016), and health (Wu et al., 2020). In other studies, genome-wide scans have been used to identify selection signals for population-specific features such as royal jelly production (Wragg et al., 2016). Although genetic markers for specific traits were first identified through quantitative trait loci (QTL) mapping (see Evans et al. (2013) for a description of this technique), the technique has fallen out of favor as high-throughput sequencing has become more accessible.</p> <p>Performing GWAS on honey bees can be challenging because the breeding system often makes the colony, which has a diverse genetic makeup, the unit of interest. Moreover, limitations arise whenever divergent and structured populations in honey bees are analyzed together without being properly accounted for in the GWAS model. For example, if bees belonging to different subspecies are analyzed together for a phenotype, the markers identified might be representatives of the different genetic types rather than linked to the phenotype of interest. This can also impact comparative genomics studies (see Section 4.4) and can lead to misguided interpretations of mechanisms underlying traits of interest.</p> <p>On top of estimating the effects and significance of targeted markers associated with a trait, it is also possible to evaluate trait heritability with GWAS (Brascamp &amp; Bijma, 2019; Guichard et al., 2021; Jourdan-Pineau et al., 2021). Such heritability measures are population-specific and might vary across studies focusing on different individuals and environments. Furthermore, genomic heritability estimates in honey bees might differ from pedigree heritability estimates, as they are not straightforward to approximate due to haplodiploidy and multiple mating (Jourdan-Pineau et al., 2021). Such heritability information is particularly useful for guiding selective breeding programs.</p> <p>So far, few research projects report genome wide association study results in honey bees but have already informed on genomic regions associated with aggressive behavior (Avalos et al., 2020; Guichard et al., 2021; Sokolowski, 2020), adaptation to mountainous environments (Everitt et al., 2023), and disease tolerance (Hassanyar et al., 2023). With the increasing availability of genomic data, due to reduction in sequencing costs and improved availability of genotyping chips, we can expect a growth in this field.</p> <p>However, genome wide association studies in honey bee genomics may still face major challenges. Honey bee genomic data can have high complexity, as it may be derived from workers, drones, or pools of individuals, and there is a lack of dedicated methods to perform GWAS in haplo-diploid organisms. Furthermore, many desirable phenotypes are scored at the colony level, necessitating pooled sampling. Many of these traits (e.g. behaviors) are also complex themselves, and can be highly polymorphic, conditional, and polygenic.</p> <p>Consequently, although efforts are underway (Grozinger &amp; Zayed, 2020), it has been exceedingly challenging for GWAS results to contribute to selection decisions in the form of genomic markers with strong prediction potential for traits of interest. GWAS may be better suited to understanding the biological mechanisms underlying traits of interest for honey bee research.</p>"},{"location":"Section_4_6/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_6/#46-population-genomics-experimental-design","title":"4.6. Population genomics: Experimental design","text":"<p>Whereas genome-wide association studies (GWAS) link SNPs to specific traits, population genomics identifies changes in the genetic composition of populations. To do this, population genomics analyzes hundreds to thousands, even millions, of markers (usually SNPs) across multiple individuals and populations to unravel microevolutionary patterns and processes. Due to the massive amounts of data that are typically generated by high-throughput sequencing or genotyping technologies, population genomics has evolved from classic population genetics (in which the number of markers was in the order of tens) to become a data-driven and computational science. It requires computational resources, memory, and expertise in bioinformatics due to the large-scale data generated in these studies.</p> <p>In honey bees, as in many other organisms, population genomics provides important insights into the bees\u2019 demographic and adaptive history (Chen et al., 2016; Cridland et al., 2017; Fuller et al., 2015; Harpur et al., 2014; Henriques, Browne, et al., 2018; Nelson et al., 2017; Wallberg et al., 2014) as well as into the genomic basis of important traits, such as tolerance to diseases and parasites (Saelao et al., 2020), royal jelly production (Rizwan et al., 2020; Wragg et al., 2016), as well as defensive, scouting and recruiting behaviors (Ari\u00e1n Avalos et al., 2020; Harpur et al., 2020; Southey et al., 2016).</p>"},{"location":"Section_4_6/#461-sampling-strategy","title":"4.6.1. Sampling strategy","text":"<p>When starting out a population genomics study, the first step is to design the sampling strategy. Before collecting the samples, several sampling-related aspects must be considered, including (i) sample sizes of individuals and markers, (ii) sample breadth, (iii) sampling design, (iv) sampling workers versus drones, and (v) sampling a single individual versus multiple individuals per colony. Final decisions are greatly constrained by the study's goals (e.g., estimating diversity within colonies or at the population level, inferring population structure, finding signatures of local adaptation, or landscape genomics), the complexity of the genetic patterns of the focal subspecies, and the budget available.</p>"},{"location":"Section_4_6/#4611-sample-sizes-of-individuals-and-markers","title":"4.6.1.1. Sample sizes of individuals and markers","text":"<p>Simulation studies have shown that population genetics inference (e.g., diversity, demographics, differentiation, or gene flow) is influenced by the sample sizes of markers and individuals (Aguirre-Liguori et al., 2020; Flesch et al., 2018; Foster et al., 2021; Landguth et al., 2012). While increasing both simultaneously produces more robust estimates, empirical and simulation studies have consistently shown that the accuracy benefits far more from increasing the number of markers than the number of individuals (Landguth et al., 2012; Nazareno et al., 2017; Willing et al., 2012).</p> <p>To the best of our knowledge, there are no simulation studies on the optimal sample sizes for population genetics or genomics inquiries in honey bees. However, inferring from studies on other organisms, when the number of markers is in the order of hundreds to thousands (which is becoming commonplace in the post-genomics era) around eight individuals per population suffice for accurate estimates of diversity and differentiation (Aguirre-Liguori et al., 2020; Flesch et al., 2018; Hongran Li et al., 2020; Nazareno et al., 2017).</p> <p>However, in honey bee studies, sample sizes have typically been larger. These have ranged from n = 9 to 87 individuals per group in population genomics studies Avalos et al., 2020; Chen et al., 2016; Harpur et al., 2014; Henriques, Wallberg, et al., 2018; Nelson et al., 2017; Wallberg et al., 2014; Wragg et al., 2016) and from n = 12 to 117 when developing SNP assays (Chapman et al., 2015; Henriques, Parejo, et al., 2018; J. C. Jones et al., 2020).</p> <p>While empirical evidence from honey bee studies is lacking, the optimal number of sampled individuals will certainly vary among subspecies, depending on their distributional range or evolutionary complexity (Henriques, Parejo, et al., 2018). For example, the optimal sample size for A. m. ruttneri, a subspecies confined to the small island nation of Malta, is expected to be much smaller than that of A. m. mellifera, a subspecies with one of the greatest geographical distributions, or of A. m. iberiensis, a subspecies with a complex history involving natural hybridization. Finally, it is also important to keep in mind that unequal population samples can impact the outcomes of some analytical approaches, such as inferences on population structure (Puechmaille, 2016).</p>"},{"location":"Section_4_6/#4612-sample-breadth","title":"4.6.1.2. Sample breadth","text":"<p>In addition to the sample size, when sampling honey bees for population genomics studies, it is also important to consider the number of sampled populations, or breadth (coverage of distributional range), which can influence inferences for classic population genetics as well as landscape genetics or outlier tests (Aguirre-Liguori et al., 2020; Albert et al., 2010; Nazareno et al., 2017; Schwartz &amp; McKelvey, 2009). In honey bees, Henriques et al. (2018) showed that sampling a geographically restricted area within the A. m. iberiensis distributional range would erroneously identify a set of SNPs with the fixation index between this and C-lineage subspecies equal to one (F~ST~ = 1), with an impact on the design of reduced panels of highly informative SNPs. This is because the true F~ST~ values are \\&lt; 1, meaning that the SNPs are not diagnostic anymore and therefore have a lower information content. When the goal of the study is to find genomic evidence of local adaptation, it is critical to ensure that populations (or individuals) are sampled across environmental gradients (e.g., latitudinal or altitudinal) and environments (e.g., arid and humid), for increased power in detecting outlier SNPs and therefore candidate genes (Manel et al., 2012).</p>"},{"location":"Section_4_6/#4613-sampling-design","title":"4.6.1.3. Sampling design","text":"<p>The sampling design will depend on the individuals' spatial distribution and the study's goal, among other factors (Paradis, 2020). For example, if the goal is to find signatures of selection in honey bee populations, sampling should cover environmental gradients. When sampling encompasses pairs of populations that maximize the environmental differences while minimizing the evolutionary differences, there is great potential for detecting selection footprints (Delaneau et al., 2012; Lotterhos &amp; Whitlock, 2015). This approach was followed in a study of honey bee adaptation to altitude in East Africa (Wallberg et al., 2017). By sampling two pairs of populations representing mountain forests and lowland savannahs, the authors could detect strong candidates for adaptation to highland habitats in whole-genome scans.</p> <p>Several sampling designs can be used by honey bee researchers. For continuously distributed populations, random and systematic sampling designs (e.g., transects or grids) have proven to be effective in simulation studies (Oyler-McCance et al., 2013). The systematic design was implemented in Iberia to unravel the genetic diversity patterns and underlying processes of A. m. iberiensis, via the establishment of three north-south transects. With this design, the authors uncovered a secondary contact zone in Iberia and found evidence for selection as another evolutionary force shaping complex genetic patterns in A. m. iberiensis (Ch\u00e1vez-Galarza et al., 2013, 2015; Henriques, Wallberg, et al., 2018). If, on the other hand, the distribution is patchy, cluster sampling (sampling several groups of individuals) is more appropriate (Oyler-McCance et al., 2013).</p>"},{"location":"Section_4_6/#4614-sampling-workers-versus-drones","title":"4.6.1.4. Sampling workers versus drones","text":"<p>The choice of sampling workers (diploid) over drones (haploid) will depend on the questions being addressed and, thereby, on the type of analyses that will be performed (see Section 4.2 for more on general ploidy and pooling considerations). For example, Hardy-Weinberg Equilibrium (HWE) testing can only be done with individual diploid workers. However, there are analyses that do not require testing for HWE, and in this case, using haploid data can be advantageous. In addition to reducing sequencing costs, drones generate phased data, thereby circumventing the hurdles of statistical phasing. Phased genomic data offers increased power for detecting selection signatures by facilitating the employment of haplotype-based methods.</p>"},{"location":"Section_4_6/#4615-sampling-a-single-individual-versus-multiple-individuals-per-colony","title":"4.6.1.5. Sampling a single individual versus multiple individuals per colony","text":"<p>Classic population genetics analysis (e.g., HWE, diversity, differentiation, structure) requires sampling one single diploid worker per colony. This approach circumvents the problem of over-representing the queen\u2019s genotype and violating the assumption of sample independence by sampling multiple individuals. However, when the study addresses questions at the intra-colony level (e.g., patriline analysis, colony structure), sampling multiple individuals is an unavoidable requirement. The number of sampled individuals per colony can vary, depending on the questions being addressed and on budget limitations. For example, the numerous studies published in the pre-genomics era, which required patriline analysis, typically sampled tens of workers per colony (61 \u00b1 72.6; see the review of Tarpy et al. (2004)). When multiple individuals are sampled from within a colony, they have historically been genotyped separately, but pooling is becoming increasingly popular in the post-genomics era (see Section 4.2).</p>"},{"location":"Section_4_7/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_7/#47-population-genomics-filtering-and-summary-statistics-using-plink","title":"4.7. Population genomics: Filtering and summary statistics using PLINK","text":"<p>In this section, we will describe some tools available for analyzing SNPs (the most common type of genetic variation used in genomic studies) using a population genomics framework. We will employ a VCF tutorial file containing 3,669,288 SNPs obtained after the variant calling of 33 individuals, 26 of which are of M-lineage ancestry (18 A. m. iberiensis and eight A. m. mellifera) and seven are of C-lineage ancestry (three A. m. carnica and four A. m. ligustica).</p> <p>The first step in any population genomics study is understanding and filtering the dataset by calculating summary statistics to evaluate missing data, allele frequencies, or linkage disequilibrium. To that end, several tools tailored for handling whole-genome data are publicly available, including VCFtools (Danecek et al., 2011), PLINK (Purcell et al., 2007), and several R packages such as pegas (Paradis, 2010) and PopGenome (Pfeifer et al., 2014). Here, we chose the highly versatile and efficient PLINK tool to illustrate the steps involved in filtering and in producing summary statistics for whole-genome datasets.</p> <p>PLINK is a command-line software that runs on different operating systems such as Linux, Microsoft DOS, and macOS. Additionally, instead of using command lines, one can also use an interface through the program gPLINK, although this is only available for the most commonly-used commands. In this section, we will go over some of the basic commands that can be carried out with PLINK (version 1.9).</p>"},{"location":"Section_4_7/#471-download-and-installation","title":"4.7.1. Download and installation","text":"<p>First, download PLINK 1.9 (www.cog-genomics.org/plink2/) and the tutorial dataset called pop_gen, which can be found on github.com/MaevaTecher/standard-methods-apis-omics. All the commands will be typed at the command prompt. To check that PLINK is installed, type \u201c./plink\u201d on the command prompt, and some information about the PLINK, like its version and examples of flags, will be printed.</p>"},{"location":"Section_4_7/#472-input-format-and-conversion","title":"4.7.2. Input format and conversion","text":"<p>PLINK can operate with various input formats, the most common are regular PLINK TXT files, PLINK 1 binary BIM file, and variant call format (either VCF or BCF). PLINK 1 binary is the preferred input format because PLINK automatically converts the other formats to this one to save time and space. There are commands for converting the formats to each other. We will explain the most common files and provide the command line to convert them to others.</p>"},{"location":"Section_4_7/#4721-variant-call-format-vcf","title":"4.7.2.1. Variant call format (VCF)","text":"<p>Genome sequence data is very often represented in the variant call format (VCF) or its binary counterpart (bcf). The following command can be used to convert vcf into the PLINK 1 binary format:</p> <pre><code>plink --vcf pop_gen.vcf \\\n--keep-allele-order \\\n--allow-extra-chr \\\n--make-bed \\\n--out pop_gen\n</code></pre> <p>The meanings of the flags are the following:</p> <p><code>--vcf</code> specifies that we are using a .vcf.gz file.</p> <p><code>--keep-allele-order</code> specifies that the reference allele will be in the 6th column (A2) and the alternate allele in the 5th column (A1). If we do not use this flag PLINK will reorder the alleles, and in A1 and A2 columns will be the minor and major alleles, respectively.</p> <p><code>--allow-extra-chr</code> indicates that chromosome code does not start with a digit.</p> <p><code>--make-bed</code> specifies that PLINK1 binary files should be generated.</p> <p><code>--out</code> specifies the output name. If one does not use <code>--out</code>, PLINK will call the file \u2018plink\u2019, for instance \u2018plink.bed\u2019.</p> <p>If there are no errors, four files will be created: pop_gen.bed, pop_gen.bim, pop_gen.fam and pop_gen.log. The pop_gen.log file contains the command and other information that was printed to the console. The other files are explained below.</p>"},{"location":"Section_4_7/#4722-plink-1-binary-format-bim","title":"4.7.2.2. PLINK 1 binary format (.bim)","text":"<p>To work with PLINK 1 binary format, the three following files (pop_gen.fam, pop_gen.bim, and pop_gen.bed) will be needed:</p> <p>1.  pop_gen.fam: Contains the sample information and has the following fields:</p> <ul> <li> <p>Family ID (If unknown, use the individual ID)</p> </li> <li> <p>Individual ID (Alphanumeric ID to uniquely identify an individual and cannot be \u20180\u2019)</p> </li> <li> <p>Paternal ID (If unknown, use \u20180\u2019)</p> </li> <li> <p>Maternal ID (If unknown, use \u20180\u2019)</p> </li> <li> <p>Sex code (Use '1' if male, '2' if female, '0' if unknown)</p> </li> <li> <p>Phenotype value (Use '1' if control, '2' if case, if not used set to \u20180\u2019)</p> </li> </ul> <p>2.  pop_gen.bim: Contains the variant information and has the following columns:</p> <ul> <li> <p>Chromosome (It should be a digit, otherwise one needs to use the flag --keep-allele-order)</p> </li> <li> <p>Variant identifier (Can contain any character, except spaces, tabs or \u2018*\u2019)</p> </li> <li> <p>Genetic distance in morgans or centimorgans (Can be set at \u20180\u2019)</p> </li> <li> <p>Base-pair coordinate (Positive integers in bp)</p> </li> <li> <p>Allele 1-A1 (Contains the less common allele or the alternate allele)</p> </li> <li> <p>Allele 2-A2 (Contains the most common allele or the reference allele)</p> </li> </ul> <p>3)  pop_gen.bed: Binary biallelic genotype data.</p> <p>To convert PLINK 1 binary format to VCF, one can use the following command:</p> <pre><code>plink --bfile pop_gene \\\n--recode vcf \\\n--out pop_gene\n</code></pre> <p><code>--bfile</code> specifies that we are using PLINK 1 binary format.</p> <p><code>--recode vcf</code> specifies to create a VCF file as an output.</p> <p><code>--out</code> specifies the output name.</p> <p>Note: To do this conversion, one needs to be sure that in PLINK 1 binary format, the reference alleles are located in the 6^th^ column (A2).</p>"},{"location":"Section_4_7/#4723-regular-plink-text-files","title":"4.7.2.3. Regular PLINK text files","text":"<p>The regular PLINK text files are formed by the PED and MAP files. The PED file is a white-space delimited file that stores the genotype calls. It contains six mandatory fields/columns which correspond to the file.famfields. After these columns, the PED file is followed by 2 (number of variants) columns with the genotype of each locus in the same order as in the MAP file. The MAP file contains the variant information corresponding to the first four columns of pop_gene.bim.</p> <p>The MAP file should have the same root name as the PED file and contain the same number of loci. For instance, if there are genotypes for 10 loci and 12 individuals, the MAP file will contain 10 lines and four columns, and the PED file will contain 12 lines and 26 columns (10 loci *2 + 6 mandatory columns). The loci in the PED file do not have to comply with the genomic order, but they must be in the same order as in the MAP file.</p> <p>To convert PLINK 1 binary format to regular PLINK text file, one can use the following command:</p> <pre><code>plink --bfile pop_gene \\\n--recode \\\n--out pop_gene\n</code></pre> <p>To convert a regular PLINK text file to 1 binary PLINK file, the following command can be run:</p> <pre><code>--make-bed \\\n--out pop_gene\n</code></pre> <p>If there are no errors, four files will be created: pop_gene.bed, pop_gene.bim, pop_gene.fam, and pop_gene.log.</p>"},{"location":"Section_4_7/#4724-filtering-and-handling-missing-data","title":"4.7.2.4. Filtering and handling missing data","text":"<p>It is common for genome-wide datasets to have individuals or variants with missing data. This is particularly frequent and expected in low-coverage sequencing data. PLINK allows us to estimate the missing data per individual and loci using the flag --missing. A report containing the missing data per Individual ID (pop_gen.imiss) and variant (pop_gen.lmiss) can be created using the following command:</p> <pre><code>plink --bfile pop_gen --missing --out pop_gen\n</code></pre> <p>It is highly recommended to discard individuals or variants with high levels of missing data. The missing data thresholds are arbitrary, but values of 10% to 30% are commonly used in the literature (Henriques, Wallberg, et al., 2018; Melanie Parejo et al., 2016; Wallberg et al., 2014; Wragg et al., 2016). To remove the variants with &gt; 20% missing data (--geno 0.2) and individuals with &gt;10% missing data (--mind 0.10), for example, the following command can be run:</p> <pre><code>plink --bfile pop_gen \\\n--geno 0.2 \\\n--mind 0.1 \\\n--make-bed \\\n--out pop_gen_MD \n</code></pre> <p>After implementing this command, a PLINK 1 binary fileset, with the root name of \u201cpop_gen_MD\u201d, without the problematic individuals and loci, will be created. Note that PLINK first removes individuals with too much missing data, and secondly the variants.</p>"},{"location":"Section_4_7/#4725-computing-and-filtering-based-on-allele-frequency","title":"4.7.2.5. Computing and filtering based on allele frequency","text":"<p>PLINK calculates allele frequencies and filters variants with a minor allele frequency (MAF) lower than an arbitrary threshold, which is commonly set at 1% or 5%. To generate a report (pop_gene_MD.frq) containing allele frequencies for each variant, the following command can be run:</p> <pre><code>plink --bfile pop_gen_MD \\\n--freq \\\n--out pop_gen_MD \n</code></pre> <p><code>--freq</code> specifies calculating the allele frequency for each variant from this dataset.</p> <p>In the report generated using this command, the first and second columns contain the chromosome and the variant ID followed by the code of the minor (3^rd^ column) and major (4^th^ column) variants and the frequency of the minor allele (5^th^ column). The last column (6^th^) contains the number of allele observations.</p> <p>To remove the variants with MAF &lt; 5%, for instance, and create a new file set (here called pop_gen_MD_maf005), the following command can be run:</p> <pre><code>plink --bfile pop_gen_MD \\\n--maf 0.05 \\\n--make-bed \\\n--out pop_gen_MD_maf005 \n</code></pre> <p><code>--maf</code> specifies that only alleles with a minimum minor allele frequency of 5% will be kept in the dataset.</p>"},{"location":"Section_4_7/#4726-computing-differentiation-indices-wrights-fst","title":"4.7.2.6. Computing differentiation indices: Wright's F~ST~","text":"<p>PLINK also allows calculating the fixation index F~ST~ values for each variant using the Weir and Cockerham method (Weir &amp; Cockerham, 1984). To do so, the flag --fst must be combined with the flag --withinfollowed by the name of the file that specifies the sets of subpopulations to be used. In the tutorial example, the within the file, called within_M_C_ind, contains the Family ID in the first column, the Individual ID in the second column, and in the third column the digit 1 to identify one subpopulation (here the C-lineages subspecies) and 2 to identify the second subpopulation (here the M-lineage subspecies).</p> <p>To calculate the variants\u2019 F~ST~ values between M and C-lineage, the following command can be run:</p> <pre><code>plink --bfile pop_gen_MD_maf005 \\\n--fst --within within_M_C_ind \\\n--out pop_gen_MD_maf005\n</code></pre> <p>A report called pop_gen_MD_maf005.fst will be generated. This report contains six columns. The first three columns contain the chromosome number, the variant ID, and the base-pair coordinates, followed by the number of called variants or non-missing genotypes (NMISS), and the 5^th^ column contains the F~ST~ values.</p>"},{"location":"Section_4_7/#4727-estimating-linkage-disequilibrium","title":"4.7.2.7. Estimating linkage disequilibrium","text":"<p>Linkage disequilibrium (LD) is the non-random association of alleles at different loci. When working with whole-genome data there will be thousands of loci that are in linkage disequilibrium due to different evolutionary forces, but also, because they are physically linked. Some analyses require the use of loci that are in linkage equilibrium (not associated), and PLINK provides an easy way to do so, for example, by using the following command:</p> <pre><code>plink --bfile pop_gen_MD_maf005 \\\n    --indep-pairwise 50 \n</code></pre> <p>The flag <code>--indep-pairwise</code> requires three parameters: the window size, the number of SNPs to shift each step and r^2^. The values of r^2^ range between 0 and 1. When r^2^ = 1, the loci provide exactly the same information. When r^2^ = 0, the loci are in perfect equilibrium. Here, LD is calculated between each pair of SNPs using a window of 50 SNPs. If one pair of SNPs has r^2^ &gt; 0.5 one of them will be removed. After that, the window will be shifted to five SNPs, and the procedure is repeated until all SNP pairs are examined. Note that lower values of r^2^ and bigger window sizes will remove more loci.</p> <p>After running this command, two files will be created, one is named plink.prune.in, which contains the loci that will be retained (r^2^ &lt; 0.5), and the other one is named plink.prune.out, which contains the loci that will be discarded. These files can be used as arguments of the flags <code>--extract</code> (plink.prune.in) or --exclude (plink.prune.out).</p> <p>To extract to a new datafile the loci that are in the file plink.prune.in, the following command can be run:</p> <pre><code>plink --bfile pop_gen_MD_maf005 \\\n--extract plink.prune.in \\\n--make-bed \\\n--out pop_gen_MD_maf005_pruneddata \n</code></pre> <p>Sometimes we do not want to discard SNPs, but we want to calculate the LD in our data. LD can be computed using the flag <code>--r2</code>. However, to reduce the output size, only the pairs with r^2^ &gt; 0.2 and within a distance &lt; 1 Mb will be printed in the output by default. To modify these thresholds, the flag <code>--ld-window</code> or <code>--ld-window-kb</code> is used to specify the maximum distance between loci and the flag <code>--ld-window-r2</code> is used to specify the minimum r^2^. Using the following command, the r^2^ values will be obtained for all pairs of loci with r^2^ &gt; 0.5 in a window of 50 Kb. The output called pop_gen_MD_maf005_pruneddata.ld will be created, and the r^2^ values will be placed in the 7^th^ column.</p> <pre><code>plink --bfile pop_gen_MD_maf005_pruneddata \\\n--r2 \\\n--ld-window-kb 50 \\\n--ld-window-r2 0.5 \\\n--out pop_gen_MD_maf005_pruneddata\n</code></pre> <p><code>--r2</code> specifies to compute the linkage disequilibrium.</p> <p><code>--ld-window-kb</code> specifies the maximum distance between two loci in kilobases.</p> <p><code>--ld-window-r2</code> specifies the minimum r^2^ to be printed out.</p> <p>PLINK also allows haplotype blocks to be detected in the genome using the flag <code>--blocks</code>. If arguments are not provided to this flag, the default options will be implemented. One of them is related to the maximum block size, which is by default 20 kb. To cancel this default flag, the argument no-small-max-span can be used. The flag <code>--blocks</code> without arguments assumes that in the dataset, there are phenotypes in the 6^th^ column of the PED or FAM files. If there is no phenotype data, the argument no-pheno-req is required. By default, the pairwise LD is only calculated for variants within 200 kb. If needed, this parameter can be changed using the flag <code>--blocks-max-kb</code>. An example of a command to calculate blocks along the honey bee genome can be:</p> <pre><code>plink --bfile pop_gen_MD_maf005 \\\n--blocks no-pheno-req no-small-max-span \\\n--blocks-max-kb 5000 \\\n--out pop_gen_MD_maf005\n</code></pre> <p>Two files called pop_gen_MD_maf005.block and plink.blocks.det will be created. Each line of these files represents a block. The file pop_gen_MD_maf005.block contains the variant IDs found in each block whereas plink.blocks.det contains their positions. If there are 10 variant IDs or positions in one line, it means that the block contains 10 SNPs.</p>"},{"location":"Section_4_8/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_8/#48-population-genomics-inferring-population-structure-using-admixture","title":"4.8. Population genomics: Inferring population structure using ADMIXTURE","text":"<p>To study the genetic differences among individuals, a population structure analysis can be performed. Many analytical tools have different assumptions. The principal component analysis (PCA) makes the least number of assumptions and is suited for a preliminary data view. There are also clustering methods that estimate the proportion of ancestral populations in each individual. The software STRUCTURE (Pritchard et al., 2000) is the classical tool for structure analysis, however, it is not suited to large datasets. Examples of clustering methods that can handle large datasets are fastStructure (Raj et al., 2014), FRAPPE (H. Tang et al., 2005), and the widely used ADMIXTURE (Alexander et al., 2009). The results obtained with population structure analysis are necessary before performing more sophisticated analyses. However, the results should not be over-interpreted because different demographic scenarios may produce similar results. Here, we will show a protocol for running ADMIXTURE.</p> <p>ADMIXTURE (version 1.3) uses a maximum likelihood approach to estimate individuals\u2019 ancestry from multilocus SNP data. It requires unrelated individuals and does not explicitly consider LD, so we advise avoiding strong LD in the dataset.</p>"},{"location":"Section_4_8/#481-download-and-installation","title":"4.8.1. Download and installation","text":"<p>Download and install PLINK (see Section 4.7), the online tool CLUMPAK (Clustering Markov Packager Across K (Kopelman et al., 2015), and ADMIXTURE (version 1.3).</p>"},{"location":"Section_4_8/#482-input-files","title":"4.8.2. Input files","text":"<p>ADMIXTURE accepts PLINK and EIGENSTRAT files as inputs. Here, the binary 1 PLINK format will be used. Because of the ADMIXTURE assumptions, the file named pop gen_MD_maf005_pruneddata generated in Section 4.7 will be used. Note: In case the relatedness of the individuals under study is unknown, plink2 and the following command line can be run:</p> <pre><code>plink2 --bfile out_dataset \\\n--king-cutoff 0.177 \\\n--make-bed \\\n--out relpruned_data\n</code></pre>"},{"location":"Section_4_8/#483-methods","title":"4.8.3. Methods","text":"<p>ADMIXTURE estimates individuals\u2019 ancestry considering a specific number of source populations commonly denoted by K. ADMIXTURE can be run for a predefined K when the number of source populations is known. Here, K can be set at two because the individuals used in the tutorial are of M- and C- lineage ancestry). To run ADMIXTURE for K = 2, the following command can be run:</p> <pre><code>./admixture pop_gen_MD_maf005_pruneddata.bed 2 \n</code></pre> <p>Two files will be produced: the pop_gen_MD_maf005_pruneddata.2.Q, which contains the proportions of each cluster for each individual, and the pop_gen_MD_maf005_pruneddata.2.P, which contains the allele frequency of the source population for each SNP. However, commonly, the best K is unknown and should therefore be calculated. To do that, we should run ADMIXTURE for different Ks and use the flag --cv to enable the calculation of cross-validation errors. A way of doing that is through a bash command-line code, which we can call, for instance, CV.sh.</p> <p>Step 1. Create and open the file CV.sh:</p> <pre><code>nano CV.sh \n# or you can use any text editor such Vim\nvi CV.sh\n</code></pre> <p>Step 2. Write a script to run ADMIXTURE for different Ks (here from 1 to 8) and with the flag --cv:</p> <pre><code>#!/bin/bash -l\nfor K in {1..8} ; do \n./admixture --cv pop_gen_MD_maf005_pruneddata.bed ${K} \ndone \n</code></pre> <p>Step 3. Run the script created in step 2.</p> <pre><code>chmod +x CV.sh\n./CV.sh &gt;admixture.out\n</code></pre> <p>Step 4. In the file admixture.out we have everything that was printed on the console, but we want to have just the CV values. For that, we can use the following command:</p> <pre><code>grep \"CV\" admixture.out | awk '{print $3,$4}' | cut -c 4,7-20 &gt; admixture.cv.error\n</code></pre> <p>We can now use the cross-validation error values in the file admixture.cv.error to construct a plot (Figure 11A). The smaller the cross-validation error value, the better the prediction. In the tutorial example, K = 2 is the best, suggesting the existence of two source populations. However, choosing the best K can be a difficult endeavor, and another approach is to run different Ks and use the one that makes the most biological sense.</p> <p>In addition, to run different Ks we should also keep in mind that ADMIXTURE can produce different outcomes for replicate runs. A good practice is to perform several runs for each K with different random seeds (or starting points), which can be done using the flag -s time.</p> <p>In the tutorial example, ADMIXTURE will be executed 20 times for each K. To save all the runs, we must change the name of the outputs, a task that is performed by the command mv. This command will change the names by appending the K and the run number. For example, consider pop_gen_MD_maf005_pruneddata.4.10.Q is the 10^th^ result for K = 4.</p> <p>The script below should be written in a file called, for instance, running_admixture.sh. To run this, the same steps described for CV.sh should be performed.</p> <pre><code>#!/bin/bash -l\nfor RUN in {1..20} ; do\nfor K in {1..8} ; do\n./admixture -s time pop_gen_MD_maf005_pruneddata.bed ${K}\nmv pop_gen_MD_maf005_pruneddata.${K}.P pop_gen_MD_maf005_pruneddata.${K}.${RUN}.P\nmv pop_gen_MD_maf005_pruneddata.${K}.Q pop_gen_MD_maf005_pruneddata.${K}.${RUN}.Q\ndone\ndone\n</code></pre> <p>The last step is generating a plot showing the ancestry of each individual. An easy way of doing that is by using the online tool called CLUMPAK (Kopelman et al., 2015). CLUMPAK uses Distruct (Rosenberg, 2004) to generate the plot and CLUMPP (Jakobsson &amp; Rosenberg, 2007) to align the multiple ADMIXTURE runs. When different solutions are found for the same K, CLUMPP will group the most similar solutions into \u201cmodes\u201d. To run CLUMPAK, one just needs to use the Q-matrices of the runs. A folder containing all the Q files produced by ADMIXTURE can be created. In this example, such a folder can be called Q_values and then zipped. Next, on the \u201cMain Pipeline\u201d page, one just needs to choose the option ADMIXTURE and upload the zip folder.</p> <p>The graphic output is shown on the main page for each K's major modes (Figure 11B). Each individual is represented by a thin vertical line, and each color represents an inferred ancestral population. The ancestry proportion corresponds to the length of the color in the vertical bar. Only one mode was found for K = 1, 2 and 3. However, for K = 4, the major mode is represented by 18 out of 20 runs, meaning that these 18 have similar solutions. Cross-validation testing determined that K = 2 was the most likely outcome.</p> <p></p>"},{"location":"Section_4_8/#figure-11-example-of-population-structure-graphical-output-using-admixture-in-four-european-honey-bee-subspecies-a-plot-of-cross-validation-error-obtained-by-admixture-from-k-1-to-k-6-the-lowest-error-was-found-for-k-2-and-is-marked-in-red-b-graphical-representation-of-admixture-results-obtained-by-clumpak-here-the-populations-of-a-m-carnica-and-a-m-ligustica-are-represented-in-orange-and-a-m-iberiensis-and-a-m-mellifera-are-in-blue-of-note-is-that-some-a-m-mellifera-individuals-have-a-small-percentage-of-orange-color-suggesting-a-history-of-introgression","title":"Figure 11. Example of population structure graphical output using ADMIXTURE in four European honey bee subspecies. A. Plot of cross-validation error obtained by ADMIXTURE from K = 1 to K = 6. The lowest error was found for K = 2 and is marked in red. B. Graphical representation of ADMIXTURE results obtained by CLUMPAK. Here, the populations of A. m. carnica and A. m. ligustica are represented in orange, and A. m. iberiensis and A. m. mellifera are in blue. Of note is that some A. m. mellifera individuals have a small percentage of orange color, suggesting a history of introgression.","text":""},{"location":"Section_4_9/","title":"4. Whole-genome population and association studies","text":""},{"location":"Section_4_9/#49-landscape-genomics-an-example-using-lfmm","title":"4.9. Landscape genomics: An example using LFMM","text":"<p>Landscape genomics, which addresses how local environmental conditions influence the distribution of genetic variation (Manel et al., 2003), is an increasingly important field. To identify associations between environmental variables and genomic variation, various approaches known as genotype-environment association (GEA) or environmental association analysis (EAA) have been developed. Examples of GEA-based software are Bayenv2 (G\u00fcnther &amp; Coop, 2013), LFMM (Frichot et al., 2013), and Sam\u03b2ada (Stucki et al., 2017).</p> <p>When compared to F~ST~-based methods, GEA methods can potentially identify selective pressures driving local adaptation. Besides, the combined analysis of genetic data and environmental data increases the power to detect loci that may be under selection (De Mita et al., 2013; de Villemereuil et al., 2014; Rellstab et al., 2015). However, each GEA method has advantages and disadvantages (see (Rellstab et al., 2015)) for further details), and combining different approaches helps reduce uncertainty of the results. Here, we will describe how to use the latent factor mixed model approach (LFMM).</p> <p>LFMM is available in a command line version (1.5), and it can be downloaded from https://bcm-uga.github.io/lfmm/index.html. The latest version (2.0) is also available in an R package called lfmm. This tool models the effect of population structure using latent factors; therefore, population structure should be previously investigated. Here, the results obtained in the Section 4.8 will be integrated in this example.</p>"},{"location":"Section_4_9/#491-materials","title":"4.9.1. Materials","text":"<p>To run LFMM, two datasets will be required:</p> <ul> <li> <p>Genomic dataset: The PLINK 1 binary file obtained in Section 4.7, called pop_gen_MD_maf005.</p> </li> <li> <p>Environmental variables dataset: A file called ex_env.csv, containing 36 variables for each individual.</p> </li> </ul> <p>To have the environmental variable dataset the geographical coordinates of each apiary are needed. These coordinates are then used to obtain environmental variables from publicly available databases such as WorldClim, Climatic Research Unit, and OPENEI. A function within the R.SamBada package, (Duruz et al., 2019) called createEnv, can help in this process (R.SamBada documentation can be found at https://cran.r-project.org/web/packages/R.SamBada/R.SamBada.pdf)..)</p>"},{"location":"Section_4_9/#492-methods","title":"4.9.2. Methods","text":"<p>To prevent problems caused by non-independency of environmental variables, first, it is important to determine if they are correlated with each other. To do that, the R packages ade4 (Thioulouse et al., 2018) for PCA computation, and factoextra (Kassambara &amp; Mundt, 2017) for PCA visualization, will be needed. The following steps are pursued in R code:</p> <p>Step 1. Install and open the R libraries:</p> <pre><code>install.packages(\"ade4\") #PCA computation\ninstall.packages(\"factoextra\") #PCA visualization\nlibrary(ade4)\nlibrary(factoextra)\n</code></pre> <p>Step 2. Read the file with environmental variables:</p> <pre><code>ex_env &lt;- read.table(\"ex_env.csv\", \nheader = TRUE, #The file contains a header\nrow.names=1, #Row names are in the first column\nsep = \";\")\n</code></pre> <p>Step 3. Perform a PCA with the environmental variables:</p> <pre><code>ex_env.pca&lt;- dudi.pca(ex_env ,\nscannf = FALSE, #Hide screen plot\nnf = 5) #Number of components kept in the results\n</code></pre> <p>Step 4. Make a correlation circle</p> <pre><code>s.corcircle(ex_env.pca$co)\n</code></pre> <p>A correlation circle similar to that of Figure 12A will be obtained. Here, the direction and the length of arrows indicate the correlation between the variables as well as between variables and principal components. For instance, in Figure 12A, the variables AUTU_TMP and TMN_ANNUAL have the same direction, the same length and are very close to each other, which indicates that they are highly correlated. Indeed, the correlation value (r^2^, calculated in the next step) is 0.99. On the other hand, the variables pointing to opposite sides of the graphs, for instance SUM_TMX and AUTO_CLD, are negatively correlated (r^2^ = -0.80).</p> <p>Step 5. Calculate a correlation matrix using the following commands:</p> <pre><code>cor_matrix=cor(ex_env, method='pearson') #To calculate the correlation values\nwrite.csv(cor_matrix, file = \"cor_matrix.csv\") #To save the matrix in a file\n</code></pre> <p>Following that, a file called cor_matrix.csv will be created. The values with |r| &gt; 0.80 should be deleted from the environmental dataset. After this, the same procedure described above (Steps 1 - 4) should be performed again to obtain a diagram similar to Figure 12B, to check that the represented variables (eight in total) are independent.</p> <p></p>"},{"location":"Section_4_9/#figure-12-correlation-circles-with-a-36-variables-and-b-8-variables-after-removing-the-highly-correlated-variables-r-080","title":"Figure 12. Correlation circles with A) 36 variables and B) 8 variables, after removing the highly correlated variables (|r| &gt; 0.80).","text":"<p>Now that the bioclimatic dataset is prepared, the genetic dataset needs to be handled. LFMM accepts its own format (.lfmm), and the software has a function to convert PED format to .lfmm.</p> <p>Step 6. Convert the pop_gen_MD_maf005 binary PLINK 1 binary file obtained in Section 4.7 to a regular PLINK text file.</p> <pre><code>plink --bfile pop_gen_MD_maf005 --keep-allele-order --recode --out\n</code></pre> <p>Step 7. Convert the PED file to .lfmm using the R function of LEA, ped2lfmm. The tutorial dataset contains 33 individuals and 2,365,431 SNPs. In order to efficiently upload this data into R, the data.table R package will be used.</p> <pre><code># To install LEA\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\ninstall.packages(\"BiocManager\")\nBiocManager::install(\"LEA\")\n\n#To download the package data.table\ninstall.packages(\"data.table\") \n\n#Loading the package lea\nlibrary(LEA) \n\n#Loading the package data.table\nlibrary(\"data.table\")\n\n#Convert ped format to lfmm\noutput &lt;- ped2lfmm(\"pop_gen_MD_maf005.lfmm\") \n\n#Loading the ped file to R\ngeno &lt;- fread(\"pop_gen_MD_maf005.ped\", showProgress = FALSE) \n</code></pre> <p>Note that, when the format PED is converted to the lfmm format, the names of the SNPs that were in the MAP file will be lost.</p> <p>Step 8. Upload the eight independent environmental variables, but without the individuals\u2019 names that are in the first column.</p> <pre><code>#Load the reduced environmental file\nenv &lt;- fread(\"ex_env_red.csv\")\n\n#Select from column 2 to 9 \nenv=env[,2:9]  \n</code></pre> <p>Step 9. Perform the association analysis between the environmental variables and the genotypes. To that end, we need to run a function (lasso_lfmm) to estimate the latent factor mixed model parameters. The results of this function will be used by the function lfmm_test to calculate the significance of the associations.</p> <pre><code>#To download the package lfmm\ninstall.packages(\"lfmm\")\n\n#To load the package lfmm\nlibrary(\"lfmm\") \n\nlfmmlasso &lt;- lfmm_lasso(Y = geno,#The genotypes matrix\nX = env, #The environmental matrix\nK = 2, #The best K calculated previously\nnozero.prop = 0.01)\n\npv &lt;- lfmm_test(Y = geno, X = env,\nlfmm = lfmmlasso, #The results obtained previously\ncalibrate = \"gif\")\n</code></pre> <p>Step 10. The variable pv is a list and contains different types of information, such as the p values and the calibrated p values for all eight environmental variables. If one wants to see the calibrated p values of the first loci the following command should be typed:</p> <pre><code>head(pv$calibrated.pvalue)\n</code></pre> <p>Step 11. This command will retrieve the first six calibrated p values for each one of the eight environmental variables. Each environmental variable is in a specific column. For instance, altitude is in the first column and SUM_PRE in the third column. If we want to see only the p-values of SUM_PRE, we just need to specify that this variable is in the third column, using the following command:</p> <pre><code>head(pv$calibrated.pvalue[,3])\n</code></pre> <p>Step 12. Select one environmental variable to continue with the procedure. The data obtained for SUM_PRE (third column) will be used. Here, the calibrated p values will be saved in the variable pvalues_pre_ver.</p> <pre><code>pvalues_pre_ver &lt;- pv$calibrated.pvalue[,3] #SUM_PRE is the third column\n</code></pre> <p>Step 13. Make a Manhattan plot coloring the SNPs with p value \\&lt; 0.0001, which corresponds to -log10(p value) &gt; 4, in red and the others in grey.</p> <pre><code>#The name of the image to be created\njpeg(filename=\" Manhattan.jpeg\")\n\n#Plot the -log10 of the calibrated P-values \nplot(-log10(pvalues_pre_ver), pch = 19, #Each P-value is represented by a circle\ncex = .2, #To specify the size of the circle\nxlab = \"SNP\", ylab = \"-Log P\",#To label X and Y axis\ncol = ifelse((-log10(pvalues_pre_ver)) &gt; 4,'red','grey')) #Values &gt;4 in red and the others in grey\n\n#To save the image in the working directory\ndev.off() \n</code></pre> <p>Step 14. Count the SNPs significantly associated with SUM_PRE (p value \\&lt; 0.0001) and save the positions of the SNPs significantly associated with SUM_PRE in a variable called pvalue_00001_pos. In the tutorial example, there are a total of 1,215 SNPs with p value \\&lt;0.0001.</p> <pre><code>length(pvalues_pre_ver[pvalues_pre_ver&lt;0.0001])\npvalue_00001_pos=which(pvalues_pre_ver&lt;0.0001) \n</code></pre> <p>Step 15. Create a file in the directory with the information contained in pvalue_00001_pos.</p> <pre><code>write.table(pvalue_00001_pos,\"pvalues_00001.csv\",row.names = FALSE, col.names=FALSE)\n</code></pre> <p>Step 16. Get thegenomic coordinates from the file positions of the outlier SNPs. Use the pop_gen_MD_maf005.map coordinates and retrieve only the positions indicated in pvalues_00001.csv.</p> <p>To that end, the following steps can be performed:</p> <p>1. Create a file called index2snp.sh.</p> <pre><code>nano index2snp.sh\n</code></pre> <p>2. Type the following code in the file and close it.</p> <pre><code>#!/bin/sh\ncat pvalues_00001.csv | while read line; do\nsed -n ${line}p pop_gen_MD_maf005.map &gt;&gt; pvalues_00001_snp_name\ndone\n</code></pre> <p>3. Allow executing of the file.</p> <pre><code>chmod +x index2snp.sh\n</code></pre> <p>4. Run the file.</p> <pre><code>./index2snp.sh\n</code></pre> <p>Step 17. Annotate theoutlier SNPs. To that end, the tool SnpEff (Cingolani et al., 2012) can be used in the Galaxy server. SnpEff accepts as input a VCF file. Thus, the first step is to build a VCF only with the outlier SNPs, which can be done in PLINK. To reduce the size of the VCF file, only one individual will be included in the tutorial example. The following steps are required to annotate the outlier SNP:</p> <p>1. Create a file with the Family and Individual ID that will be retained. In the example by writing \u201ccar ID1\u201d in the file one_ind.</p> <pre><code>nano one_ind\ncar ID1\n</code></pre> <p>2. Create a file with the SNPs list to be retained.</p> <pre><code>awk '{print $2}' pvalues_00001_snp_name &gt; outlier_snp\n</code></pre> <p>3. Create a VCF file.</p> <pre><code>plink --bfile pop_gen_MD_maf005 \\\n--keep one_ind `# list of individuals to keep ` \\\n--extract outlier_snp `# list of SNPs to keep` \\\n--recode vcf --out outlier_snps\n</code></pre> <p>4. Go to Galaxy and select the tool \u201cSnpEff download\u201d and write \u201cApis_mellifera\u201d in the box \u201cSelect the annotation database you want to download\u201d.</p> <p>5. While on the Galaxy platform, go to the \u201cSnpEff eff\u201d tool and upload the outlier_snps.vcf file. In \u201cGenome source,\u201d select \u201cDownloaded snpEff database in your history\u201d and in \u201cGenome data,\u201d select the database downloaded in the previous step.</p> <p>After this step, Galaxy will provide a report with statistics (in input HTML stats file) such as the number of missense variants and the number of SNPs per chromosome. A second file shows all the genes and regions in which SNPs are located. Similar to many other selection studies, most selective SNPs detected in the dataset tested herein fall outside of exons (609 intergenic and 573 intronic). There were only 25 exonic SNPs, two of which appear to be missense or non-synonymous, and these were located in candidate genes GB42150 and GB46140.</p> <p>While genome-wide scans provide a powerful way of highlighting candidate genes for selection, causal inferences about the molecular basis of adaptation can be obtained from functional and expression studies and also from in silico protein modeling (Henriques, Wallberg, et al., 2018). Nonetheless, before employing such approaches, cross-validation of detected outlier SNPs should be always sought by other conceptually different methods.</p>"},{"location":"Section_5_1/","title":"5. Epigenomics","text":""},{"location":"Section_5_1/#51-introduction","title":"5.1. Introduction","text":"<p>Genetic components of genes are the fundamental basis of molecular mechanisms for social evolution (Rehan &amp; Toth, 2015). Gene expression and regulation are precisely programmed not only by the sequence of the DNA, but also by epigenetic modifications occurring on the genomic DNA (Tirado-Magallanes et al., 2017; Yong et al., 2016), on messenger RNA (mRNA) (Peer et al., 2017; Wang et al., 2021), proteins that interact with DNA (Shirvaliloo, 2022), chromatin accessibility (Liu et al., 2019) transcription factor binding motifs (Hu et al., 2010), and other non-coding RNA (Benayoun et al., 2015; Ruffo et al., 2023). These factors collectively contribute to the intricate programming of gene expression and control.</p> <p>Honey bees are known to be among the arthropods embodying remarkably the phenomenon of phenotypic plasticity, particularly regarding development, reproductive abilities, and behavior (Corona et al., 2016; Pfennig et al., 2010). In a colony, there are not only different castes (such as queens and workers) but also different divisions within workers (such as nurses and foragers), all of which can arise from the same genome. Many of the differences between these phenotypes responding to change in environmental cues (e.g., nutrition, pheromones, colony size and stress) are driven by epigenetic changes (Figure 14A &amp; B) which are molecular modifications that regulate genes without changing the actual DNA sequence (Feinberg, 2007; Haig, 2004; Jirtle &amp; Skinner, 2007). DNA methylation (Glastad et al., 2014; Herb et al., 2012; Kucharski et al., 2008; Oldroyd &amp; Yagound, 2021; Shi et al., 2011), RNA methylation (Wang, Xiao, et al., 2021), histone modifications (Glastad et al., 2019), microRNAs (Ashby et al., 2016; Behura &amp; Whitfield, 2010; Shi et al., 2012), other non-coding RNAs (Glastad et al., 2019; Tadano et al., 2009), or organization and material state of chromatin (Wojciechowski et al., 2018) are all examples of epigenetic mechanisms. However, DNA methylation and histone modifications are among the most commonly studied, and new attention is being given to RNA methylation. Therefore, this chapter focuses on these three types of epigenetic modifications.</p> <p>Honey bees have a DNA methylation system with two key enzymes: DNA-methyltransferase 1 and 3 (DNMT1 and DNMT3) (Wang et al., 2006). The most common covalent modification of DNA is the methylation on the position 5 of the cytosine base (5-methylcytosine, or 5mC), which often appears with guanine (CpG) (Li-Byarlay, 2016; Maleszka, 2008; Ruden et al., 2015; Wang &amp; Li-Byarlay, 2015; H. Yan et al., 2014). Compared to vertebrate species, the honey bee genome has lower coverage of CpG DNA methylation (Bewick et al., 2017; Schmitz et al., 2019).</p> <p>Environmental factors, such as changes in nutrition, biotic stress and other external stimuli (e.g., resource availability), can affect honey bee caste determination, development, and behavior (Drewell et al., 2014; Foret et al., 2012; Galbraith et al., 2015; Herb et al., 2012; Kucharski et al., 2008; Li-Byarlay et al., 2020; Lyko et al., 2010; Remnant et al., 2016). These changes are often mediated by epigenetics. Epigenetics is, therefore, a bridge linking genetics and the environment, contributing to the complex biology of honey bees (Wang &amp; Li-Byarlay, 2015). However, the parent-specific gene expression, as associated with the kinship theory of intragenomic conflict, did not involve DNA methylation (Wu et al., 2020).</p> <p></p>"},{"location":"Section_5_1/#figure-14-major-epigenetic-modifications-a-dna-methylation-marks-methylated-cytosine-or-5mc-and-rna-methylation-marks-n6-methyladenosine-or-m6a-b-histone-methylation-and-acetylation","title":"Figure 14. Major epigenetic modifications. A) DNA methylation marks (methylated cytosine, or 5mC) and RNA methylation marks (N6-methyladenosine, or m6A). B) Histone methylation and acetylation.","text":""},{"location":"Section_5_2/","title":"5. Epigenomics","text":""},{"location":"Section_5_2/#52-dna-methylation","title":"5.2. DNA methylation","text":""},{"location":"Section_5_2/#521-bisulfite-seq","title":"5.2.1. Bisulfite-seq","text":"<p>Bisulfite sequencing (BS-seq) is a method used to study DNA methylation at the single-nucleotide resolution. The method involves treating DNA with sodium bisulfite, which converts unmethylated cytosine residues to uracil, while leaving methylated cytosine (5mC) residues unchanged. Consequently, after bisulfite treatment, only the methylated cytosines are retained. The treated DNA is then sequenced, and the resulting data can be analyzed to determine the methylation status of each cytosine in the genome. Bisulfite sequencing is widely employed in epigenetics research to elucidate the role of DNA methylation in gene regulation and various diseases.</p> <p>There are several strategies to study DNA methylation marks, including 1) whole genome bisulfite sequencing (WGBS), 2) reduced representation bisulfite sequencing (RRBS) using restriction digestion of the genomic sequences, or 3) targeted DNA methylation analysis using PCR. In honey bee research, WGBS is most often used, and is covered below.</p>"},{"location":"Section_5_2/#5211-considerations","title":"5.2.1.1. Considerations","text":"<ul> <li> <p>Input: WGBS requires high-quality and high-quantity DNA samples. It is important to have enough DNA to generate sufficient sequencing depth to detect methylation at low-frequency sites. Caution must be taken because the sample processing can degrade DNA to some degree. Sufficient depth can be achieved by using large numbers of sequencing reads, or by using high-throughput sequencing platforms.</p> </li> <li> <p>Sequencing: Bisulfite-treated DNA needs to be converted into a sequencing library before it can be sequenced. This typically involves fragmenting the DNA, end-repairing the fragments, and then ligating adapters for sequencing.</p> </li> <li> <p>Integration: WGBS data is often compared with other epigenetic data such as ChIP-seq and RNA-seq to understand the functional relevance of DNA methylation.</p> </li> <li> <p>Validation: It is important to validate the WGBS data using other techniques such as pyrosequencing, bisulfite pyrosequencing, or methylation-specific PCR (MSP).</p> </li> </ul>"},{"location":"Section_5_2/#5212-materials","title":"5.2.1.2. Materials","text":"<ul> <li> <p>Large equipment: Thermal cycler for PCRs, downstream sequencing platform such as Illumina MethylationEPIC Array, Single Cell Methyl-Seq, Agilent SureSelect MethylSeq (Agilent Technologies Inc.), or IDT xGen\u2122 Methylation-Sequencing technologies</p> </li> <li> <p>Kits for bisulfite conversion and genomic library prep such as the EZ DNA Methylation Kits, generally including the M-Binding Buffer, M-Wash Buffer, L-Desulphonation Buffer, M-Elution Buffer, and Bisulfite conversion reagent, spin columns, and collection tubes.</p> </li> </ul>"},{"location":"Section_5_2/#5213-methods","title":"5.2.1.3. Methods","text":"<p>Wet lab processing:</p> <ol> <li> <p>Extract total genomic DNA (1 \u03bcg per group) from bulk tissue of interest using a total DNA extraction kit (for example, DNeasy Blood &amp; Tissue Kit (QIAGEN), Maxwell\u00ae RSC Tissue DNA Kit (Promega), Quick-DNA Tissue/Insect Kit (Zymo Research)).</p> </li> <li> <p>Use the EZ DNA methylation kit (Zymo Research), or equivalent, to perform the bisulfite treatment on all the genomic DNA samples following the manufacturer\u2019s instructions.</p> </li> <li> <p>Bisulfite conversion reagent (130 \u00b5l) is added to a DNA sample (20 \u00b5l, DNA quantity range is between 100 pg to 2 \u00b5g) in a PCR tube.</p> </li> <li> <p>Place the mix on the thermal cycler and run the following protocol: 98 \u00b0C (8 min), 54 \u00b0C (60 min), then 4 \u00b0C for overnight (no more than 20 h).</p> </li> <li> <p>Add the converted DNA to a spin column which has M-Binding Buffer pre-added (600 \u00b5l).</p> </li> <li> <p>Mix the sample and the buffer well, centrifuge for 30 s at &gt; 10,000 g.</p> </li> <li> <p>Add M-Wash Buffer (100 \u00b5l) and repeat centrifugation</p> </li> <li> <p>Add L-Desulphonation Buffer (200 \u00b5l) to the column and incubate 15-20 min (room temperature) and repeat centrifugation.</p> </li> <li> <p>Add M-Wash Buffer (200 \u00b5l) to the column and repeat centrifugation. Repeat the wash again.</p> </li> <li> <p>Transfer the column to a microcentrifuge tube (1.5 ml) and add 10 \u00b5l M-Elution Buffer, water, or TE buffer (pH value is more than or equal to 6.0) to the column center. Centrifuge 30 s at full speed to collect the DNA.</p> </li> </ol> <p>Sequencing and quality check:</p> <ol> <li> <p>Sequence the DNA on your preferred sequencing platform following the manufacturer\u2019s guidelines.</p> </li> <li> <p>Check the sequencing data for quality control (QC), processed to align read to the most updated Apis mellifera genome (see Section 5.2.4). Several key QC measures to consider include the sequence quality, mapping efficiency as general sequencing process, coverage, and the bisulfite conversion efficiency. The coverage of each base should be at least 20x, and ideally higher.</p> </li> </ol> <pre><code>**TIP:** If there is a high duplicate rate, it can indicate issues with library preparation or sequencing. It is generally recommended to have a duplication rate of less than 10%. It is also important to check the efficiency of bisulfite conversion, which can be done by comparing the proportion of C to T transitions in the WGBS data with the proportion of C to T transitions in the input DNA.\n</code></pre>"},{"location":"Section_5_2/#522-methylated-dna-immunoprecipitation-sequencing-medip-seq","title":"5.2.2. Methylated DNA immunoprecipitation-sequencing (MeDIP-seq)","text":"<p>Methylated DNA immunoprecipitation sequencing (MeDIP-seq) is a tool to identify regions of the genome that are methylated. It is based on the principle that methylated DNA can be selectively pulled down from a sample using an antibody that recognizes 5-methylcytosine 5mC. Basically, the DNA is fragmented and denatured, then incubated with an antibody that specifically binds to 5mC. The methylated DNA is then immunoprecipitated using magnetic beads or protein A/G. The immunoprecipitated DNA is then sequenced, and the resulting data is analyzed to identify regions of the genome that are methylated.</p>"},{"location":"Section_5_2/#5221-considerations","title":"5.2.2.1. Considerations","text":"<p>MeDIP-seq is a powerful technique that can be used to identify methylated regions in a genome-wide manner, and it also allows the detection of low levels of methylation. However, it has some limitations, such as the need for a high-quality antibody that recognizes 5mC and the potential for cross-reactivity with other modified forms of cytosine.</p> <p>MeDIP-seq data can also be compared with other epigenetic data such as ChIP-seq and RNA-seq to understand the functional relevance of DNA methylation. The MeDIP-seq procedure described here is referenced from (Qinghe Li et al., 2011) and (Shi et al., 2013).</p>"},{"location":"Section_5_2/#5222-materials","title":"5.2.2.2. Materials","text":"<ul> <li> <p>DNA template</p> </li> <li> <p>Genomic DNA extraction kit</p> </li> <li> <p>A Quick Ligation kit (QIAGEN)</p> </li> <li> <p>MinEluteH PCR Purification kit (QIAGEN)</p> </li> <li> <p>IP buffer (Tris-HCl 10 mM with pH 7.5, NaCl 280 mM, EDTA 1 mM)</p> </li> <li> <p>T4 polynucleotide kinase</p> </li> <li> <p>T4 DNA polymerase</p> </li> <li> <p>Anti5-methylcytosine mouse monoclonal antibody (Calbiochem)</p> </li> <li> <p>Dynabeads Protein G and Protein A</p> </li> </ul>"},{"location":"Section_5_2/#5223-methods","title":"5.2.2.3. Methods","text":"<ol> <li> <p>DNA is isolated by phenol-chloroform extraction, and fragmented (around 200\u2013350 bp), and extracted by a gel extraction kit. The recovered DNA is first 5\u2019 and 3\u2019 end blunting, phosphorylating and repairing by T4 Polynucleotide Kinase and T4 DNA Polymerase.</p> </li> <li> <p>After adding the ATP in the 3\u2019 end, an Illumina sequencing primer adapter is ligated to the DNA using the Quick Ligation kit.</p> </li> <li> <p>DNA is recovered by MinEluteH PCR Purification Kit (QIAGEN) and used for immunoprecipitation (IP).</p> </li> <li> <p>IP DNA (4 mg) is then heat denatured (5 min), then is incubated with 32 mg anti5-methylcytosine mouse monoclonal antibody in a 400 ml of IP buffer for 30 min at 4 \u00b0C.</p> </li> <li> <p>The Dynabeads Protein G (100 ml) and Protein A (Dynal) are added to the mix for incubation of 5.5 hours at 4 \u00b0C.</p> </li> <li> <p>After immunoprecipitation, the DNA is amplified by PCR with specific Illumina sequencing primers. Illumina platforms such as HiSeq (discontinued), NextSeq, or NovaSeq can be used for sequencing, depending on the cost and coverage needs.</p> </li> </ol>"},{"location":"Section_5_2/#523-data-processing-and-analysis","title":"5.2.3. Data processing and analysis","text":"<p>The analysis of BS-seq data involves several steps, including data preprocessing, alignment, methylation calling, and downstream analysis. These steps can vary depending on the specific research question and the software tools used.</p>"},{"location":"Section_5_2/#5231-software-recommendations","title":"5.2.3.1. Software recommendations","text":"<p>The first step is to align the preprocessed reads to the reference genome. The most commonly used aligner for BS-seq data is Bismark, which is able to align bisulfite-converted reads to the reference genome (Krueger &amp; Andrews, 2011).</p> <p>After alignment, the next step is to call methylation levels at each cytosine position in the genome. There are several different methylation calling tools available, such as MethPipe (Song et al., 2013), DSS (Feng &amp; Wu, 2019), and MethylSight (Biggar et al., 2020). The model-based analysis of chIPseq (MACS) approach can also be used to measure the methylation levels in the A. mellifera genome (Neary &amp; Carless, 2020; Shi et al., 2013).</p> <p>Once the methylation levels have been called, the next step is to perform downstream analysis to identify differentially methylated regions (DMRs), annotate them with functional elements and explore relationships with other data types such as transcriptomics. There are various tools available for this purpose, such as MethylKit (Akalin et al., 2012), DMRcate (Peters et al., 2021), and MethylSeekR (Burger et al., 2013). These tools use different algorithms to call methylation levels and correct for sequencing errors. The results can be visualized using various tools such as IGV, methylKit and Bioconductor packages such as BSgenome and BSseq.</p>"},{"location":"Section_5_2/#5232-data-repository","title":"5.2.3.2. Data repository","text":"<p>Like all sequencing data, DNA methylation or RNA methylation data should be deposited in a public database. For example, NCBI Sequence Read Archive (SRA) data portal is a public database for scientists to deposit their raw sequencing data (see Section 11).</p>"},{"location":"Section_5_2/#5233-statistical-analysis","title":"5.2.3.3. Statistical analysis","text":"<p>Statistical analysis of BS-seq data typically involves the estimation of methylation levels at individual cytosine positions or at predefined regions of interest, such as gene bodies in the case of honey bee genome. The estimation of methylation levels is usually based on the proportion of methylated reads, which are reads that have a cytosine-to-thymine (C-to-T) change due to bisulfite conversion (Foret et al., 2012).</p> <p>Once methylation levels have been estimated, several statistical methods can be used to identify differentially methylated regions (DMRs) between different samples or groups. Commonly used statistical thresholds for differential methylation are a percent methylation difference larger than 10% and q &lt; 0.01 (Akalin et al., 2012). A Bayesian framework can also be used to estimate the probability of different methylation states at each cytosine position and to identify DMRs.</p> <p>After DMRs have been identified, several downstream analyses such as functional annotation of DMRs, correlation of DMRs with other epigenetic or transcriptomic data, pathway analysis, or clustering of DMRs to identify patterns of co-regulation can be performed.</p>"},{"location":"Section_5_3/","title":"5. Epigenomics","text":""},{"location":"Section_5_3/#53-epitranscriptomics-rna-methylation-of-m6a","title":"5.3. Epitranscriptomics: RNA methylation of m6A","text":"<p>Besides the chemical modifications on the DNA, RNA molecules can also undergo more than 100 different dynamic chemical modifications that impact gene expression (Roundtree et al., 2017; S\u00e1nchez-V\u00e1squez et al., 2018). The study of RNA methylation so far has mainly focused on the N6-methyladenosine (m6A) modification, which occurs in mRNAs of eukaryotes and represents about 80% of all RNA methylation in the honey bees (Wang et al., 2021). In honey bees, recent discoveries have linked m6A methylation to larval development and caste differentiation, highlighting its significance in Apis biology (Bataglia et al., 2021; Wang et al., 2021). Epitranscriptomics is the field that focuses on studying all types of mRNA mRNA modifications, including m6A. The protocol below describes how to quantify total m6A methylation across all transcripts, but more advanced methods must be used to actually identify the sites of methylation.</p>"},{"location":"Section_5_3/#531-considerations-for-testing-global-rna-methylation-of-m6a","title":"5.3.1. Considerations for testing global RNA methylation of m6A","text":"<ul> <li> <p>This test requires a precise quantity of RNA input; therefore, it is crucial to have the equipment to quantify the RNA concentration in your RNA extraction sample. Nanodrop spectrophotometers or Qubit fluorometers can both provide accurate concentration information about your sample, but the latter is recommended for accuracy.</p> </li> <li> <p>The EpiQuik m6A RNA Methylation Quantification Kit (EpiGentek) can be used to quantify total m6A methylation globally across a complete RNA sample. The range of the RNA quantity is 100 ng to 300 ng. See Evans et al. (2013) for sample handling and RNA extraction protocols.</p> </li> </ul>"},{"location":"Section_5_3/#532-materials","title":"5.3.2. Materials","text":"<ul> <li>Large equipment: Microplate reader capable of reading absorbance at 450 nm, 37 \u00b0C incubator</li> <li>Kits: EpiQuik m6A RNA Methylation Quantification Kit (EpiGentek) including negative and positive RNA controls, capture antibody, detection antibody, wash buffer, binding solution, enhancer solution, developer solution, stop solution, standard control</li> <li>8-well assay strips</li> <li>Distilled water</li> <li>1x TE buffer with pH 7.5 -8.0</li> <li>Adjustable pipette</li> <li>Aerosol-resistant filtered pipette tips</li> <li>96 well plates</li> <li>1.5 ml microcentrifuge tubes</li> <li>Plate sealing film or parafilm M</li> </ul>"},{"location":"Section_5_3/#533-procedure","title":"5.3.3. Procedure","text":"<ol> <li> <p>Follow the kit manufacturer\u2019s instructions for RNA binding, antibody binding, and RNA quantification.</p> </li> <li> <p>After color development, measure absorbance at 450 nm.</p> <ol> <li> <p>For relative quantification, the percentage of m6A in total RNA can be calculated based on the average OD450 of negative control, average OD450 of positive control, average OD450 of sample, the amount of input sample RNA in ng, and the amount of input positive control in ng.</p> </li> <li> <p>For absolute quantification, a standard curve can be generated based on the m6A standard controls (0.01, 0.02, 0.05, 0.1, 0.2, and 0.5 ng/ul). With the standard curve, the amount of m6A in the total RNA sample can be calculated using sample OD minus negative control OD, then divided by the slope. The proportion of m6A in the samples can be calculated using m6A amount in ng divided by input quantity (for example 200 ng).</p> </li> </ol> </li> </ol>"},{"location":"Section_5_3/#534-identifying-methylation-sites","title":"5.3.4. Identifying methylation sites","text":"<p>Although global m6A methylation is valuable for assessing large-scale methylation states, it is beneficial to understand which specific residues are modified on a transcript. Most RNA extraction techniques retain the methylation state on the mRNA transcripts, and there are several ways that the m6A sites may be identified. m6A-seq uses ribose-sensitive nuclease digestion and high-throughput sequencing (Dominissini et al., 2013). MeRIP-seq (Meng et al., 2014) is another approach which uses m6A-specific antibodies to pull down m6A-containing RNAs and then sequences them.</p> <p>A final option is Nanopore MinION sequencing. Using this technique, you can glean which specific RNA transcripts have m6A methylation as well as which residues are modified. Nanopore MinION direct RNA sequencing (dRNA-seq) provides long reads (10,000\u201330,000 base fragments being common) and, in some cases, can provide reads of entire transcripts. The advantage of dRNA-seq is that one sequencing procedure can include information of both transcriptome and m6A methylome modifications of RNA. See Section 6.2 for more information on direct RNA sequencing.</p>"},{"location":"Section_5_3/#535-software-recommendations","title":"5.3.5. Software recommendations","text":"<p>For m6A RNA methylation from the Nanopore dRNA-seq data, one new tool for identifying differential RNA modifications is called xPore (Pratanwanich et al., 2021). xPore uses a machine learning-based approach to predict the presence and location of RNA modifications, including m6A, within the dRNA-seq reads. It also allows for the quantification of modification levels, and it can also be used to identify differentially modified sites between different samples or conditions. xPore's ability to handle long read lengths of direct-RNA sequencing data allows for accurate detection of m6A modifications in introns and exons, as well as in regions spanning multiple exons, resulting in higher resolution and more comprehensive coverage of m6A sites. It allows for high-resolution and comprehensive detection of m6A modifications, which can help to improve our understanding of the role of m6A in regulating gene expression.</p> <p>One of the main challenges in the analysis of m6A site data is distinguishing true m6A modifications from sequencing noise. To address this, many tools use a threshold-based approach to call m6A sites, which involves setting a threshold for the minimum number of reads or the minimum proportion of methylated reads required to call a site as methylated. The choice of threshold will depend on the sequencing depth and the desired level of specificity and sensitivity. Similar to other transcriptomic analyses, multiple hypothesis testing must be accounted for (by using a Benjamini-Hochberg correction, for example).</p>"},{"location":"Section_5_4/","title":"5. Epigenomics","text":""},{"location":"Section_5_4/#54-chromatin-organization-and-histone-modifications","title":"5.4. Chromatin organization and histone modifications","text":"<p>Among a variety topics of epigenomics, transcriptional activities occurring at tissue and cellular levels are regulated by transcription factors (TFs) (Li-Byarlay et al., 2013; Qiu et al., 2013; Spitz &amp; Furlong, 2012). TFs work with cis-acting regulatory elements (CRE) for cell regulation od promoters, epigenetic patterns, and genome structure (Stadhouders et al., 2019).</p> <p>A histone is an octomeric (8-subunit) protein complex which is a crucial component of chromatin. These complexes serve as a spool that genomic DNA is wrapped around. Post-translational modifications determine how tightly the DNA is associated with histones. Methylation of lysine 9 on the third subunit of the histone proteins (denoted H3K9me3) results in tighter association of the DNA to the histones, and limits the ability of transcription factors to access the DNA for transcription. Acetylation of several amino acids causes the DNA and histones to be associated more loosely, making the DNA more accessible to transcription factors and therefore more likely to be transcribed. Modification of the histones proteins provides an additional mechanism of gene regulation, beyond the binding of transcription factors to the promoter region of a gene.</p>"},{"location":"Section_5_4/#541-chromatin-immunoprecipitation-sequencing-and-transcription-factor-binding-motifs","title":"5.4.1. Chromatin immunoprecipitation sequencing and transcription factor binding motifs","text":"<p>Chromatin immunoprecipitation sequencing (ChIP-seq) is one way that sites of histone modifications can be mapped to the genome. Like many modern molecular techniques, existing protocols and guidelines can be, more or less, directly adapted for use in honey bees with little modification (e.g. see Nakato &amp; Sakata (2021)).</p>"},{"location":"Section_5_4/#542-hi-c-chromatin-conformation","title":"5.4.2. Hi-C &amp; chromatin conformation","text":"<p>The Hi-C technology that captures genome-wide chromatin interactions and structure method has been already discussed in Section 3.3.1.1. Beyond genome assembly improvement, HI-C has identified that the variation of the genomic structure of A. mellifera is associated with the variation of phenotype (Jin et al., 2023), and is highly regulated with gene activities or adaptations in different environment (Kirkpatrick &amp; Barton, 2006; Wallberg et al., 2017). In Drosophila fruit flies, or Heliconius butterflies, chromosomal inversions is related to adaptation to environmental adaptation (Joron et al., 2011; Krimbas &amp; Powell, 1992). Future research using Hi-C technology is needed to obtain more information on the chromatin structure and how they interact with gene regulations.</p>"},{"location":"Section_5_4/#543-chromatin-accessibility-and-transcriptional-factor-motifs","title":"5.4.3. Chromatin accessibility and transcriptional factor motifs","text":"<p>The chromatin accessibility is the percentage of time any given fragment of the genome is occupied by a nucleosome. Although not necessarily heritable, it plays an important role in gene regulation and can change in response to environmental cues (Turner, 2008). Three assays used to study chromatin accessibility are: 1) assay for transposase accessible chromatin by sequencing (ATAC-seq), 2) DNase I hypersensitive site -seq (DNase-seq), and 3) micrococcal nuclear sequencing (MNase-seq). High read depth in these assays can reveal regions that where TFs bind (Tsompana &amp; Buck, 2014).</p> <p>Recent research using ATAC-seq, RNA-seq and ChIP-seq has identified many regulatory regions, including accessible chromatin regions, nucleosome occupancy, and specific patterns of TF gene networks in the genome of queen, worker, and drone adult bees (Lowe et al., 2022; Zhang et al., 2023). Another ATAC-seq and RNA-seq study comparing the TFs among the brains of foragers, newborn workers, and nurses revealed different regulatory landscape and new interactions within the transcriptional regulatory network underlying the division of labor (Fang et al., 2022). Previous meta-analyses and cis-metanalysis tools also revealed that transcriptional regulatory mechanisms that are underlying the behavioral maturation of honey bee workers (Ament et al., 2012). The genome-wide scanning and gene regulatory network activity also identified TF motifs in the honey bee brains at the colony and individual levels, and how they are associated with the regulation of social behavior and its evolution (Jones et al., 2020; Rittschof et al., 2014; Shpigler et al., 2019).</p> <p>Additional ChIP-seq experiments have informed on transcriptional factor binding sites of Vitellogenin gene, which affect the immunity and behavior of honey bees (Salmela et al., 2022). Other transcription factors such as usp, ubx, Mblk-1/E93 are also critical for phenotypic plasticity and development of honey bees and other insects (Ament, Wang, et al., 2012; Matsumura et al., 2022; Prasad et al., 2016; H. Yan et al., 2014). While these cutting-edge methods are still rare in Apis, the few studies that exist provide very detailed protocols for performing ChIP-seq experiments of histone methylation in honey bee larvae, including the extensive optimization such as crosslinking time and buffer compositions (Wojciechowski et al., 2018).</p>"},{"location":"Section_5_4/#544-detecting-histone-modifications-by-mass-spectrometry","title":"5.4.4. Detecting histone modifications by mass spectrometry","text":"<p>Histone modifications, a key epigenetic mechanism, significantly contribute significantly to phenotypic dimorphism and caste difference in A. mellifera honey bees (Dickman et al., 2013; Jin et al., 2023; Zhang et al., 2023). Several studies have reported that histone modifications are associated with social behavior, evolution, development, and ecology of A. mellifera (Alghamdi &amp; Alattal, 2024; Dickman et al., 2013; Wojciechowski et al., 2018; Zhang et al., 2023). Histone deacetylase inhibitors also play a role in caste determination in honey bees (Spannhoff et al., 2011).</p> <p>Mass spectrometry-based proteomics can be used to detect and quantify modified histones. Since a typical proteomics workflow will dissociate histones from the DNA with which they interact, this approach is not suitable for identifying DNA binding sites. However, the power of mass spectrometry is its ability to detect numerous types of covalent modifications, with dozens of potential post-translational modifications of histones (Huang et al., 2015). While a generic shotgun proteomics dataset will contain ions corresponding to modified peptides, signal intensity and data quality are improved if immunoprecipitation is conducted to enrich the peptide or protein sample for sequences carrying the desired modification. The resulting mass spectrometry data processing will differ as well, as the mass shift and affected amino acid residue associated with the modification will need to be specified. Sample preparation procedures are essentially as described in Section 8, but further details can be found in see Huang et al. (2015).</p>"},{"location":"Section_5_5/","title":"5. Epigenomics","text":""},{"location":"Section_5_5/#55-applications-and-limitations","title":"5.5. Applications and limitations","text":"<p>Honey bees have long been studied as a model system for epigenetics in insects. Tools for epigenetic analyses have enabled research of epigenetic mechanisms underlying the complex behaviors, development, gene regulation, diseases, ecology, and health of honey bees (Galbraith et al., 2015; Grozinger &amp; Robinson, 2015; Grozinger &amp; Zayed, 2020; Kucharski et al., 2008; Li-Byarlay et al., 2020, 2013). Specifially, 5mC DNA methylation is involved in caste determination and behavioral maturation, which are essential for regular colony functioning (Herb et al., 2012). Furthermore, m6A modifications have been linked to behavior, learning, and memory (Bataglia et al., 2021; Wang &amp; Li-Byarlay, 2015). However, research on m6A modifications in honey bees is still in its early stages, and further studies are needed to elucidate the specific role of m6A in regulating gene expression and splicing in this model organism.</p> <p>Many studies also show that these epigenetic changes are tissue-specific or change over time (Li-Byarlay et al., 2020); therefore, genes with differential methylation patterns could be used in the future as biomarkers for environmental stress. In human cancer studies, for example, DNA methylation can be used to assist with diagnosis (Shames et al., 2007).</p> <p>However, the study of epigenetics and epigenomics can be complicated by tissue-specific effects and temporal dynamics during different developmental stages of organisms (Li-Byarlay et al., 2020). Future research using multi-omic approaches that combine epigenomics with transcriptomics, genomics, and other \u2018omic tools may provide more comparative data. Until then, great care should be taken to control the age or developmental stage of samples used in these studies.</p>"},{"location":"Section_6_1/","title":"6. Transcriptomics","text":""},{"location":"Section_6_1/#61-introduction","title":"6.1. Introduction","text":"<p>Transcriptomics is the study of expressed transcripts, differential splicing patterns of messenger RNA, or chemical modifications on RNAs. What mechanisms program or influence genes expression, regulation, interaction? These questions can be answered holistically by sequencing the transcriptome and aligning it against an annotated reference genome.</p> <p>Before NGS became accessible and affordable, northern blot techniques were most often used to detect and quantify mRNA transcripts. Quantitative reverse transcription-polymerase chain reaction (qRT-PCR) has also been used to answer similar questions. However, each of these techniques is practically limited to a small number of targeted genes. Transcriptomic techniques can identify nearly every transcript in an organism or tissue, and the relative quantities of these transcripts can be compared, providing valuable insights into the gene regulatory networks involved in a phenotype.</p> <p>As honey bees were among the first insect genomes sequenced, the study of gene expression and regulations in Apis had the tremendous advantage of having an annotated reference genome as an anchor to map transcripts. At the time of publication of Evans et al. (2013), microarrays were the most commonly used high-throughput method of evaluating transcript abundances. Since then, RNA-seq has become a mainstay, with multiple sequencing platforms available, and even single-cell transcriptomics is possible. Here, we address these new techniques and how they can be applied to honey bee samples.</p>"},{"location":"Section_6_2/","title":"6. Transcriptomics","text":""},{"location":"Section_6_2/#62-sequencing-technologies","title":"6.2. Sequencing technologies","text":"<p>Many of the same sequencing platforms used to sequence genomes can be used for transcriptomes as well (see Section 3: Genomic DNA sequencing, and (Evans et al., 2013)). The major differences between RNA-seq and DNA sequencing are 1) laboratory pre-processing conditions that require ultra-clean and low-temperature handling to limit RNA degradation and 2) the need to convert extracted sensitive RNA into double-stranded cDNA. Once transformed into cDNA, the material is stable and can be processed similarly to gDNA. Here, we describe specific considerations when applying this technology to transcriptome sequencing.</p>"},{"location":"Section_6_2/#621-considerations","title":"6.2.1. Considerations","text":"<ul> <li> <p>Always use proper microbiological aseptic techniques when working with the RNA and RNA-seq library to avoid degradation and cross-contamination. Transcript sequencing output will depend on the initial quality (RIN) and RNA degradation levels (Gallego Romero et al., 2014).</p> </li> <li> <p>Wear and change frequently disposable gloves to prevent RNase contamination and work as quickly as possible until cDNA is prepared.</p> </li> <li> <p>Keep tubes closed and on ice or cold block whenever possible.</p> </li> <li> <p>Be aware that as sequencing technology progresses, the platform chemistry can shift quickly. This can cause discordance in the data output and yield of the same RNA library sequenced (De-Kayne et al., 2021).</p> </li> <li> <p>Downstream analysis such as differential gene expression analysis are sensitive to the number of replicates chosen per condition. A too low sample size may ignore natural variation and can be prone to false discoveries (Y. Li et al., 2022; Squair et al., 2021).</p> </li> </ul>"},{"location":"Section_6_2/#622-illumina-sequencing-short-reads","title":"6.2.2. Illumina sequencing (short reads)","text":"<p>Similar to genome sequencing, Illumina is the technology most often used for transcriptomic studies. Short reads are ideal for samples with low RNA yield, and it is relatively quick and inexpensive compared to other sequencing technologies. However, because this technology sequences many short strands with a fragment size ranging from 150-250 bp (Quail et al., 2009), reads from genes with multiple splice variants cannot always be mapped to a specific spliceoform. There are numerous resources describing short-read RNA sequencing and data analysis best practices (Conesa et al., 2016), which, combined with sample handling and RNA extraction protocols previously described specifically for honey bees (Evans et al., 2013), are directly applicable to honey bees. Here, we will focus on long-read sequencing and single-cell transcriptomics, but include updates to short-read sequencing covered in the previous BEEBOOK (Evans et al., 2013).</p>"},{"location":"Section_6_2/#623-third-generation-sequencing-long-reads","title":"6.2.3. Third generation sequencing (long reads)","text":"<p>Third-generation sequencing enables the user to sequence contiguous and long reads from molecules of &gt;10 kb on average, which minimizes some of the computational workload needed to analyze full length transcripts, improves the accuracy of the alignments against the reference genome, and helps resolve ambiguous splice variants.</p> <p>The main platforms for generating long reads include Oxford Nanopore Technology (ONT) and Isoform sequencing (ISO-seq) using Single-molecule, Real-time (SMRT) sequencing by PacBio. RNA extraction and sample handling for analysis by these platforms are essentially as previously described in Evans et al. (2013), with scrupulous attention to maintaining RNA integrity. Once RNA is extracted, the kit each sequencing platform manufactures, which are appropriate for their devices, should be used (for example, the Direct RNA or cDNA Sequencing Kit from ONT, or SMRTBell\u2122 kit from PacBio).</p>"},{"location":"Section_6_2/#6231-considerations-for-choosing-a-long-read-platform","title":"6.2.3.1. Considerations for choosing a long-read platform","text":"<ul> <li> <p>ONT has developed sequencing platforms to sequence RNA directly, without conversion to a cDNA intermediate. This minimizes the possibility of errors that could arise during a reverse transcription reaction, but the samples themselves are less stable leading up to sequencing.</p> </li> <li> <p>SMRT PacBio sequencing technology is an especially powerful platform because of its ability to generate long reads by reading a single molecule multiple times, which improves sensitivity.</p> </li> </ul>"},{"location":"Section_6_3/","title":"6. Transcriptomics","text":""},{"location":"Section_6_3/#63-single-cell-transcriptomics","title":"6.3. Single-cell transcriptomics","text":"<p>RNA-seq has traditionally been done with whole tissue samples also called \u201cbulk sequencing.\u201d However, recent advances in sequencing technology to target smaller input material have made it possible to sequence the transcriptomes of individual cells within a tissue sample while preserving the identity of their cell of origin to create a cell atlas. Single-cell transcriptomics is a relatively new technique developed in 2013 for biomedical purposes and only started to be applied to non-model organisms (Chen, Sun, et al., 2021). This field is uniquely suited to studying gene expression in known heterogeneous tissues and even identifying the spatial structure of cells in tissue downstream.</p> <p>The approach takes a cell suspension of the tissue of interest, separates cells individually, and assigns a unique barcode to each mRNA transcript in the cell. This allows researchers to achieve incredible resolution within organs even creating cell atlas in mammals, fly and ants (Chen et al., 2021; Li et al., 2022; Li et al., 2022). Recently, Zhang et al., (2022) used the technique to compare the transcriptomes of different types of neurons within the honey bee brain (e.g. Kenyon cells, optic lobe cells, olfactory projection neurons, etc.), initiating the first cell atlas in bees. Below is a general protocol for single-cell transcriptomics sample preparation adapted from Traniello et al. (2020).</p>"},{"location":"Section_6_3/#631-considerations","title":"6.3.1. Considerations","text":"<ul> <li> <p>Single-cell sequencing requires fresh samples that can readily be dissociated into a cell suspension.</p> </li> <li> <p>If it is not possible to use a fresh sample, the cell suspension (protocol described below) can be made fresh, then frozen and used later for sequencing.</p> </li> <li> <p>Cells embedded in excessive extracellular matrix run the risk of being damaged through dissociation and rendered unusable for sequencing.</p> </li> <li> <p>Different cell types from different tissues (for example brain versus fat body) will need more time to optimize the procedure for cell dissociation by testing different buffers or reagents.</p> </li> </ul>"},{"location":"Section_6_3/#632-materials","title":"6.3.2. Materials","text":"<ul> <li> <p>Large equipment: 10x chromium controller</p> </li> <li> <p>Pipette and tips</p> </li> <li> <p>Kits: Chromium Chip G Single Cell Kit (10x Genomics), Chromium Next GEM Single Cell 3\u2019 Kit (10x Genomics)</p> </li> <li> <p>RNAse-free 1X PBS</p> </li> <li> <p>1.5 ml microfuge tubes (nuclease-free)</p> </li> <li> <p>Trypsin</p> </li> <li> <p>Ethylene-diamine-tetracetic acid (EDTA)</p> </li> <li> <p>Phosphate-buffered saline (PBS)</p> </li> <li> <p>Dissection plate</p> </li> <li> <p>Dissection forceps and scissors</p> </li> <li> <p>Dissociation media</p> </li> <li> <p>Table centrifuge</p> </li> <li> <p>0.4% trypan blue</p> </li> <li> <p>C-Chip disposable hemocytometer and a Compound microscope or a cellometer</p> </li> </ul>"},{"location":"Section_6_3/#633-sample-preparation-procedure-for-single-cell-sequencing","title":"6.3.3. Sample preparation procedure for single-cell sequencing","text":"<ol> <li> <p>Rapidly dissect desired tissue in cold RNase-free 1X PBS and place in a 1.5 ml microfuge tube.</p> </li> <li> <p>Add PBS with 0.25% trypsin to sample.</p> </li> <li> <p>Incubate on ice for 30 minutes.</p> </li> <li> <p>Gently dissociate cells by pipetting with 200 \u03bcl pipette tips.</p> </li> <li> <p>Separate individual brain cells using a 10x Genomics microfluidics chip following the manufacturer\u2019s instructions.</p> </li> <li> <p>Prepare single cell transcriptomics library utilizing the Chromium NextGen Single Cell 3\u2019 technology according to manufacturer instructions.</p> </li> <li> <p>Sequence single-cell libraries utilizing either Illumina or Nanopore sequencing.</p> </li> </ol>"},{"location":"Section_6_4/","title":"6. Transcriptomics","text":""},{"location":"Section_6_4/#64-data-handling-and-analysis","title":"6.4. Data handling and analysis","text":""},{"location":"Section_6_4/#641-rna-seq-and-differentially-expressed-genes-degs","title":"6.4.1. RNA-seq and differentially expressed genes (DEGs)","text":"<p>To identify differentially expressed genes in RNA-seq data obtained from a minimum of two conditions/treatments, here we provide an example analysis pipeline (Figure 15) using the aligner software STAR (spliced transcripts alignment to a reference) (Dobin &amp; Gingeras, 2015), the software package Subreads (Liao et al., 2013)and a reference genome. Many bioinformatic pipelines exist for such analysis, some of which use open-source workflows and containers such as Nextflow to create community curated frameworks that facilitate and standardize DEGs detection (Ewels et al., 2020; Wratten et al., 2021). For example, nf-core/rnaseq pipeline offers an alternative to our proposed method, allowing for alignment to the genome with STAR or pseudo-alignment to the transcriptome with Salmon (Patro et al., 2017) or Kallisto (Bray et al., 2016)and adaptable for both bulk-tissue and single-cell transcriptomes. Additionally, it is important to mention that pseudo-alignment workflow might be better suited to users with a limited computational power and time as it achieves similar accuracy in terms of transcripts quantification than reference-anchor mapping and reads counts (Bray et al., 2016).</p> <p>The resulting processed data can then be analyzed for differential expression using the R package, DESeq2 (Love et al., 2014). We optionally recommend that users compare and cross-validate the differential expression results with those of other packages, such as edgeR package (Liu et al., 2021), to verify the overlap of genes found up- and down-regulated. If the overlap is significant, this increase our confidence in identifying true differentially expressed genes, as both DESeq2 and edgeR varies in their statistical models to estimate differential expression. These software benefits from frequent updates and comprehensive tutorials are made available by the developer (e.g., DESeq2, and edgeR manual).</p> <p></p>"},{"location":"Section_6_4/#figure-15-example-rna-seq-data-analysis-pipeline-using-a-genome-as-anchor-many-software-options-are-available-for-each-step-only-selected-standard-softwares-are-shown-note-key-paces-where-data-export-may-be-desirable-created-with-biorender","title":"Figure 15. Example RNA-seq data analysis pipeline using a genome as anchor. Many software options are available for each step; only selected standard softwares are shown. Note key paces where data export may be desirable. Created with Biorender.","text":"<p>Step 1. After data pre-processing and quality control, map reads to annotated Apis mellifera genome.</p> <ul> <li> <p>STAR can be run in the command line to map RNA-seq reads to a supplied reference genome. The most current version of the honey bee genome is Amel_HAv3.1 and can be downloaded on NCBI RefSeq.</p> </li> <li> <p>For running STAR in command line, generate a directory for the genome by using the following command:</p> </li> </ul> <pre><code>mkdir starAligned\n</code></pre> <p>Step 2. Create the genome index with the following command:</p> <pre><code>STAR --runThreadN 4\n--runMode genomeGenerate \n--genomeDir starAligned \n--genomeFastaFiles /path/to/FASTAfiles \n--sjdbGTFfile /path/to/GTF\n</code></pre> <p>The parameters were chosen for the following reasons:\\ <code>--runMode genomeGenerate</code> indicates we are in the mode to build genome index in the directory <code>--genomeDir starAligned</code>.\\ <code>--sjdbGTFfile /path/to/GTF</code> indicates that we want the annotation file in GTF format.</p> <p>Step 3. Map the reads from the RNA-seq data onto the indexed genome, and place the counts into a table to be used later for the identification of differentially expressed genes. For paired reads, both the forward and reverse read will need to be provided as input. Because the FASTQ files are zipped, <code>readFilesCommand gunzip -c</code> must be used to unzip the files to be accessed by the mapping program. This script generates the aligned reads in a BAM file to be used by featureCounts.</p> <p>TIP: Further questions related to the application of STAR can be found in the STAR manual.</p> <pre><code>STAR --runThreadN 4 \n--readFilesIn /path/to/genomeDir \n--readFilesIn /path/to/fastq1r1.gz,/path/to/fastq2r1.gz,\\\n/path/to/fastq1r2.gz,/path/to/fastq2r2.gz   \n--genomeDir starAligned \n#--quantMode TranscriptomeSAM GeneCounts\n--outFileNamePrefix sampleName \n--outSAMtype BAM SortedByCoordinate \n--readFilesCommand gunzip -c \n</code></pre> <p><code>--runThreadN 4</code> indicates that we run the mapping process using 4 threads.\\ <code>--genomeDir</code> indicates where the genome index is located.</p> <p><code>--outSAMtype BAM SortedByCoordinate</code> indicates that the output should be in BAM format and sorted by coordinates.</p> <p>Alternatively to featureCounts, we can also use directly the <code>--quantMode TranscriptomeSAM GeneCounts</code> to produce two outputs, one with the Read Count for each gene and one with the gene aligned to the transcriptome only.</p> <p>Step 4. Counting reads can be accomplished using the featureCounts program, part of the Subreads package, in the command line. Once you have loaded Subreads, running the following command quantifies the reads associated with each gene. When the program is supplied with multiple BAM files, it will combine those reads into a single output which can be easily used in the DESeq2 Rpackage for differential expression analysis.</p> <pre><code>featureCounts -a /path/to/annotationFile \n-o sampleNameCounts.txt \n-g gene_id \nsampleName1Counts.BAM \nsampleName2Counts.BAM \nsampleName3Counts.BAM\n</code></pre> <p>Step 5. Identify differentially expressed genes using DESeq2 in R. This program takes the BAM files generated by featureCounts, and metadata about the individual samples, and calculates significant changes in gene expression based on</p>"},{"location":"Section_6_4/#642-gene-network-analysis","title":"6.4.2. Gene network analysis","text":"<p>Gene ontology analysis can reveal groups of elevated or repressed genes classified by functional similarity. However, gene ontology does not represent groups of genes which have common patterns of regulation within groups. To uncover analysis pathways related to common regulatory mechanisms (genes regulated by a common transcription factor, for example), whole genome co-expression network analysis (WGCNA) can identify mechanisms of regulation (Langfelder &amp; Horvath, 2008). This program, run in R, calculates modules of genes with correlated expression. Then, considering metadata, identifies modules whose expression correlates with those modules. Genes within individual modules can then be exported from the program, and can be used for further analysis (such as gene ontology).</p> <p>An alternative to WGCNA is the ASTRIX (Analyzing Subsets of Transcriptional Regulators Influencing eXpression) method developed on honey bee brain TRN model (Sriram Chandrasekaran et al., 2011) which has been specifically designed for transcriptional regulatory network inference and has been widely applied in honey bee research. Recent studies have used the ASTRIX method in various tissues to identify the key regulatory genes and pathways that contribute to phenotypic plasticity and adaptation in A. mellifera (Chandrasekaran et al., 2011; Jones et al., 2020; Shpigler et al., 2017, 2019; Traniello et al., 2023, 2020).</p>"},{"location":"Section_6_4/#643-single-cell-transcriptomics","title":"6.4.3. Single-cell transcriptomics","text":"<p>Single-cell sequencing data are unique in that each transcript has a unique RNA sequence tag added during the sequencing step. This modifier allows each read to be mapped to the cell in which it was transcribed. With this information, a complete transcriptome can be assembled for each individual cell in a sample. This creates an additional step in analysis, because each transcript must be assigned a cellular identity, in addition to being mapped to the genome. Software packages that can be used to analyze these datasets are described below.</p>"},{"location":"Section_6_4/#6431-10x-genomics-specific-software","title":"6.4.3.1. 10x Genomics specific software","text":"<p>10x Genomics has a platform available specifically for the analysis of 10x Genomics datasets, using the programs Cell Ranger and Loupe Browser. The types of analyses, access to the platform, and a description of the coding involved are found on the 10x support webpage: https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/tutorials/gex-analysis-nature-publication.</p> <p>Cell Ranger contains analysis pipelines for analyzing single-cell transcriptomic data, including converting raw base call (BCL) files to FASTQ files, aligning reads to a reference, and performing differential expression analysis. It can either be run in the 10x Cloud, or Cell Ranger can be downloaded and run from a desktop.</p> <p>After expression profiles are generated for individual cells in cell ranger, they are grouped into clusters based on the co-expression of genes. Loupe Browser takes files created in Cell Ranger\u2019s aggr pipeline and converts them to a spatial representation of individual cells based on their expression profiles. Loupe Browser is available for download and can be run on a desktop.</p>"},{"location":"Section_6_4/#6432-third-party-software","title":"6.4.3.2. Third party software","text":"<p>Seurat is an R package specifically designed to align, map, count, and analyze single-cell transcriptomic data (https://cran.r-project.org/web/packages/Seurat/index.html)..) Using weighted nearest-neighbor analysis, Seurat takes transcriptomic data and creates clusters of cells based on their gene expression profiles (Hao et al., 2021).</p>"},{"location":"Section_6_5/","title":"6. Transcriptomics","text":""},{"location":"Section_6_5/#65-applications-and-limitations","title":"6.5. Applications and limitations","text":"<p>RNA-seq, particularly with short reads, is an incredibly versatile tool for gaining high quality transcriptomic data. However, long-read RNA sequencing data align more accurately to the genome and can help to identify the complete length of isoforms that are differentially expressed or differentially spliced. Long-read sequencing is thus filling an important gap in our knowledge of isoform expression patterns in honey bees.</p> <p>Single-cell transcriptomics is a relatively new field, and while the potential resolution of this type of sequencing data is unparalleled, current practices do not yet reach the full potential. For example, to obtain a diverse representation of different cell types from targeted tissue, pooled samples are often still used. To harvest enough cells (50,000-100,000) for a good coverage of honey bee brain samples, brains from several honey bees are pooled together (Traniello et al., 2023, 2020). In the future, a key objective should be to decrease the quantity of the input cell numbers. Ideally, the ultimate goal would be to obtain deep sequencing data from individual bees instead of relying on pooled bee samples. This approach would significantly enhance statistical power and unlock the full potential of single-cell sequencing, providing exceptional resolution. A further limitation is that few cell types can currently be recognized based on the gene markers available. To overcome this limitation, it is crucial to conduct more extensive studies on individual gene markers that can accurately represent a broader range of honey bee cell types beyond neurons and glia.</p> <p>Transcriptomics and RNA-seq analyses can provide information on the expression, isoforms abundance, alternative splicing, and chemical modifications of genes. Additional information about the activity of proteins or other cellular processes is essential for understanding gene function, and can be added by designing additional experiments using functional genomics (Section 7) proteomics (Section 8) and metabolomics (Section 9).</p>"},{"location":"Section_7_1/","title":"7. Functional genomics and xenobiotic treatment","text":""},{"location":"Section_7_1/#71-introduction","title":"7.1. Introduction","text":"<p>By analyzing the entire genome, researchers can explore intergenic relationships that extend beyond monogenic, individual polymorphisms. Recent developments in sequencing technology, combined with publicly available computational tools, have made it possible to glean a huge amount of information from these datasets. However, the challenge lies in our ability to fully interpret the data, particularly in cases where gene functions are either unknown or poorly characterized. In fact, approximately one third of A. mellifera genes fall into this category, posing limitations on our understanding of their roles and contributions.</p> <p>This gap in functional knowledge can be filled by experimentally manipulating genes of interest to directly examine their contribution to a specific phenotype. Gene expression can be manipulated through changes to DNA (e.g. using CRISPR/Cas9 technology) or knockdowns of RNA (RNAi). These techniques can provide researchers with causal information about their phenotype of interest to go along with correlative data from genomic analysis. This is a necessary step for validating gene functions and gene interactions.</p>"},{"location":"Section_7_2/","title":"7. Functional genomics and xenobiotic treatment","text":""},{"location":"Section_7_2/#72-crispr","title":"7.2. CRISPR","text":"<p>Clustered regularly interspaced palindromic repeats and Cas9 (CRISPR/Cas9) gene editing is a relatively recent molecular tool for modifying the genome at very precise locations (Jinek et al., 2012). Knock-outs (removal of a large portion of a gene from the genome), knock-ins (insertion of an endogenous gene, a modified gene with altered expression, or a reporter), and targeted gene editing are all possible with the use of CRISPR. CRISPR has already been used to study the role of major royal jelly proteins (X. F. Hu et al., 2019; Kohno et al., 2016), taste (De\u011firmenci et al., 2020), development (Kohno &amp; Kubo, 2018), neurodevelopment (Chen et al., 2021), and mechanisms of sex-determination (Roth et al., 2019; Wang et al., 2021) in honey bees. It is not, however, the only method of manipulating gene expression; other approaches are discussed in McAfee et al. (2022).</p> <p>CRISPR technology relies on a well-designed short guide RNA (sgRNA) sequence to target a specific region of the genome. This sgRNA must include the following components:</p> <ul> <li> <p>A tracr RNA sequence, which creates a hairpin to act as a scaffold for Cas9 binding</p> </li> <li> <p>A crRNA (CRISPR RNA) sequence (17-20 bp) which is specific to the target DNA</p> </li> </ul> <p>Constructs can be designed manually or utilizing a web-based tool. Several such tools exist, but many do not currently query against the A. mellifera genome. However, the tool Cas-OFFinder has this option. In addition, the region of interest within the genome must have a PAM (protospacer adjacent motif) sequence. This serves as a guide for the actual site of cleavage, which is 3-4 bp upstream of the PAM sequence. The following protocol for germline gene editing was inspired by (Chen, et al., 2021; Hu et al., 2019). Methods for egg collection and microinjection were originally developed by (Beye et al., 2002).</p>"},{"location":"Section_7_2/#721-considerations","title":"7.2.1. Considerations","text":"<ul> <li> <p>Both Cas9 protein and sgRNA can either be purchased from vendors or expressed and purified in-house. The following protocol is for in-house expression. If purchasing components from vendors, skip to Section 7.2.1.3.</p> </li> <li> <p>This protocol describes injecting the gene editing components into honey bee eggs, but injecting into non-embryonic tissues (e.g. adult brains) is also possible.</p> </li> <li> <p>Egg injections typically have a high failure rate and injecting thousands of eggs will likely be necessary to obtain an adequate number of mutants. To collect large numbers of fresh eggs, we recommend using the Jenter egg collection kit, which allows eggs to be conveniently collected on removable plastic plugs, although other methods are possible (e.g., (Lee &amp; Lee, 2019)). Condition queens by introducing them to the cages several days before injection day. You may need 3-5 laying queens to collect a sufficient number of fresh eggs.</p> </li> <li> <p>Check with your institution\u2019s Biosafety department for regulations around handling, maintaining, and disposing of genetically modified insects.</p> </li> </ul>"},{"location":"Section_7_2/#722-materials","title":"7.2.2. Materials","text":"<ul> <li> <p>Large equipment: Incubators for bacterial culture and injected eggs, microinjector (e.g. PLI100 Pico injector (Warner Instruments) or Femtojet 4i (Eppendorf)), dissection scope, micromanipulator, basic laboratory equipment (microfuge, vortex, water bath, etc.), and a Nanodrop (Thermo Fisher) or Qubit (Thermo Fisher)</p> </li> <li> <p>Kits: QIAprep plasmid purification kit (QIAGEN, or equivalent), T7 RiboMAX Express Large Scale RNA Production System (Promega), Monarch RNA Cleanup Kit (New England Biolabs, Inc)</p> </li> <li> <p>Basic E. coli transformation and culturing reagents and materials</p> </li> <li> <p>IPTG (IPTG (isopropyl \u03b2-d-1-thiogalactopyranoside)</p> </li> <li> <p>Ni-NTA Superflow resin column (QIAGEN)</p> </li> <li> <p>PD-10 column (GE Life Sciences)</p> </li> <li> <p>BsaI restriction enzyme and digestion buffer</p> </li> <li> <p>Cas9 storage buffer (20 mM Tris, pH 8, 200 mM KCl, 10 mM MgCl~2~, 10% glycerol)</p> </li> <li> <p>Injection buffer (20 mM HEPES, pH 7.5, 300 mM KCl, 1 mM MgCl~2~)</p> </li> </ul>"},{"location":"Section_7_2/#723-methods-for-crisprcas9-gene-editing-of-embryos","title":"7.2.3. Methods for CRISPR/Cas9 gene editing of embryos","text":""},{"location":"Section_7_2/#7231-generating-cas9-protein","title":"7.2.3.1. Generating Cas9 protein","text":"<ol> <li> <p>Obtain the plasmid pET-28b-Cas9-His (Addgene, Watertown, MA) for Cas9 expression under the control of the lac operator. Follow standard protocols for transformation, culturing, and IPTG induction in E. coli cells.</p> </li> <li> <p>Purify the His-tagged Cas9 from protein lysate with a Ni-NTA Superflow resin column.</p> </li> <li> <p>Desalt the Cas9 using a PD-10 column.</p> </li> <li> <p>Once eluted, Cas9 protein can be stored as a 50 \u03bcM solution in storage buffer at \u201380\u00b0C.</p> </li> <li> <p>For new batches, check Cas9 purity by gel electrophoresis.</p> </li> </ol>"},{"location":"Section_7_2/#7232-generating-sgrna","title":"7.2.3.2. Generating sgRNA","text":"<ol> <li> <p>Ensure that equipment, surfaces, and reagents are nuclease-free.</p> </li> <li> <p>sgRNA cDNA can be inserted into a MiniGene plasmid (or equivalent plasmid for T7 in vitro transcription). Follow basic E. coli transformation and culturing protocols to increase plasmid copy numbers.</p> </li> <li> <p>Extract plasmid and purify using a plasmid QIAprep kit (QIAGEN) or equivalent.</p> </li> <li> <p>Linearize plasmid by digesting with BsaI (if using a MiniGene plasmid), or equivalent.</p> </li> <li> <p>Conduct in vitro transcription on linearized plasmid using the T7 RiboMAX Express Large Scale RNA Production System.</p> </li> <li> <p>Purify RNA with the Monarch RNA Cleanup Kit according to the manufacturer\u2019s instructions for purification and storage.</p> </li> <li> <p>For new batches, check RNA integrity by gel electrophoresis and quantify using a Nanodrop or Qubit</p> </li> </ol>"},{"location":"Section_7_2/#7233-ribonucleoprotein-assembly","title":"7.2.3.3. Ribonucleoprotein assembly","text":"<ol> <li> <p>Combine a 1:2 molar ratio of Cas9 to sgRNA, at a final concentration of 5 \u03bcM RNP, in injection buffer.</p> </li> <li> <p>This working solution can be split into 6 \u00b5l aliquots and frozen at \u201380 \u2103.</p> </li> <li> <p>After thawing, dilute solution to 2.5 \u03bcM with injection buffer.</p> </li> </ol>"},{"location":"Section_7_2/#7234-egg-collection-and-microinjection","title":"7.2.3.4. Egg collection and microinjection","text":"<ol> <li> <p>Train queen in queen cages (Jenter\u2122) (Figure 16A) by intermittently caging her for one day at a time. This will also give the workers a chance to build out the comb.</p> </li> <li> <p>On injection day, replace old egg plugs with fresh plugs. 2-4 h later, collect the freshly laid eggs by removing the plugs and fastening them to plasticine disks (Figure 16B).</p> </li> <li> <p>Keep eggs warm (30-33 \u02daC) at all times or development will be delayed. Store in an incubator unless actively injecting. Perform injections in a walk-in incubator if possible.</p> </li> <li> <p>Load ~ 1 \u00b5l of RNP working solution into the injection pipet.</p> </li> <li> <p>Inject approximately 300-400 pL into the egg. Research has shown that injecting into the anterior third of the egg is most effective (Otte et al., 2018).</p> </li> <li> <p>Eggs should hatch about 72 h after injection. A few hours before hatching, prime the egg cups with a small amount of warmed royal jelly (Figure 16C). Remove cups with shriveled or deformed eggs.</p> </li> <li> <p>Once hatched, follow methods described in \u201cStandard Methods for Artificial Rearing of Apis mellifera Larvae\u201d (Crailsheim et al., 2013).</p> </li> </ol> <p></p>"},{"location":"Section_7_2/#figure-16-examples-of-the-jenter-egg-collection-system-a-cartoon-diagram-of-an-egg-collection-cassette-not-to-scale-real-cassette-has-110-plugs-image-adapted-from-mcafee-et-al-2018-cc-by-40-b-plugs-with-eggs-fastened-on-modeling-clay-c-newly-hatched-larva-primed-with-royal-jelly","title":"Figure 16. Examples of the Jenter egg collection system. A) Cartoon diagram of an egg collection cassette (not to scale, real cassette has 110 plugs). Image adapted from McAfee et al. (2018) (CC BY 4.0). B) Plugs with eggs fastened on modeling clay. C) Newly hatched larva primed with royal jelly.","text":""},{"location":"Section_7_3/","title":"7. Functional genomics and xenobiotic treatment","text":""},{"location":"Section_7_3/#73-rna-interference","title":"7.3. RNA interference","text":"<p>RNA interference (RNAi) is a molecular tool used for transient knock-down (reduction) of gene expression (Brutscher &amp; Flenniken, 2015; Wilson &amp; Doudna, 2013). This technique takes advantage of endogenous molecular machinery that normally helps protect the host against RNA viruses, which replicate their genome via a double-stranded (ds)RNA intermediate. The presence of dsRNA within host cells thus signals viral infection and triggers a cascade of events leading to viral inactivation by the RNA-induced silencing complex (RISC).</p> <p>Although RNAi evolved as an immune defense against viruses, the dsRNA that leads to the antiviral response does not necessarily need to be a viral sequence. RNAi against nearly any gene is theoretically possible and can be achieved simply through the introduction of short interfering RNA (siRNA; 20-25 bp) or long dsRNA (several hundred bp) to the organism - a technique that has proven to be especially feasible in insects (Huvenne &amp; Smagghe, 2010). Here we present current methods for conducting RNAi experiments in honey bees.</p>"},{"location":"Section_7_3/#731-rnai-considerations","title":"7.3.1. RNAi considerations","text":"<ul> <li> <p>A common method of introducing RNAi constructs into bees is via injection; however, this is highly invasive and creates a wound on the bee. This might be useful if modeling parasitization by mites, but in most cases, the wound creates undesirable trauma. The methods described here are less invasive.</p> </li> <li> <p>Feeding dsRNA to larvae or adults is also a non-invasive method. It has been covered already in Evans et al. (2013).</p> </li> <li> <p>Non-specific effects associated with RNAi are well-documented (Flenniken &amp; Andino, 2013; Jarosch &amp; Moritz, 2012; Nunes et al., 2013) and probably unavoidable, but the likelihood of observing severe off-target phenotypes can be reduced by cross-referencing the siRNA/dsRNA sequence to the honey bee genome. Only sequences unique to the target should be pursued. Moreover, negative control groups utilizing GFP dsRNA or scrambled dsRNA sequences are essential to distinguish gene-specific phenotypes from non-specific effects.</p> </li> <li> <p>Consider labeling the siRNA construct, either with a fluorescent tag (GFP or RFP) or digoxigenin (DIG) to visualize localization in tissue after treatment and check that the siRNA is correctly introduced to the target tissue.</p> </li> <li> <p>An alternative strategy for RNAi using symbiont-mediation is also documented (Lariviere et al., 2023)</p> </li> </ul>"},{"location":"Section_7_3/#732-methods-for-nanoparticle-mediated-rnai","title":"7.3.2. Methods for nanoparticle-mediated RNAi","text":"<p>Honey bees breathe through spiracles, which are small holes in the abdomen connected to a tracheal network. In addition to feeding and injection, one way to introduce a foreign substance into a bee is through inhalation. Spiracles are approximately 200 \u00b5m wide; therefore, nebulized nanoparticles carrying RNAi constructs can enter the bee, assuming the nanoparticle-containing droplets or aerosolized particles are sufficiently small. Here we describe the general procedure for using perfluorocarbon (PFC) nanoparticles for delivering siRNA to bees, adapted from methods described in (Li-Byarlay et al., 2013).</p>"},{"location":"Section_7_3/#7321-materials","title":"7.3.2.1. Materials","text":"<ul> <li> <p>Large equipment: humidity-controlled incubator</p> </li> <li> <p>Medical nebulizer (purchased from a medical health supply store)</p> </li> <li> <p>Collecting chamber with end cap (Bioquip, Catalog #2820GA: 2820D) attached to the nebulizer. Bioquip is now closed permanently. Equivalent needs to be searched</p> </li> <li> <p>Nanoparticles that can carry small interfere RNAs (PFCs purchased from Thermo Fisher, for example)</p> </li> <li> <p>siRNA (follow methods outlined in Evans et al. (2013) for siRNA design, production, and purification, or purchase from a vendor)</p> </li> <li> <p>Acrylic or plexiglass cages for maintaining live bees in the laboratory and which are suitable for exposure to nebulized nanoparticles</p> </li> </ul>"},{"location":"Section_7_3/#7322-procedure","title":"7.3.2.2. Procedure","text":"<ol> <li> <p>To coat nanoparticles with siRNA, mix siRNA and add nanoparticles to create a solution with a ratio of 1 \u03bcM siRNA to 200 pM nanoparticles.</p> <p>TIP: Higher ratios may be used, but will not necessarily be more efficacious.</p> </li> <li> <p>Select bees and maintain them in laboratory cages according to methods outlined in Williams et al. (2013).</p> </li> <li> <p>Add the siRNA and nanoparticle solution to a nebulizer compressor machine. Live bees to be treated are housed in the collecting chamber. The solution is then sprayed on bees for ~5 min.</p> </li> <li> <p>Allow bees to recover in a dark incubator held at 32 \u00b0C and at least 40% humidity for 96 h. Provide pollen paste (50% w/v honey, 50% w/v pollen) and sugar water (50% w/v sucrose in water) ad libitum.</p> </li> </ol>"},{"location":"Section_7_4/","title":"7. Functional genomics and xenobiotic treatment","text":""},{"location":"Section_7_4/#74-xenobiotic-treatment","title":"7.4. Xenobiotic treatment","text":"<p>Treating bees with xenobiotic compounds is a quick and non-invasive means for modifying neurotransmitters and the activity of signaling pathways. In addition, it provides a convenient means for studying the impact of environmental chemicals (e.g. pesticides) on bee health. Most of the protocols below are described in Barron et al., (2007). Furthermore, additional types of compounds such as hormones and neurotransmitters can be used to treat bees and study their functions in behavior (Blenau &amp; Baumann, 2016).</p>"},{"location":"Section_7_4/#741-xenobiotic-treatment-considerations","title":"7.4.1 Xenobiotic treatment considerations","text":"<ul> <li> <p>For any application, it is important to consider the realistic and relevant dosage. One way to determine this is to conduct assays with different xenobiotic concentrations and observe any changes in health or behavior which indicate that the chemical is active in the bee.</p> </li> <li> <p>Depending on the goals of the experiment, the distribution of the chemical throughout the bee\u2019s body may need to be monitored to confirm that it enters the tissue of interest. This has been done previously using radiolabeled chemicals (Barron et al., 2007) so that the radioactivity could be traced after administration.</p> </li> <li> <p>Always follow chemical safety guidelines when working with pesticides and other chemicals that could be hazardous to human health</p> </li> <li> <p>Many different drugs of interest can be taken up using this method, and requires very little reagent to see an effect. Serial dilutions will likely be necessary to generate solutions for application with precise concentrations.</p> </li> <li> <p>The appropriate controls such as injection with saline should also be considered.</p> </li> </ul>"},{"location":"Section_7_4/#742-materials","title":"7.4.2. Materials","text":"<ul> <li> <p>Large equipment: Dissection microscope, Hamilton syringe, flight cage, in-hive feeders or feeding stations</p> </li> <li> <p>Insect Ringer solution (0.125 M sodium chloride, 1.5 mM calcium chloride dihydrate, 5 mM potassium chloride, 0.8 mM sodium phosphate dibasic, pH 7.4, filter sterilized)</p> </li> <li> <p>High-purity xenobiotic compound</p> </li> <li> <p>Organic solvent or water for to produce xenobiotic stock solution, depending on solubility</p> </li> </ul>"},{"location":"Section_7_4/#743-procedure","title":"7.4.3 Procedure","text":""},{"location":"Section_7_4/#7431-thorax-application","title":"7.4.3.1 Thorax application","text":"<p>Different compounds may be soluble in different solvents. Acetone (Li-Byarlay et al., 2014) and dimethylformamaide (DMF) (Barron et al., 2007) have been previously described for topical applications. This is the simplest application method; however, actual absorption efficiency of most drugs through the cuticle is unknown.</p> <ol> <li> <p>Anesthetize bees on ice or otherwise immobilize them for treatment.</p> </li> <li> <p>Apply 1 \u03bcl of solution containing the xenobiotic dissolved in organic solvent directly to the thorax of bees.</p> </li> <li> <p>Continue to immobilize bees for at least 30 seconds after application to allow for absorption and solvent evaporation.</p> </li> <li> <p>Analysis of phenotype (behavioral assay, dissection, genetic analysis) can be conducted 24 h after treatment.</p> </li> <li> <p>The amount of time suggested here may be different depending on the treatment and phenotypes.</p> </li> </ol>"},{"location":"Section_7_4/#7432-injection","title":"7.4.3.2. Injection","text":"<p>Injections allow very precise quantities of the drug to be directly administered to tissues or body sections of interest. This is especially useful for determining the action of a particular gene or signaling cascade in a specific location. However, this method requires specialized equipment, which the feeding methods do not. In addition, the person administering the drug must be incredibly careful when controlling the drug delivery to ensure that there is no damage to the bee in the course of the experiment.</p> <ol> <li> <p>Dilute the xenobiotic stock solution in insect ringer solution to the desired concentration.</p> </li> <li> <p>Administer 1 \u03bcl of solution to each bee using a Hamilton syringe.</p> </li> <li> <p>Inject the bee.</p> <p>a. For injections in the thorax, insert the needle at the base of the mesonotum to the right of the midline.</p> <p>b. For injections into the head, the solution should be applied to the median ocellus. To do so, anesthetize the bees and place them on a strip of duct tape, such that the head is immobilized. Remove the lens of the median ocellus with a micro scalpel and apply 1 \u03bcl of the solution to this area. Confirm that absorption occurs over several minutes.</p> </li> </ol>"},{"location":"Section_7_4/#7433-feeding-individual-bees","title":"7.4.3.3. Feeding individual bees","text":"<p>This method allows for control over the quantity of drug administered and allows for the researcher to control the time elapsed between the administration and any behavioral or genetic assay. However, administering drugs in this way can be very tedious and time consuming. It is also easier to damage bees in the course of collection, harnessing, and feeding.</p> <ol> <li> <p>Prior to feeding, starve bees for 1-4 hours.</p> </li> <li> <p>Dissolve your drug of interest in a sucrose solution (50% w/v). TIP: Depending on the solubility of the chemical, a carrier solvent may be needed, such as lecithin or ethanol. If a carrier is used, it is crucial to take this into account when conducting vehicle controls.</p> </li> <li> <p>Immobilize bees in a 1.5 ml microfuge tube that has a hole made in the conical end.</p> </li> <li> <p>With a single bee in the tube with their heads towards the conical end opening, administer the drug in the sugar solution via pipette. Visually confirm that the bees are eating the solution. Bees can be fed up to 10 \u03bcl of solution in this way.</p> </li> </ol>"},{"location":"Section_7_4/#7434-flight-cage-feeding","title":"7.4.3.4. Flight cage feeding","text":"<p>Although feedings are typically done in the laboratory, it is possible to conduct pharmaceutical feedings on a larger scale. However, a major concern when feeding colonies in the field is the potential for contaminating the environment with the drug being administered. One way around this is to utilize a closed system, such as a flight cage, where no other pollinators will be exposed. In a flight cage system (Figure 17), the drug of interest can be administered in a sucrose solution (1:1 weight/volume) using in-hive feeders or feeding stations (Momowoa). Food coloring can also be mixed with the sucrose solution, so that its ingestion can be observed in the bees.</p> <p>This method enables researchers to feed compounds to an entire honey bee colony, without exposing the drug to other animals or plants. This method requires the installation of a specialized facility (the flight house), which can be expensive and time consuming. Because the bees can only eat food that is provided to them, fresh sugar solution and pollen must be provided daily. Food that isn\u2019t replaced regularly might become moldy and toxic to the bees.</p> <p></p>"},{"location":"Section_7_4/#figure-17-setup-for-flight-cage-feeding-a-bees-are-provided-with-a-sugar-water-solution-with-the-compound-of-interest-b-flight-cage-enclosure-is-covered-to-protect-from-direct-sunlight-and-rain","title":"Figure 17. Setup for flight cage feeding. A) Bees are provided with a sugar water solution with the compound of interest. B) Flight cage enclosure is covered to protect from direct sunlight and rain.","text":""},{"location":"Section_7_5/","title":"7. Functional genomics and xenobiotic treatment","text":""},{"location":"Section_7_5/#75-applications-and-limitations","title":"7.5. Applications and limitations","text":"<p>In honey bees, the genome is complex and many genes are not fully understood; indeed, over one third still are not functionally annotated (Walsh et al., 2022). Therefore, it can be difficult to know what particular genes control a trait or function, and RNAi is most commonly applied as a discovery tool in order to elucidate the roles genes play. There is also variability in responses of the knockdown effects. Factors such as genetic variation, environmental factors, and widespread off-target effects (Schulte et al., 2014), which are difficult to predict or control, sometimes making it challenging to replicate results.</p> <p>Because of the haplodiploid system of sex-determination and complex mating strategy of honey bees, there is limited applicability to manipulate gene expression long-term (that is, to develop mutated lineages using CRISPR or transgenic techniques). Though there has been some success rearing transgenic queens (Schulte et al., 2014), those queens would need to mate with transgenic drones in order to establish a fully modified colony. Such an endeavor is exceedingly difficult and has not yet been achieved, but unmated queens can be stimulated to lay haploid eggs in microcolonies to yield genetically modified drones (Schulte et al., 2014). Moreover, ethical considerations of bee containment and risk of escape further inhibit widespread use of this technique.</p> <p>The high efficiency of genetic modification by CRISPR, however, is making it increasingly feasible to avoid the need of creating a genetic lineage to produce large numbers of modified bees for experiments. Instead, embryos can be injected and reared in vitro in sufficient numbers to facilitate developmental studies (Roth et al., 2019). This method also poses virtually no risk of viable bees escaping into the environment. For these reasons, this seems to be the direction in which the field is headed, but studies on social phenotypes, such as the dance language or hygienic behavior, are not possible.</p>"},{"location":"Section_8_1/","title":"8. Proteomics","text":""},{"location":"Section_8_1/#81-introduction","title":"8.1. Introduction","text":"<p>While massively parallel sequencing enables high-throughput analyses of gene expression, transcripts are still one step away from the proteins that actually execute most biological functions. Gene and protein expression patterns are often not well correlated (Payne, 2015); therefore, transcriptomics and proteomics techniques are complementary. Diverse technologies have been used for proteomics over the years, including two-dimensional gel electrophoresis, mass fingerprinting, top-down proteomics, antibody microarrays, and shot-gun proteomics. Shot-gun proteomics has become the dominant technique, representing the vast majority of proteomics work done currently, andwill be the focus of the methods described here.</p> <p>In this approach, proteins are first digested to peptides using proteases, then the peptides are ionized (acidified) and measured in a liquid chromatography-coupled tandem mass spectrometer (LC-MSMS) instrument. This type of instrument first measures the mass-to-charge ratio of a peptide ion, then fragments the ion and measures the mass-to-charge ratios of the fragments. These data can be used to identify the original peptide sequence, and bioinformatics tools are used to infer which proteins were present in the sample and in what quantities. Proteomics has historically lagged behind transcriptomics in terms of coverage and sensitivity (transcriptomics datasets typically quantify tens of thousands of genes, whereas proteomics datasets typically quantify several thousand proteins) (Timp &amp; Timp, 2020), but improved liquid chromatography systems, instrumentation, and software have made proteomics competitively powerful (Aebersold &amp; Mann, 2016).</p> <p>Despite these exciting advances, it is still challenging to achieve rich proteomics datasets for honey bees relative to model species (McAfee et al., 2016). As with many non-model organisms, honey bees have undergone fewer iterations of genome annotation refinement than humans and model species, which hinders the ability of mass spectrometry data processing algorithms to assign spectra to peptide sequences. In a typical workflow (Figure 18), spectra can only be matched to known peptide sequences; therefore, proteome coverage is inherently sensitive to how precise and complete the genome annotation is. At the time of writing, the highest honey bee proteome coverage yet published in a single study is 4,604 unique protein groups (McAfee et al., 2021), obtained from unfractionated shot-gun analysis of n = 28 samples of eggs, but identifications more typically range from 1,000-3,000 protein groups (McAfee et al., 2016). Here, we outline the experimental procedure and data processing steps used to obtain this high-coverage dataset, although there are many potential variations on the protocol to fit different needs (e.g. alternate lysis buffers, digestion buffers, precipitation methods, peptide desalting approaches, chromatography systems, etc.). The following methods work well for most honey bee proteomics samples.</p> <p></p>"},{"location":"Section_8_1/#figure-18-schematic-of-a-typical-shot-gun-proteomics-workflow","title":"Figure 18. Schematic of a typical shot-gun proteomics workflow.","text":""},{"location":"Section_8_2/","title":"8. Proteomics","text":""},{"location":"Section_8_2/#82-standard-methods-for-shot-gun-proteomics-sample-preparation","title":"8.2. Standard methods for shot-gun proteomics sample preparation","text":""},{"location":"Section_8_2/#821-considerations","title":"8.2.1. Considerations","text":""},{"location":"Section_8_2/#8211-general","title":"8.2.1.1. General","text":"<ul> <li> <p>Depending on the type of tissue, expect between 1 and 10% of the total wet mass to be made up of protein.</p> </li> <li> <p>Aim to digest 10-30 \u00b5g of protein per sample \u2013 more if performing additional sample enrichment or fractionation steps (e.g. high-pH reverse phase fractionation, phosphopeptide enrichment, size exclusion chromatography, etc) ahead of LC-MS/MS (reviewed elsewhere (Hedrick et al., 2015)).</p> </li> <li> <p>Mass spectrometer and liquid chromatography parameters are reviewed elsewhere (Savaryn et al., 2016).</p> </li> </ul>"},{"location":"Section_8_2/#8212-sample-handling","title":"8.2.1.2. Sample handling","text":"<ul> <li> <p>Always use gloves and keep the workspace free from dust to prevent keratin contamination. Do not wear wool clothing.</p> </li> <li> <p>Adult honey bees and larvae can be coated with unwanted substances (e.g. honey, pollen, or royal jelly). Wash the samples by gently vortexing one or more times in phosphate-buffered saline (1x PBS) prior to lysis to help remove contaminants.</p> </li> <li> <p>If preparing fatty tissue samples, such as fat bodies, avoid retaining the top layer of fat after clarifying the lysate.</p> </li> <li> <p>If preparing gut samples, consider that there could be many plant, fungal, and bacterial proteins present inside. These could be washed out or included in the analysis, depending on the purpose of the experiment. But, if included, their protein sequences must be added to the search database in order to identify them.</p> </li> <li> <p>Guanidinium chloride will denature enzymes and must be removed from the sample or diluted prior to digestion. Protease inhibitors are not necessary during sample lysis if using a guanidinium chloride extraction buffer, but may be considered if a non-denaturing buffer is used.</p> </li> <li> <p>Mass spectrometry is not compatible with polymers (e.g., polyethylene glycol, PEG) and detergents (e.g., sodium dodecyl sulfate, SDS). If such reagents come in contact with the sample, they must be removed prior to mass spectrometry analysis. Consult Keller et al. (2008) for a list of common contaminants.</p> </li> <li> <p>Mass spectrometry data analysis is not compatible with disulfide bonds between peptides. Disulfide bonds must therefore be reduced and alkylated to block the reactive sulfur.</p> </li> </ul>"},{"location":"Section_8_2/#8213-reagent-handling","title":"8.2.1.3. Reagent handling","text":"<ul> <li> <p>All reagents should be mass spectrometry grade.</p> </li> <li> <p>When preparing reagents with undiluted strong acids, use glass pipettes for dispensing, as polymers and plasticizers can leach from plastics in contact with strong acids.</p> </li> </ul>"},{"location":"Section_8_2/#822-materials","title":"8.2.2. Materials","text":"<ul> <li> <p>Large equipment: sample homogenizer (e.g. Precellys 24), speed-vac, centrifuge, bath sonicator (optional), liquid chromatography system coupled to a mass spectrometer (see Section 8.3 for more details)</p> </li> <li> <p>Homogenization tubes (e.g. 2 mL DuraTubes) and ceramic homogenization beads</p> </li> <li> <p>C18 membrane or inert material for a column frit</p> </li> <li> <p>Bulk C18 powder (e.g. ReproSil-Pur 120 C18-AQ, 2.4 \u00b5m)</p> </li> <li> <p>Lysis buffer (6 M guanidinium chloride, 100 mM Tris, pH 8.0) \u2013 store at room temperature (RT) for several days, or 4 \u00b0C for weeks or months</p> </li> <li> <p>100% acetone (pre-chilled to -20 \u00b0C)</p> </li> <li> <p>80% acetone in water (pre-chilled to -20 \u00b0C)</p> </li> <li> <p>Bradford assay reagents (store at 4 \u00b0C)</p> </li> <li> <p>Step 1 digestion buffer (6 M urea, 2 M thiourea, 100 mM Tris, pH 8.0) \u2013 make fresh</p> </li> <li> <p>Step 2 digestion buffer (50 mM ammonium bicarbonate, pH 8.0) \u2013 make fresh</p> </li> <li> <p>Endoproteinase lys-C, mass spectrometry grade (see manufacturer\u2019s protocol for storage)</p> </li> <li> <p>Porcine-modified trypsin, mass spectrometry grade (see manufacturer\u2019s protocol for storage)</p> </li> <li> <p>Dithiothreitol (DTT; 0.5 \u00b5g/\u00b5l in water) \u2013 store at -20 \u00b0C</p> </li> <li> <p>Iodoacetamide (IAA; 1 \u00b5g/\u00b5l in water) \u2013 store at -20 \u00b0C, sensitive to light</p> </li> <li> <p>Buffer A (0.2% trifluoroacetic acid in water) \u2013 store at RT</p> </li> <li> <p>Buffer B (0.1% formic acid, 80% acetonitrile in water) \u2013 store at RT</p> </li> <li> <p>Elution buffer (0.1% formic acid, 40% acetonitrile in water) \u2013 store at RT</p> </li> <li> <p>Resuspension buffer (0.1% formic acid, 2% acetonitrile in water \u2013 store at RT</p> </li> </ul>"},{"location":"Section_8_2/#823-proteomics-methods","title":"8.2.3. Proteomics methods","text":""},{"location":"Section_8_2/#8231-lysis-and-precipitation","title":"8.2.3.1. Lysis and precipitation","text":"<ol> <li> <p>Place the tissue sample (1 \u2013 100 mg) in a homogenization tube with four ceramic beads and cold lysis buffer (maximum ratio: 100 mg tissue per mL). Work on ice.</p> </li> <li> <p>Homogenize the sample (3 x 30 s, 1 min on ice in between, maximum frequency 6,000 rpm).</p> <p>TIP: The sample should be pulverized with no large pieces left in the solution. If you do not have a bead mill homogenizer and have a large sample quantity, the sample can be ground in liquid nitrogen with a mortar and pestle, then transferred to a tube containing lysis buffer.</p> </li> <li> <p>Quick spin, then transfer lysate to a new tube. Spin sample at 16,000 g for 10 min (4 \u00b0C) to remove debris. Transfer supernatant to a new tube. Repeat if necessary.</p> </li> <li> <p>Precipitate protein from the clarified lysate by adding 4x the sample volume of ice-cold 100% acetone (-20 \u00b0C, overnight - final solution should be 80% acetone).</p> </li> <li> <p>Spin sample at 5,000 g (15 min, 4 \u00b0C) to pellet precipitated protein. Discard the supernatant and wash the pellet with 500 \u00b5l ice-cold 80% acetone. For large pellets, disrupt with the pipet tip or sonicator for complete washing. Repeat, spin again, and discard the final supernatant.</p> </li> <li> <p>Allow residual acetone to air dry until the tube is odorless (~5 min, RT). TIP: Careful not to over-dry or the pellet will be difficult to resuspend.</p> </li> </ol>"},{"location":"Section_8_2/#8232-solubilization-and-digestion","title":"8.2.3.2. Solubilization and digestion","text":"<ol> <li>Solubilize the pellet in step 1 digestion buffer. TIP: Do not heat samples in urea. If the pellet is difficult to solubilize, sonicate in an ice water bath instead.</li> <li>Estimate protein concentration using a Bradford assay.</li> <li>Reduce disulfide bonds by adding 1 \u00b5g DTT per 50 \u00b5g protein, incubate at RT, 30 min.</li> <li>Alkylate cysteine residues by adding 5 \u00b5g IAA per 50 \u00b5g protein, incubate at RT, 20 min. TIP: IAA is light-sensitive \u2013 keep the reaction and reagents in the dark.</li> <li>Digest protein by adding 1 \u00b5g lys-C per 50 \u00b5g protein, incubate at RT, 3 h, dark.</li> <li>Dilute the mixture with six volumes of step 2 digestion buffer and add 1 \u00b5g trypsin per 50 \u00b5g protein, incubate at RT at least 4 h (up to overnight), dark.</li> <li>When complete, acidify the peptide digest to pH &lt; 2.0 using 20% formic acid diluted in water. Check pH by dispensing a small amount (~0.2 \u03bcl) onto a pH test strip.</li> </ol>"},{"location":"Section_8_2/#8233-peptide-desalting-and-resuspension","title":"8.2.3.3. Peptide desalting and resuspension","text":"<ol> <li>Prepare desalting \u2018columns\u2019 (Rappsilber et al., 2003) by punching out small disks of C18 Empore filter using a 17 G flat-tipped syringe and ejecting the disks into P200 pipette tips. Ensure that the disk is securely wedged in the bottom of the tip. Stack bulk C18 powder above the disk by suspending the powder in methanol and pipetting it into the tip. Elute the methanol either by centrifugation or by pressurizing the tip with a syringe barrel. The C18 stack should be ~1 cm tall and can desalt a sample containing ~50 \u00b5g of peptides, although capacity may vary depending on the type of bulk C18 material used.</li> <li>Wash the column with 200 \u00b5l Buffer B. Discard eluate. If any C18 columns have visible channels or dead volume after this stage, do not use the column.</li> <li>Condition the column with 200 \u00b5l Buffer A. Discard eluate.</li> <li>Load the column with the peptide digest sample. Discard eluate.</li> <li>Wash the column at least twice with 200 \u00b5l Buffer A. Discard eluate.</li> <li>Elute peptides into a clean tube with 200 \u00b5l elution buffer. Repeat for complete elution (expect one elution to yield ~90% of peptides).</li> <li>Evaporate the sample in a vacuum centrifuge (RT) until dry.</li> <li>Dissolve peptides in resuspension buffer and quantify by nanodrop. Equalize the sample concentrations. TIP: If an absorbance peak is observed at 240 nm, this likely indicates residual urea/thiourea contamination. The sample may need to be desalted again</li> <li>Centrifuge diluted samples at 16,000 g (10 min) to remove potential particulates from solution. Transfer the supernatants in randomized order to a 96-well autosampler plate for LC-MS/MS.</li> </ol>"},{"location":"Section_8_3/","title":"8. Proteomics","text":""},{"location":"Section_8_3/#83-liquid-chromatography-and-mass-spectrometry","title":"8.3. Liquid chromatography and mass spectrometry","text":"<p>There are many types of columns, chromatography systems, and mass spectrometers that can be used for proteomics, precluding a universal standard method. Here we offer four main points to consider when deciding on a specific approach.</p> <ol> <li> <p>The amount of sample to inject depends on the sample complexity, chromatography resolution, and instrument sensitivity, but it is normally in the range of 0.1 \u2013 1 \u00b5g (lower complexity samples will require less material to inject).</p> </li> <li> <p>If a sample has high complexity but is dominated by a relatively small number of highly abundant peptides, such as what is routinely observed in mammalian plasma (Hortin &amp; Sviridov, 2010) or honey bee ejaculates (McAfee et al., 2020), the sample may benefit from orthogonal fractionation upstream of LC-MS/MS. That is, the peptides should be fractionated based on different chemical or physical properties than utilized in the downstream LC (which normally separates peptides based on hydrophobicity) in order to reduce ion suppression by the highly abundant species. Examples of orthogonal or semi-orthogonal fractionation techniques are high-pH reverse-phase fractionation (Batth et al., 2014), strong cation exchange (Edelmann, 2011), size exclusion chromatography (Kristensen et al., 2012), and isoelectric trapping (Cologna et al., 2010).</p> </li> <li> <p>The final stage of chromatography, which is online-coupled to the mass spectrometer, is nearly always C18 reverse phase run under acidic conditions. Different chromatography systems have different constraints, but in general, the length of the chromatography gradient trades off peak intensity with peak separation: longer gradients offer better separation, but eluent peaks are broader with lower intensity, which may affect spectrum quality. Gradients typically ramp from 2% to 80% acetonitrile over the course of 45 \u2013 180 minutes. Refer to vendor recommendations for information on column selection and instrument settings.</p> </li> <li> <p>There are two main data acquisition approaches for shot-gun proteomics: data-dependent acquisition (DDA) and data-independent acquisition (DIA) (Doerr, 2014). DIA is growing in popularity, as it is thought to yield more accurate, more reproducible, and higher coverage proteomic data (Barkovits et al., 2020), though this point is debated (Fern\u00e1ndez-Costa et al., 2020). DIA has, at the time of writing, not yet been applied to honey bees, and the approach has unique database considerations if a spectral library is used (Pino et al., 2020). The sample preparation methods covered here can be used for both DDA and DIA, but downstream data processing may differ. This is a technique to watch as it becomes more popular and widespread.</p> </li> </ol>"},{"location":"Section_8_4/","title":"8. Proteomics","text":""},{"location":"Section_8_4/#84-proteomics-data-processing","title":"8.4. Proteomics data processing","text":""},{"location":"Section_8_4/#841-software-recommendations","title":"8.4.1. Software recommendations","text":"<p>Raw mass spectrometry data must be \u2018searched\u2019 in order to derive biological meaning from it. That is, a computer algorithm matches mass spectra to peptide sequences, deconvolutes the pool of identified peptides into the most parsimonious set of proteins that must be present to explain all those peptides, translates peptide intensity data into quantitative protein data, and controls false discovery rates. While there are many software options available to perform these tasks (reviewed elsewhere (Verheggen et al., 2020)), we recommend MaxQuant (Cox &amp; Mann, 2008)owing to its i) high regard in the field, ii) robust label-free quantification (LFQ) algorithm, iii) delayed normalization feature to accommodate fractionated samples, iv) continual feature upgrades, v) capability of handling DIA and DDA data, and vi) lack of associated cost (please see the latest information from the annual MaxQuant Summer School for upcoming tutorials: https://maxquant.org/summer_school/)..) DIA-NN is also an excellent search tool which is especially well-suited for processing DIA data (Demichev et al., 2020). MaxQuant and DIA-NN are only compatible with Windows and Linux machines.Theoretically, spectra can also be sequenced de novo (without an existing protein database) using other software, such as PEAKS (B. Ma et al., 2003); however, this is only viable for very high-quality spectra and the resulting proteome coverage is therefore exceedingly low.</p>"},{"location":"Section_8_4/#8411-maxquant-and-dia-nn-search-parameters","title":"8.4.1.1. MaxQuant and DIA-NN search parameters","text":"<p>The default search parameters within MaxQuant and DIA-NN are generally appropriate for most shot-gun proteomics analyses, but some options should be considered (and see Sinitcyn et al. (2021) for handling DIA data in MaxQuant). In particular, \u201cmatch between runs\u201d or \u201cMBR\u201d is an option that increases sensitivity by borrowing peptide identification information across samples. For example, if a spectrum is confidently matched to a peptide in sample 1 but not sample 2, sample 2 is re-inspected for likely features of that spectrum, and, if found, it can receive the same peptide assignment. This approach assumes that if a peptide is confidently identified in one sample, it has a high likelihood of being present in other, similar samples, and the spectrum quality threshold for that peptide matching can be reasonably lowered. We recommend enabling this option in both MaxQuant and DIA-NN to reduce the frequency of missing data. In DIA-NN, \u201cunrelated runs\u201d should also be checked if samples represent independent replicates, and the \u201cProtein inference\u201d option should be set to \u201cProtein names (from FASTA)\u201d.</p>"},{"location":"Section_8_4/#8412-choosing-an-appropriate-protein-database","title":"8.4.1.2. Choosing an appropriate protein database","text":"<p>For typical shot-gun proteomics experiments, the data processing software requires at least two inputs: the raw data files and a database of proteins to which it can compare spectra. It is very important to choose an appropriate protein database; failure to do so can result in flawed data with an unacceptable level of false positive or false negative errors. One example of this happening in the literature includes a published paper claiming to discover a link between invertebrate iridescent virus-6, detected in honey bee proteomics samples, and colony collapse disorder (CCD) (Bromenshenk et al., 2010). The database used to search the mass spectrometry data included only viral protein sequences and no host (honey bee) proteins, despite host proteins composing the majority of the sample.</p> <p>This means that, since spectrum matching is a probabilistic task, it is possible for spectra from host peptides to match to viral peptides if those are the most likely assignments within the constraints of the protein database supplied. Indeed, that is exactly what happened, leading to incorrect peptide assignments, dramatically skewed false discoveries, and ultimately flawed conclusions. When the host proteins were included in the search database, spectra that previously matched to iridescent virus-6 actually had far higher scoring matches to host peptides, indicating that the virus was unlikely to have actually existed in the sample (Foster, 2011; Tokarz et al., 2011), let alone cause CCD.</p> <p>Since genome builds, as well as gene and protein annotation databases, are continually upgraded, the most up-to-date reference proteome should be used. Furthermore, and following the above discussion, the database should contain all sequences with a reasonable probability of being found in the sample. For honey bees, this means that, in addition to honey bee protein sequences, honey bee virus sequences should be included in the protein database (FASTA file) for virtually all sample types, given the high incidence of asymptomatic infections (Grozinger &amp; Flenniken, 2019). Nosema spp., chalkbrood (Ascosphaera apis), European foulbrood (Melissococcus plutonius), American foulbrood (Paenibacillus larvae), or any other likely pathogen or colonizing microbe may be added as well, if applicable. We recommend obtaining FASTA files from Uniprot due to the ease of subsequently incorporating gene ontology (GO) information during data analysis. We also recommend including protein sets for the core gut bacteria (Motta &amp; Moran, 2024) when bee abdomens form part of the sample (see Section 10).</p>"},{"location":"Section_8_4/#8413-statistical-analysis","title":"8.4.1.3 Statistical analysis","text":"<p>When finished searching, MaxQuant will output a series of tables, including one named ProteinGroups.txt, which contains the protein quantitation information with the dominant members of the protein groups and LFQ intensities. The equivalent output from DIA-NN is report.pg_matrix.tsv file. The matrix of protein names (rows) and LFQ intensities (columns) is used for subsequent differential expression analyses. Any proteins indicated as reverse hits, potential contaminants, or those only identified by site are undesirable and typically excluded. MaxQuant\u2019s companion program, Perseus (Tyanova et al., 2016), can be used for basic statistical tests and figure generation; however, most R packages originally intended for microarray or RNA-seq data analysis (e.g. limma (Ritchie et al., 2015)) are also appropriate for proteomics data and offer more flexibility. For users who are new to proteomics analysis, we recommend using Perseus, since it is a user-friendly platform developed specifically for proteomics, and is accompanied by detailed step-by-step tutorials (http://www.coxdocs.org/doku.php?id=perseus:user:use_cases:interactions) and lectures (http://www.coxdocs.org/doku.php?id=perseus:user:tutorials)..) The tutorial \u201clabel-free interaction data\u201d provides a detailed guide to data preparation (loading, filtering, transforming, etc.), quality control, statistical analyses, and visualization.Currently, Perseus is only compatible with Windows.</p> <p>Once differential expression analysis is complete, the results may be used for gene ontology (GO) term enrichment tests similar to what might be conducted for microarray or RNA-seq data. While a multitude of suitable tools exist for such analyses, reviewed in (Laukens et al., 2015), we recommend ErmineJ (Gillis et al., 2010; Lee et al., 2005) for its flexibility, simplicity, and capability for accounting for both multiple hypothesis testing and protein multifunctionality when determining enrichment significance.</p>"},{"location":"Section_8_5/","title":"8. Proteomics","text":""},{"location":"Section_8_5/#85-applications-and-limitations","title":"8.5. Applications and limitations","text":"<p>Shot-gun proteomics can be used to investigate anything from responses to pesticides, pathogens, nutritional stress, aging, and an endless array of other conditions (Arad et al., 2024). Proteomics has even been used to discover specific protein markers suitable for guiding selective breeding for varroa resistance mechanisms (Guarna et al., 2017). While LFQ proteomics is best suited to compare conditions across which the majority of proteins can be assumed to be expressed at the same abundance, with a smaller fraction of the proteome changing in response to a stimulus, meaningful results can be obtained from experiments with more dramatic proteomic shifts, such as between castes and across developmental stages. LFQ has been demonstrated to achieve accurate relative quantification even when approximately one-third of the proteome is changing in abundance (Cox et al., 2014).</p> <p>Although proteomics is an increasingly powerful technique, interpretation of the results can be challenging owing to limited functional annotation of the honey bee proteome (Elsik et al., 2018). Each protein can have one or more biological functions, which are associated with unique GO terms (Ashburner et al., 2000), to help derive biological meaning from the hundreds or thousands of proteins that are often differentially expressed in proteomics experiments. According to Hymenopteramine, a database of genomic resources for hymenopterans, only 7,929 out of 15,314 sequences (52%) in the honey bee official gene set (v3.2) were linked to GO terms as of 2018 (Elsik et al., 2018), meaning that the remaining sequences have poorly characterized functions. This figure has since increased (Walsh et al., 2022), but many uncharacterized genes remain. Our limited understanding of honey bee gene and protein functions means that high-throughput datasets can be difficult to interpret, as we are blind to the roles of a large fraction of the very targets we are analyzing.</p> <p>Because shot-gun proteomics requires protein digestion into peptides, and peptide sequences can be shared between different proteins, it is often difficult to say definitively to which protein the peptides belong. MaxQuant deals with this problem by reporting \u201cprotein groups,\u201d which offer the most parsimonious explanatory proteins likely to be present in the sample, rather than individual proteins. However, this also complicates GO term assignment: Since multiple different proteins can be listed in a single protein group, which GO terms should the protein group be given? A simple heuristic, though imperfect, is to assign a protein group with the GO terms associated with its leading protein. Since both GO terms and protein groups are defined based on sequence similarities, it is a reasonable assumption that proteins within a group will share GO terms. Alternatively, though more laboriously, GO terms associated with all proteins in the group can be linked.</p> <p>Unfortunately, for those proteins which are poorly characterized, it is difficult to generate functional information without a high-throughput way to generate gene knock-out (a gene is deleted or rendered nonfunctional) or knock-in (a gene is inserted) mutant organisms. Organisms such as Drosophila melanogaster and Mus musculus have benefitted from decades of detailed genetic and biochemical research into specific genes and proteins, but this is only recently possible for honey bees and is still far from routine (Kohno &amp; Kubo, 2019). While much information can be borrowed from what is known about homologous proteins in other species, honey bees diverged from flies about 300 million years ago (Honeybee Genome Sequencing Consortium, 2006) and therefore have experienced considerable sequence divergence. Until we know more about the functions of all honey bee proteins, we will not be able to interpret high-throughput differential expression data to its full potential.</p>"},{"location":"Section_9_1/","title":"9. Metabolomics","text":""},{"location":"Section_9_1/#91-introduction","title":"9.1. Introduction","text":"<p>Metabolomics is the study of small molecules, metabolites, and biological intermediate substrates. This omics tool has become very popular within the last decade, including among entomologists (Snart et al., 2015), and applications to understand the biology of honey bees (Ardalani et al., 2021; Broadrup et al., 2019; Chandrasekaran et al., 2015; Chang et al., 2022; Chen et al., 2021; du Rand et al., 2017; Jousse et al., 2020; Klupczynska et al., 2020; Li et al., 2020, 2023; Ma et al., 2024; Paten et al., 2022; Pratavieira et al., 2020; Rand et al., 2015; Ricigliano et al., 2022; Rothman et al., 2019; Shi et al., 2018; Wang et al., 2022; Wu et al., 2024; Wu et al., 2017; Xu et al., 2024; Zhang et al., 2022; Zhao et al., 2020; Zhong et al., 2024), the relationship with their symbionts (Ke\u0161nerov\u00e1 et al., 2017; Quinn et al., 2024; Zhang et al., 2022; Zheng et al., 2017), and characteristics of colony products (Arathi et al., 2018; Baky et al., 2023; Chakrabarti et al., 2019; Guo et al., 2020; Koulis et al., 2021; Li et al., 2019; Milone et al., 2021; Qi et al., 2023; Sun et al., 2021; Virgiliou et al., 2020; Wang et al., 2022; Wilson et al., 2013; Yan et al., 2024; Yusoff et al., 2022) are expanding (see Jung (2023) for a brief review). The method allows small molecules to be characterized in a biological system, and is an important complement to more established omics methods, such as genomics, transcriptomics and proteomics. In fact, metabolomics is often considered as the final piece of the omics puzzle (Veenstra, 2012). Metabolomic investigations can be conducted using nuclear magnetic resonance (NMR), capillary electrophoresis mass spectrometry (CE-MS), gas chromatography mass spectrometry (GC-MS) or liquid chromatography tandem mass spectrometry (LC-MSMS) (reviewed in Munjal et al. (2022)). LC-MSMS is the most commonly used technique and is the one we focus on here.</p> <p>Unlike the other omics tools, where species-specific sequence libraries are required, one advantage of metabolomics is that a general library of small molecule fragmentation patterns has been established. Fragmentation patterns and other characteristics (mass, isotope ratio, and retention time) determine the metabolite being identified, rather than a specific sequence of the organism. Metabolomics is thus a widely applicable tool, especially for honey bees, where researchers are trying to assess the biological processes of development or the physiological impacts of various stressors (pesticides, malnutrition, mites, etc.) or other stimuli.</p> <p>The following general method has been successfully applied to analyze honey bee pollen (Chakrabarti et al., 2019) and royal jelly (Milone et al., 2021), but also works well for conducting metabolite detection in honey bee tissues, where the method has enabled identification of 251 high-confidence metabolites from whole honey bees (Chakrabarti et al., manuscript in preparation). However, as there are many sample types and desired compound classes of potential interest, variations of this protocol may work better for certain applications. For example, while methanol/water extractions are commonly conducted (e.g. Paten et al., 2022; Chang et al., 2023; Xu et al., 2024), extraction solvents composed of a mix of acetonitrile, methanol, and water (e.g. Chen et al., 2021; Zhang et al., 2022; Ma et al., 2024), acetonitrile and methanol (e.g. Liu et al., 2023; Wu et al., 2024), or methanol and chloroform (e.g. Ricigliano et al., (2022)) have also been used for honey bee tissues. The choice of extraction solvent depends on the polarity of the desired metabolites, and additional extraction techniques developed for mammalian tissues (Sitnikov et al., 2016) are likely also applicable to honey bees. For example, in a preprint report, (McAfee et al., 2024) recently applied a two-phase extraction technique (using an initial methanol/water extraction followed by addition of methylated tert butyl ether) developed by (Chen et al., 2013) [1] for mouse liver samples for parallel analysis of the metabolome, lipidome, and pheromone profiles from queen honey bee heads. The following protocol serves as a starting point for researchers interested in conducting metabolomics, with the knowledge that there are many possible variations of the general technique, particularly with respect to the extraction solvent and liquid chromatography solvents.</p> <p>The method described here is intended for a semi-quantitative (i.e. relative quantitation, which is suitable for differential abundance testing but does not provide information on absolute quantities), untargeted metabolomics approach. These sample preparation guidelines are also applicable to absolute quantitation, provided that the user includes the additional step of creating standard curves for each analyte. However, as untargeted semi-quantitative analysis is the most widely used method, that is the application we focus on for both sample preparation and data analysis methods. Interested readers should familiarize themselves with existing overviews of sample preparation and data acquisition (Broadhurst et al., 2018; David &amp; Rostkowski, 2020; Defossez et al., 2023; Munjal et al., 2022; Rampler et al., 2021), statistical analysis (Bartel et al., 2013; Chen et al., 2022; Xi et al., 2014), and reporting (Alseekh et al., 2021; Sumner et al., 2007) described elsewhere.</p>"},{"location":"Section_9_2/","title":"9. Metabolomics","text":""},{"location":"Section_9_2/#92-sample-preparation-for-metabolomics","title":"9.2. Sample preparation for metabolomics","text":""},{"location":"Section_9_2/#921-considerations","title":"9.2.1. Considerations","text":""},{"location":"Section_9_2/#9211-general","title":"9.2.1.1. General","text":"<ul> <li> <p>Metabolomics experiments may be either focused on discovery (untargeted analysis; e.g. discovery of metabolome changes in response to stimuli) or monitoring changes in or presence of an a priori defined set of compounds (targeted analysis). This protocol may need to be adjusted if the analytes of interest are better extracted in another solvent or better separated with another LC gradient.</p> </li> <li> <p>Untargeted metabolomics analysis is normally conducted using high-resolution instruments such as Q-TOF or Orbitrap mass spectrometers while targeted metabolomics may be performed with low resolution, highly selective mass spectrometers such as triple quadrupoles (QQQs). Ensure the instrumentation available meets the needs of your experiment and sample complexity</p> </li> <li> <p>Mass spectrometer sensitivity may drift between runs. Running QCs every few samples is thus useful for data normalization. Constitute quality control (QC) samples by mixing equal volumes from all samples.</p> </li> <li> <p>Data acquisition can be performed in both positive and negative ion mode, and small molecules may be more amenable to one or the other depending on their structure and functional groups. Though time consuming, analyzing samples in both negative and positive ionization modes captures a wider spectrum of metabolites.</p> </li> <li> <p>Aim to inject 1-10 \u00b5l of sample into the column. Before running a batch of new samples, check the concentrations by running a diluted test sample. This will help gauge the amount to inject to avoid overloading or underloading the instrument.</p> </li> <li> <p>Adding a generic internal standard during sample preparation can help the user compare data between sample runs and facilitate relative quantitation. However, for absolute quantitation, either isotopically-labeled internal standards matching the compound of interest or external standard curves of the unlabelled compound are required.</p> </li> </ul>"},{"location":"Section_9_2/#9212-sample-handling","title":"9.2.1.2. Sample handling","text":"<ul> <li> <p>Store samples at -80 \u00b0C</p> </li> <li> <p>Sample processing is somewhat dependent on the type of metabolite to be extracted and identified. Generally, methanol:water extractions work well, but the extraction solvent may need to be adjusted to best capture specific classes of compounds (see Section 9.1).</p> </li> <li> <p>The step at which an internal standard is added may vary. Adding the standard before homogenization accounts for variation in extraction efficiency, while adding the standard immediately ahead of injection will ensure the same amount is present in each sample. If desired, two sets of internal standards may be added at different points in the sample processing protocol.</p> </li> <li> <p>Blank samples should be prepared in parallel with real samples in order to determine what compounds are contaminants introduced from solvents, plastics, and the environment. These blank samples should be analyzed at regular intervals during data acquisition and it is good practice to either subtract the average intensities of compounds in the blank samples from those in real samples, or to only retain sample compounds present at an abundance above a threshold factor over the blanks (e.g. 5-fold higher in real samples than blanks)</p> </li> <li> <p>Solvent-only injections may also be performed at regular intervals in order to assess sample carry-over between injections as well as potential system contamination. These injections are distinct from blank samples in that they are not derived from parallel processing of real samples; instead, they are comprised of pure reconstitution buffer</p> </li> <li> <p>LC-MS/MS instruments with auto-samplers require HPLC vials (~ 2 mL). For small volume samples, a 300 \u00b5l vial insert may be required.</p> </li> </ul>"},{"location":"Section_9_2/#9213-reagent-handling","title":"9.2.1.3. Reagent handling","text":"<ul> <li> <p>All reagents and solvents should be mass spectrometry grade. Care must be taken to avoid any impurities in the reagents and chemicals used.</p> </li> <li> <p>Prepare fresh buffers and solutions.</p> </li> </ul>"},{"location":"Section_9_2/#922-materials","title":"9.2.2. Materials","text":"<ul> <li> <p>Large equipment: homogenizer or bead beater, centrifuge, speed vacuum concentrator, -80 \u00b0C and -20 \u00b0C freezers, a vortex, and liquid chromatography system coupled to a mass spectrometer (for example, a high-resolution system such as a Nexera LC30 UPLC (Shimadzu) coupled to a quadrupole-time-of-flight mass spectrometer (TripleTOF 5600, AB SCIEX), but see Section 9.3)</p> </li> <li> <p>In-house library of metabolites (such as the IROA Mass Spectrometry Metabolite Library of Standards)</p> </li> <li> <p>Mass spectrometry grade methanol, water, formic acid, and acetonitrile</p> </li> <li> <p>Homogenization tubes and beads</p> </li> </ul>"},{"location":"Section_9_2/#923-metabolomics-methods","title":"9.2.3. Metabolomics methods","text":""},{"location":"Section_9_2/#9231-sample-homogenization","title":"9.2.3.1. Sample homogenization","text":"<ol> <li> <p>Homogenize 50 mg of sample in 0.5 ml of methanol and water solution (80:20 v/v) in a homogenizer (for example, a QIAGEN TissueLyser or Precellys 24 tissue homogenizer). Use tubes and tips without color. TIP: Including BHT (butylated hydroxytoluene) at 0.01% in the extraction solvent protects compounds from oxidation</p> </li> <li> <p>Homogenize until the tissues are broken down into minute particles to maximize extraction.</p> </li> </ol>"},{"location":"Section_9_2/#9232-extraction","title":"9.2.3.2. Extraction","text":"<ol> <li> <p>Incubate samples for at least 1 hour at -20 \u00b0C to allow metabolites to be extracted and proteins to precipitate.</p> </li> <li> <p>Centrifuge at 10,000 g for 10 min (4 \u00b0C) to pellet the precipitate containing proteins and other cellular debris.</p> </li> <li> <p>Transfer 400 \u00b5l of the supernatant to a clean 2 ml tube and evaporate to dryness in a speed vacuum concentrator.</p> </li> <li> <p>Reconstitute dry extracts in 200 \u00b5l of acetonitrile:water solution (1:1 v/v).</p> </li> <li> <p>Vortex the tube for 30 s and centrifuge for 10 min at 10,000 g (4 \u00b0C).</p> </li> <li> <p>Collect the supernatants and transfer them to HPLC vials.</p> </li> <li> <p>If not immediately conducting mass spectrometry, store the samples at -80 \u00b0C until analysis. Re-centrifuge the samples before LC-MS/MS to remove any precipitates.</p> </li> </ol>"},{"location":"Section_9_3/","title":"9. Metabolomics","text":""},{"location":"Section_9_3/#93-chromatography-and-mass-spectrometry","title":"9.3. Chromatography and mass spectrometry","text":"<p>Similar to proteomics (see Section 8), there are numerous options for chromatography and mass spectrometer instruments and acquisition methods. Additional considerations for chromatography and mass spectrometry are as follows:</p> <ol> <li> <p>The methods described here have been used successfully with a Nexera LC30 UPLC (Shimadzu), coupled to a quadrupole-time-of-flight mass spectrometer (ABSCIEX TripleTOF 5600); however, other combinations are possible. High-resolution mass spectrometers require occasional calibration. Time of flight mass spectrometers (TOFs), for example, require calibration every 2 to 3 hours to retain &lt; 3 ppm mass accuracy.</p> </li> <li> <p>The HPLC column is used to separate metabolites and other small molecules based on polarity (Figure 19). The LC-MS/MS approach described here has been used with an Inertsil Phenyl-3 stationary phase column (such as 150 mm \u00d7 4.6 mm, 5 \u00b5m by GL Sciences), but other columns may be better suited for analyzing different kinds of metabolites. Common columns include BEH C18 and ACQUITY HSS T3 (both manufactured by Waters) because they are suitable for analytes with a broad range of molecular weights and polarity.</p> </li> <li> <p>A guard column can be used to avoid unrecoverable column contamination. In case of contamination or sample impurities, the guard column can be discarded and replaced, thereby retaining the functionality of the HPLC column and extending its lifespan.</p> </li> <li> <p>For specialized small molecule analyses, an entirely different extraction and analysis method may be needed. Queen mandibular pheromone, for example, is typically extracted in ether, derivatized, and analyzed by GC-MS), rather than LC-MSMS, although a recent report does describe successful utilization of LC-MSMS for this purpose (McAfee et al., 2024). Some testing may be required to see which method works best for your target analytes. In addition, small and/or highly polar metabolites may not be compatible with reverse-phase chromatography; such compounds may require specialized chromatography techniques (e.g. hydrophilic interaction liquid chromatography, or HILIC; (Buszewski &amp; Noga, 2012) or derivatization and analysis by GC-MS (De Souza, 2013).</p> </li> <li> <p>Data is normally acquired in data-dependent acquisition mode (DDA; also known as information dependent acquisition, or IDA). Survey scans are acquired followed by a specified number of MS/MS spectra in a given scan. This results in a \u201cfeature,\u201d i.e., a mass, retention time, isotope ratio, and an MS/MS fragmentation pattern (Figure 20). In DDA mode, parent ion peaks are selected for fragmentation based on their intensities (ions producing the most intense peaks are selected). The number of ions that can be fragmented is finite and depends on the speed of the instrumentation. Data-independent acquisition (DIA) is also available for metabolomics analysis, and although it results in lower spectrum quality than DDA, DIA appears to be more precise and has better fragmentation spectrum coverage (Guo &amp; Huan, 2020).</p> </li> <li> <p>Sample injections should always be randomized. In addition, blanks and QCs should be run at the beginning, during, and at the end of injection sequences to help correct for drifting signal intensities. This is especially important for large batch metabolomics.</p> </li> <li> <p>Gradients for metabolite elution may vary. This is experimentally derived to separate and optimize metabolite identification. For honey bee metabolomics, the following gradient has been successfully used (solvent A: 100% water containing 0.1% formic acid; solvent B: 100% methanol containing 0.1% formic acid): 0.0 min \\@ 5% Solvent B; 1 min \\@ 5% solvent B; 11 min \\@ 30% solvent B; 23 min \\@ 100% solvent B: 35 Min \\@ 100% solvent B; 37 min \\@ 5% solvent B; 50 minutes stop chromatography. While gradients using methanol are common (e.g. Zhang et al., 2022; Liu et al., 2023, McAfee et al., 2024), it may also be appropriate to use acetonitrile (e.g. Shi et al., 2018; Paten et al., 2022; Wu et al., 2024; Zhong et al., 2024) and additives such as ammonium formate (e.g. Xu et al., 2024), or ammonium acetate and ammonium hydroxide (e.g. Ma et al., 2024), depending on the chemical properties of the analytes to be separated. Refer to the vendor instructions when choosing the column and guard column, flow rate, solvent composition, and column cleaning tips. A GL Sciences Phenyl 3 column (4.6 x 150mm, 5 uM particle size) was used for this metabolomics profile.</p> </li> </ol> <p></p>"},{"location":"Section_9_3/#figure-19-example-of-the-chromatographic-profiles-tic-total-ion-chromatogram-typical-compound-classes-amino-acids-lipids-and-organic-acids-are-identified-in-the-different-regions-during-the-hplc-gradient","title":"Figure 19. Example of the chromatographic profiles TIC (total ion chromatogram). Typical compound classes; amino acids, lipids and organic acids are identified in the different regions during the HPLC gradient.","text":""},{"location":"Section_9_3/#figure-20-description-of-an-ida-information-dependent-acquisition-feature-a-a-total-ion-chromatogram-of-all-ions-detected-in-the-sample-each-ion-feature-has-a-corresponding-b-extracted-ion-chromatogram-in-this-case-for-the-20510-parent-ion-c-survey-spectrum-scan-containing-the-ion-at-a-given-retention-time-and-d-fragmentation-spectrum-for-the-given-parent-ion-and-retention-time","title":"Figure 20. Description of an IDA (information dependent acquisition) feature. A) A total ion chromatogram of all ions detected in the sample. Each ion (feature) has a corresponding B) Extracted ion chromatogram (in this case, for the 205.10 parent ion), C) Survey spectrum scan containing the ion at a given retention time, and D) Fragmentation spectrum for the given parent ion and retention time.","text":""},{"location":"Section_9_4/","title":"9. Metabolomics","text":""},{"location":"Section_9_4/#94-metabolomics-data-processing","title":"9.4. Metabolomics data processing","text":"<p>The essential steps of metabolomics data processing that are required ahead of statistical analysis are peak picking (selecting chromatographic peaks), alignment (correcting for shifts in retention times), deconvolution (separating composite spectra from co-eluting analytes), integration (calculating peak areas), normalization (correcting for variation in sample injection amounts), and database querying/searching (annotating peaks with compound identities). The final result of these processing steps is a data matrix of samples and high-confidence compounds with their intensities that can be used for statistical analysis (differential abundance testing, pathway enrichments, etc.).</p> <p>These informatic tasks can only be achieved with the help of specialized software (see Chen et al. (2022) for an outline of workflows and software options), which may include either commercial vendor software, free software available online, or a combination of both. In some cases, all essential data processing steps can be achieved within one software platform, whereas others may require a combination of tools (see below for examples). Regardless of the workflow employed, users should be familiar with the minimum reporting criteria outlined by the Metabolomics Standards Initiative before commencing (Spicer et al., 2017; Sumner et al., 2007).</p> <p>Examples of paid software include Peakview (AB SCIEX) for peak visualization and compound identification, and MultiQuant (AB SCIEX) for feature integration, among other instrument-specific options. Progenesis QI (Waters, Nonlinear dynamics) is another popular paid software that can achieve all aspects of raw data processing when accompanied by the METLIN (discussed further below) plugin for database querying. Reifycs is another cross-instrument paid software option which supports various data formats and negates the need to purchase dedicated software for each mass spectrometry instrument.</p> <p>Freely available software is also highly regarded in the field and can be used to process data from many types of instruments, provided the raw spectrum data files can be converted to the required input format. For example, MetaboAnalyst is one of the most widely used metabolomics data processing tools and can be used for several raw data types, once converted from the vendor data format to NetCDF, mzXML, or mzDATA format. The newest release of MetaboAnalyst (v. 6.0) includes updated processing and peak annotation modules for fragmentation (MS/MS) spectra and more sophisticated downstream statistical analysis modules (Pang et al., 2024). MSDial is another popular tool for raw data processing, which requires data in analysis base file (ABF) format (Tsugawa et al., 2015). The task of converting data files to the formats required by different software can be achieved using open-source tools available through ProteoWizard or tools such as Reifycs Abf (for conversion to ABF format; available at https://www.reifycs.com/AbfConverter/index.html).</p> <p>The ultimate goal of metabolomics is to identify and quantify small molecule metabolites in a biological system, so, clearly, the task of assigning spectra to correct compound identities is critical. After peak picking, alignment, deconvolution, integration, and normalization, metabolites are tentatively identified by matching their masses, fragmentation patterns, isotope distributions, and retention times (Figure 21), to corresponding data from an in-house chemical library, in silico library, or both. An in-house chemical library is a purchased set of metabolite standards (e.g., the IROA library) that are used to acquire reference data using the same conditions as the metabolomics HPLC gradient, whereas an in silico library is a database of spectra and compound identities (which should be derived from the same instrumentation used to acquire the experimental data). Examples of online in silico resources include METLIN, NIST17, MassBank Europe (mass spectral database of Europe) and MoNA MS/MS libraries (MassBank of North America) (Ardalani et al., 2021). The METLIN database used to be publicly available (Guijas et al., 2018), but the updated version (XCMS-METLIN) is now behind a paywall. NIST17 is also a paid resource, with mass spectral libraries as well as various software tools that are needed to analyze the datasets. MoNA is a free database currently housing over two million mass spectral records from multiple data sources, such as experimental libraries with established datasets, in silico libraries, as well as information sourced from general user contributions. Regardless of the software or libraries used, it is essential to manually check each feature\u2019s integration and qualifying attributes before including them in the list of tentatively identified metabolites, otherwise the risk of misassignment is high.</p>"},{"location":"Section_9_4/#_1","title":"9.4. Metabolomics data processing","text":""},{"location":"Section_9_4/#figure-21-example-of-methodology-for-tentative-metabolite-identification-tryptophan-is-used-in-this-example-a-the-extracted-ion-chromatogram-is-compared-with-an-established-hplc-method-library-with-known-retention-times-for-the-metabolite-of-interest-b-the-survey-spectrum-to-compare-mass-measurements-mass-error-should-be-less-than-5-ppm-in-this-example-the-mass-error-is-06-ppm-c-isotope-pattern-the-theoretical-isotope-distribution-for-tryptophan-is-compared-to-the-observed-isotope-ratio-d-library-msms-spectrum-matching-observed-msms-is-compared-to-the-iroa-library-msms-spectrum-for-tryptophan","title":"Figure 21. Example of methodology for tentative metabolite identification. Tryptophan is used in this example. A) The extracted ion chromatogram is compared with an established HPLC method library with known retention times for the metabolite of interest. B) The survey spectrum to compare mass measurements. Mass error should be less than 5 ppm. In this example the mass error is 0.6 ppm. C) Isotope pattern. The theoretical isotope distribution for tryptophan is compared to the observed isotope ratio. D) Library MS/MS spectrum matching. Observed MS/MS is compared to the IROA library MS/MS spectrum for tryptophan.","text":"<p>Once the data are extracted and in \u201c.xls\u201d or \u201c.csv\u201d format, a wide range of statistics and visualization methods can be used, such as producing heat maps, hierarchical clustering, principal component analysis, and correlation matrices, or performing comparisons using t-tests or ANOVAs (with multiple hypothesis testing corrections), etc. These statistical approaches are essentially the same as for other high-throughput biological data, such as proteomics or RNA-seq. To visualize data (as, e.g., PCA plots, heat maps, dendrograms, etc.), analytical software such as MarkerView (AB SCIEX) or Progenesis QI can be used. As mentioned earlier, the freely available software MetaboAnalyst, which enables a user to directly upload mass spectrometry files to the online platform, is especially appealing with its updated statistical analysis module (it can now handle more complex experimental designs) and new module for estimating causal relationships between metabolites and phenotypes (Pang et al., 2024). This software can also compute pathway analysis, enrichment analysis, biomarker analysis, network analysis, joint pathway analysis, and has an associated package for use in R (MetaboAnalystR; (Chong &amp; Xia, 2018)). Please see Chen et al. (2022) for additional statistical analysis workflows and methods.</p>"},{"location":"Section_9_5/","title":"9. Metabolomics","text":""},{"location":"Section_9_5/#95-metabolomics-applications-and-limitations","title":"9.5. Metabolomics applications and limitations","text":"<p>Metabolomics is gaining popularity due to the vast spectrum of metabolites that can be identified and compared between samples. Using mass spectrometry for metabolomics has many advantages over traditional biochemical assays, such as high sensitivity and the ability to detect a large number of metabolites and small molecules from very small sample sizes (Veenstra, 2012). In addition, with the availability of better databases, identification of small molecules has become easier. But despite the effort that goes into sample preparation and analysis, metabolomic identifications are only tentative detections until retention times and fragmentation patterns are confirmed with high-purity analytical standards, whether part of an in-house library or purchased separately. When this confirmation is achieved, such compounds may rise to the level of being \u201cidentified\u201d (i.e., level 1 annotation, as opposed to levels 2, 3, and 4, corresponding to \u201cputatively annotated compounds,\u201d \u201cputatively annotated compound classes,\u201d and \u201cunknown compounds,\u201d respectively (Sumner et al., 2007).</p> <p>Features must always be compared with an MS/MS spectral library (e.g. METLIN) when compounds are not an exact match with those within the in-house library. In this case, a high-purity standard must be purchased to confirm a tentative assignment. Furthermore, for absolute quantitation of targeted metabolomics, isotopically labeled and unlabeled standards are required for exact quantifications of the targeted small molecules. While labeled standards are used as internal standards, unlabeled standards are used for creating standard curves for absolute quantification. All these analytical standards can add a substantial cost to an already costly method, and labeled standards are not available for every compound, but these steps are essential to confidently identify and quantify small molecules.</p> <p>If metabolomics is conducted in the absence of an in-house chemical library, the user must rely on generic spectral matching using digital libraries for putative compound assignments, and reliability of such matches is limited without time consuming manual assessments of annotations and subsequent verification using analytical standards. However, reliable results can still be produced using open source software tools not made by a specific instrument vendor, particularly by integrating complementary digital reference libraries, and confirming identifications with pure analytical standards.</p> <p>Metabolomics is a powerful tool and gives us a snapshot into a wide spectrum of biological molecules in honey bees. It is helpful for understanding honey bee developmental physiology or adaptive molecular responses to various stressors. With ongoing small molecule discoveries and inclusion of these species in spectral libraries, metabolomics is emerging as the new power tool in modern omics analyses. Excitingly, the closely related field of lipidomics is also emerging in honey bees (Morfin et al., 2022), and co-extraction of metabolites, lipids, and pheromones has been performed on queens (McAfee et al., 2024). The diversity of small molecules that can be analyzed by LC-MSMS and integration with pheromone analysis will likely enable many new insights into honey bee physiology in the future.</p>"},{"location":"about/","title":"About the COLOSS Wiki Initiative","text":"<p>In the past decades, COLOSS members have joined forces multiple times to develop and condense standard methods related to honey bees, their pests, pathogens, and hive products. This led to the open access of four BEEBOOK volumes that have been enthusiastically welcomed by honey bee researchers worldwide. Among the chapters, the \u201cStandard methods for molecular research in Apis mellifera \u201d written by Evans and collaborators in 2013 has been a cornerstone for the standardization of honey bee molecular studies. However, since sequencing technologies and analyzing algorithms have made tremendous progress, many described methods needed a refreshing update. In parallel, other Apis species genomes have been sequenced, thus opening new research avenues in a comparative framework.</p>"},{"location":"about/#advancing-multi-omics-research-reproducibility","title":"Advancing Multi-Omics Research Reproducibility","text":"<p>Our team has spent the last years developing and summarizing new protocols related to the recent multi-omics field advances in a new chapter entitled \u201cStandard methods and good practices in Apis honey bee \u2018omics research.\u201d At the same time, next-generation sequencing and bioinformatics will continue to improve and change, mirroring how the multi-omics field is rapidly evolving. As a result, we concluded that a classical chapter would become outdated unless we adopted a modern communication approach.</p> <p>Online shared resources such as databases, codes, Wikis, and tutorials are great ways to provide protocols in a dynamic and collaborative framework. We propose here a set of standard protocols related to applications of genomics, transcriptomics, proteomics, epigenomics, metabolomics, metagenomics, and microbiome analyses in Apis honey bees. One advantage of this platform will be version control of methods, which can be corrected and improved by the developing team at the suggestion of COLOSS members or experts. This would allow readers to track major changes related to the progress of wet lab techniques or computing pipelines.</p> <p>While initially, omics data are often created for highly specialized scope and research questions, we noted that Apis honey bee research slowly moves toward multi-omics integration. This transition will push the boundaries of our understanding regarding honey bee biology and evolution. However, this would require the establishment of resources to aid communication, information sharing about tools and techniques, and data interpretation between different teams of honey bee experts. We hope that this chapter will lay some foundations by reviewing jargon and tools specific to each omic field and support the communication of innovative studies taking advantage of large and complex datasets.</p> <p>The methods and tutorials described here are still part of the chapter \u201cStandard Methods and Good Practices in Apis Honey Bee \u2018Omics Research\u201d in BEEBOOK Volume IV. If these resources are useful for you, please cite our work: \u201cTecher, M.A., Chakrabarti, P., Caesar, L., Eynard, S.E., Farrell, M.C., Foster, L.J., Gorrochategui-Ortega, J., Henriques, D., Li-Byarlay, H., Morre, J.T., Newton, I.L.G., Parejo, M., Pinto, M.A., Vignal, A., Zarraonaindia, I., McAfee, A. (2025) Standard methods and good practices in Apis honey bee \u2018omics research. In P. Chantawannakul, J.D. Evans, P. Neumann, N. L. Carreck, J. D. Ellis &amp; V. Dietemann (Eds.), The COLOSS BEEBOOK, Volume IV: Standard methods for Apis cerana research and Apis \u2018omics. Journal of Apicultural Research, 64(2).\"</p>"},{"location":"chapt_layout/","title":"1. The \u2018omics revolution in Apis: More data than meets the eye","text":""},{"location":"chapt_layout/#2-sample-management","title":"2. Sample management","text":""},{"location":"chapt_layout/#3-genome-sequencing","title":"3. Genome sequencing","text":""},{"location":"chapt_layout/#31-introduction","title":"3.1. Introduction","text":""},{"location":"chapt_layout/#32-genome-sequencing-technologies","title":"3.2. Genome sequencing technologies","text":""},{"location":"chapt_layout/#321-sanger-sequencing","title":"3.2.1. Sanger sequencing","text":""},{"location":"chapt_layout/#322-next-generation-sequencing","title":"3.2.2. Next generation sequencing","text":""},{"location":"chapt_layout/#323-long-read-sequencing","title":"3.2.3. Long-read sequencing","text":""},{"location":"chapt_layout/#33-the-reference-genome","title":"3.3. The reference genome","text":""},{"location":"chapt_layout/#331-assembling-the-reference-genome","title":"3.3.1. Assembling the reference genome","text":""},{"location":"chapt_layout/#3311-hi-c-chromosome-conformation-capture","title":"3.3.1.1. Hi-C chromosome conformation capture","text":""},{"location":"chapt_layout/#3312-dna-source-selection","title":"3.3.1.2. DNA source selection","text":""},{"location":"chapt_layout/#332-annotating-the-reference-genome","title":"3.3.2. Annotating the reference genome","text":""},{"location":"chapt_layout/#333-high-molecular-weight-dna-extraction","title":"3.3.3. High molecular weight DNA extraction","text":""},{"location":"chapt_layout/#34-small-and-large-variant-detection","title":"3.4. Small and large variant detection","text":""},{"location":"chapt_layout/#341-rad-seq","title":"3.4.1. RAD-seq","text":""},{"location":"chapt_layout/#35-sequencing-museum-specimens","title":"3.5. Sequencing museum specimens","text":""},{"location":"chapt_layout/#351-considerations","title":"3.5.1. Considerations","text":""},{"location":"chapt_layout/#352-materials","title":"3.5.2. Materials","text":""},{"location":"chapt_layout/#353-procedure","title":"3.5.3. Procedure","text":""},{"location":"chapt_layout/#3531-preparation-and-lysis","title":"3.5.3.1. Preparation and lysis","text":""},{"location":"chapt_layout/#3532-dna-extraction","title":"3.5.3.2. DNA extraction","text":""},{"location":"chapt_layout/#3533-precipitation","title":"3.5.3.3. Precipitation","text":""},{"location":"chapt_layout/#3534-washing","title":"3.5.3.4. Washing","text":""},{"location":"chapt_layout/#3535-final-solubilization","title":"3.5.3.5. Final solubilization","text":""},{"location":"chapt_layout/#354-sequencing-of-museum-and-ancient-genomes","title":"3.5.4. Sequencing of museum and ancient genomes","text":""},{"location":"chapt_layout/#355-guidance-on-the-data-analysis-methods","title":"3.5.5. Guidance on the data analysis methods","text":""},{"location":"chapt_layout/#356-applications-and-limitations","title":"3.5.6. Applications and limitations","text":""},{"location":"chapt_layout/#4-whole-genome-population-and-association-studies","title":"4. Whole-genome population and association studies","text":""},{"location":"chapt_layout/#41-introduction","title":"4.1. Introduction","text":""},{"location":"chapt_layout/#42-ploidy-and-sampling-considerations","title":"4.2. Ploidy and sampling considerations","text":""},{"location":"chapt_layout/#421-individual-sampling","title":"4.2.1. Individual sampling","text":""},{"location":"chapt_layout/#422-pooled-sampling","title":"4.2.2. Pooled sampling","text":""},{"location":"chapt_layout/#4221-groups-of-workers","title":"4.2.2.1. Groups of workers","text":""},{"location":"chapt_layout/#4222-groups-of-drones","title":"4.2.2.2. Groups of drones","text":""},{"location":"chapt_layout/#43-snp-and-indel-detection","title":"4.3. SNP and indel detection","text":""},{"location":"chapt_layout/#431-mapping-reads-with-bwa-mem-from-fastq-files-to-bam-files","title":"4.3.1. Mapping reads with BWA-MEM: From FASTQ files to BAM files","text":""},{"location":"chapt_layout/#432-marking-duplicate-reads-with-picard","title":"4.3.2. Marking duplicate reads with Picard","text":""},{"location":"chapt_layout/#433-base-quality-score-recalibration-bqsr-with-gatk","title":"4.3.3. Base quality score recalibration (BQSR) with GATK","text":""},{"location":"chapt_layout/#434-calling-variants-with-gatk","title":"4.3.4. Calling variants with GATK","text":""},{"location":"chapt_layout/#435-combining-all-samples-and-genotypes-with-gatk","title":"4.3.5. Combining all samples and genotypes with GATK","text":""},{"location":"chapt_layout/#436-filtering-variants-with-gatk-technical-filters","title":"4.3.6. Filtering variants with GATK: Technical filters","text":""},{"location":"chapt_layout/#437-filtering-variants-with-vcftools-data-quality","title":"4.3.7. Filtering variants with VCFtools: Data quality","text":""},{"location":"chapt_layout/#438-genotype-phasing","title":"4.3.8. Genotype phasing","text":""},{"location":"chapt_layout/#439-snp-annotation-with-snpeff","title":"4.3.9. SNP annotation with SnpEff","text":""},{"location":"chapt_layout/#4310-snp-analysis-by-sequencing-pooled-samples","title":"4.3.10. SNP analysis by sequencing pooled samples","text":""},{"location":"chapt_layout/#43101-from-fastq-files-to-bam-files","title":"4.3.10.1. From FASTQ files to BAM files","text":""},{"location":"chapt_layout/#43102-snp-selection-and-pileup-files","title":"4.3.10.2. SNP selection and pileup files","text":""},{"location":"chapt_layout/#43103-counting-reads-per-allele-with-popoolation","title":"4.3.10.3. Counting reads per allele with PoPoolation","text":""},{"location":"chapt_layout/#44-comparing-whole-genomes","title":"4.4. Comparing whole genomes","text":""},{"location":"chapt_layout/#441-conducting-a-pairwise-genome-comparison-with-last","title":"4.4.1. Conducting a pairwise genome comparison with LAST","text":""},{"location":"chapt_layout/#45-genome-wide-association-studies","title":"4.5. Genome-wide association studies","text":""},{"location":"chapt_layout/#451-considerations-for-phenotypic-data","title":"4.5.1. Considerations for phenotypic data","text":""},{"location":"chapt_layout/#452-considerations-for-sample-selection","title":"4.5.2. Considerations for sample selection","text":""},{"location":"chapt_layout/#4521-power-analysis","title":"4.5.2.1. Power analysis","text":""},{"location":"chapt_layout/#453-materials","title":"4.5.3. Materials","text":""},{"location":"chapt_layout/#4531-computational-resources","title":"4.5.3.1. Computational resources","text":""},{"location":"chapt_layout/#4532-genotypic-and-phenotypic-data","title":"4.5.3.2. Genotypic and phenotypic data","text":""},{"location":"chapt_layout/#454-methods","title":"4.5.4. Methods","text":""},{"location":"chapt_layout/#4541-preparation-of-phenotypic-data","title":"4.5.4.1. Preparation of phenotypic data","text":""},{"location":"chapt_layout/#4542-preparation-of-genotypic-data","title":"4.5.4.2. Preparation of genotypic data","text":""},{"location":"chapt_layout/#4543-performing-gwas-methods-and-software","title":"4.5.4.3. Performing GWAS: Methods and software","text":""},{"location":"chapt_layout/#4544-detecting-signatures-of-selection","title":"4.5.4.4. Detecting signatures of selection","text":""},{"location":"chapt_layout/#455-sources-of-variation","title":"4.5.5. Sources of variation","text":""},{"location":"chapt_layout/#456-quality-control-and-data-interpretation","title":"4.5.6. Quality control and data interpretation","text":""},{"location":"chapt_layout/#457-applications-and-limitations","title":"4.5.7. Applications and limitations","text":""},{"location":"chapt_layout/#46-population-genomics-experimental-design","title":"4.6. Population genomics: Experimental design","text":""},{"location":"chapt_layout/#461-sampling-strategy","title":"4.6.1. Sampling strategy","text":""},{"location":"chapt_layout/#4611-sample-sizes-of-individuals-and-markers","title":"4.6.1.1. Sample sizes of individuals and markers","text":""},{"location":"chapt_layout/#4612-sample-breadth","title":"4.6.1.2. Sample breadth","text":""},{"location":"chapt_layout/#4613-sampling-design","title":"4.6.1.3. Sampling design","text":""},{"location":"chapt_layout/#4614-sampling-workers-versus-drones","title":"4.6.1.4. Sampling workers versus drones","text":""},{"location":"chapt_layout/#4615-sampling-a-single-individual-versus-multiple-individuals-per-colony","title":"4.6.1.5. Sampling a single individual versus multiple individuals per colony","text":""},{"location":"chapt_layout/#47-population-genomics-filtering-and-summary-statistics-using-plink","title":"4.7. Population genomics: Filtering and summary statistics using PLINK","text":""},{"location":"chapt_layout/#471-download-and-installation","title":"4.7.1. Download and installation","text":""},{"location":"chapt_layout/#472-input-format-and-conversion","title":"4.7.2. Input format and conversion","text":""},{"location":"chapt_layout/#4721-variant-call-format-vcf","title":"4.7.2.1. Variant call format (VCF)","text":""},{"location":"chapt_layout/#4722-plink-1-binary-format-bim","title":"4.7.2.2. PLINK 1 binary format (.bim)","text":""},{"location":"chapt_layout/#4723-regular-plink-text-files","title":"4.7.2.3. Regular PLINK text files","text":""},{"location":"chapt_layout/#4724-filtering-and-handling-missing-data","title":"4.7.2.4. Filtering and handling missing data","text":""},{"location":"chapt_layout/#4725-computing-and-filtering-based-on-allele-frequency","title":"4.7.2.5. Computing and filtering based on allele frequency","text":""},{"location":"chapt_layout/#4726-computing-differentiation-indices-wrights-fst","title":"4.7.2.6. Computing differentiation indices: Wright's FST","text":""},{"location":"chapt_layout/#4727-estimating-linkage-disequilibrium","title":"4.7.2.7. Estimating linkage disequilibrium","text":""},{"location":"chapt_layout/#48-population-genomics-inferring-population-structure-using-admixture","title":"4.8. Population genomics: Inferring population structure using ADMIXTURE","text":""},{"location":"chapt_layout/#481-download-and-installation","title":"4.8.1. Download and installation","text":""},{"location":"chapt_layout/#482-input-files","title":"4.8.2. Input files","text":""},{"location":"chapt_layout/#483-methods","title":"4.8.3. Methods","text":""},{"location":"chapt_layout/#49-landscape-genomics-an-example-using-lfmm","title":"4.9. Landscape genomics: An example using LFMM","text":""},{"location":"chapt_layout/#491-materials","title":"4.9.1. Materials","text":""},{"location":"chapt_layout/#492-methods","title":"4.9.2. Methods","text":""},{"location":"chapt_layout/#410-applying-population-genomics-to-conservation-reduced-snp-analysis","title":"4.10. Applying population genomics to conservation: Reduced SNP analysis","text":""},{"location":"chapt_layout/#4101-materials","title":"4.10.1. Materials","text":""},{"location":"chapt_layout/#4102-methods","title":"4.10.2. Methods","text":""},{"location":"chapt_layout/#5-epigenomics","title":"5. Epigenomics","text":""},{"location":"chapt_layout/#51-introduction","title":"5.1. Introduction","text":""},{"location":"chapt_layout/#52-dna-methylation","title":"5.2. DNA methylation","text":""},{"location":"chapt_layout/#521-bisulfite-seq","title":"5.2.1. Bisulfite-seq","text":""},{"location":"chapt_layout/#5211-considerations","title":"5.2.1.1. Considerations","text":""},{"location":"chapt_layout/#5212-materials","title":"5.2.1.2. Materials","text":""},{"location":"chapt_layout/#5213-methods","title":"5.2.1.3. Methods","text":""},{"location":"chapt_layout/#522-methylated-dna-immunoprecipitation-sequencing-medip-seq","title":"5.2.2. Methylated DNA immunoprecipitation-sequencing (MeDIP-seq)","text":""},{"location":"chapt_layout/#5221-considerations","title":"5.2.2.1. Considerations","text":""},{"location":"chapt_layout/#5222-materials","title":"5.2.2.2. Materials","text":""},{"location":"chapt_layout/#5223-methods","title":"5.2.2.3. Methods","text":""},{"location":"chapt_layout/#523-data-processing-and-analysis","title":"5.2.3. Data processing and analysis","text":""},{"location":"chapt_layout/#5231-software-recommendations","title":"5.2.3.1. Software recommendations","text":""},{"location":"chapt_layout/#5232-data-repository","title":"5.2.3.2. Data repository","text":""},{"location":"chapt_layout/#5233-statistical-analysis","title":"5.2.3.3. Statistical analysis","text":""},{"location":"chapt_layout/#53-epitranscriptomics-rna-methylation-of-m6a","title":"5.3. Epitranscriptomics: RNA methylation of m6A","text":""},{"location":"chapt_layout/#531-considerations-for-testing-global-rna-methylation-of-m6a","title":"5.3.1. Considerations for testing global RNA methylation of m6A","text":""},{"location":"chapt_layout/#532-materials","title":"5.3.2. Materials","text":""},{"location":"chapt_layout/#533-procedure","title":"5.3.3. Procedure","text":""},{"location":"chapt_layout/#534-identifying-methylation-sites","title":"5.3.4. Identifying methylation sites","text":""},{"location":"chapt_layout/#535-software-recommendations","title":"5.3.5. Software recommendations","text":""},{"location":"chapt_layout/#54-chromatin-organization-and-histone-modifications","title":"5.4. Chromatin organization and histone modifications","text":""},{"location":"chapt_layout/#541-chromatin-immunoprecipitation-sequencing-and-transcription-factor-binding-motifs","title":"5.4.1. Chromatin immunoprecipitation sequencing and transcription factor binding motifs","text":""},{"location":"chapt_layout/#542-hi-c-chromatin-conformation","title":"5.4.2. Hi-C &amp; chromatin conformation","text":""},{"location":"chapt_layout/#543-chromatin-accessibility-and-transcriptional-factor-motifs","title":"5.4.3. Chromatin accessibility and transcriptional factor motifs","text":""},{"location":"chapt_layout/#544-detecting-histone-modifications-by-mass-spectrometry","title":"5.4.4. Detecting histone modifications by mass spectrometry","text":""},{"location":"chapt_layout/#55-applications-and-limitations","title":"5.5. Applications and limitations","text":""},{"location":"chapt_layout/#6-transcriptomics","title":"6. Transcriptomics","text":""},{"location":"chapt_layout/#61-introduction","title":"6.1. Introduction","text":""},{"location":"chapt_layout/#62-sequencing-technologies","title":"6.2. Sequencing technologies","text":""},{"location":"chapt_layout/#621-considerations","title":"6.2.1. Considerations","text":""},{"location":"chapt_layout/#622-illumina-sequencing-short-reads","title":"6.2.2. Illumina sequencing (short reads)","text":""},{"location":"chapt_layout/#623-third-generation-sequencing-long-reads","title":"6.2.3. Third generation sequencing (long reads)","text":""},{"location":"chapt_layout/#6231-considerations-for-choosing-a-long-read-platform","title":"6.2.3.1. Considerations for choosing a long-read platform","text":""},{"location":"chapt_layout/#63-single-cell-transcriptomics","title":"6.3. Single-cell transcriptomics","text":""},{"location":"chapt_layout/#631-considerations","title":"6.3.1. Considerations","text":""},{"location":"chapt_layout/#632-materials","title":"6.3.2. Materials","text":""},{"location":"chapt_layout/#633-sample-preparation-procedure-for-single-cell-sequencing","title":"6.3.3. Sample preparation procedure for single-cell sequencing","text":""},{"location":"chapt_layout/#64-data-handling-and-analysis","title":"6.4. Data handling and analysis","text":""},{"location":"chapt_layout/#641-rna-seq-and-differentially-expressed-genes-degs","title":"6.4.1. RNA-seq and differentially expressed genes (DEGs)","text":""},{"location":"chapt_layout/#642-gene-network-analysis","title":"6.4.2. Gene network analysis","text":""},{"location":"chapt_layout/#643-single-cell-transcriptomics","title":"6.4.3. Single-cell transcriptomics","text":""},{"location":"chapt_layout/#6431-10x-genomics-specific-software","title":"6.4.3.1. 10x Genomics specific software","text":""},{"location":"chapt_layout/#6432-third-party-software","title":"6.4.3.2. Third party software","text":""},{"location":"chapt_layout/#65-applications-and-limitations","title":"6.5. Applications and limitations","text":""},{"location":"chapt_layout/#7-functional-genomics-and-xenobiotic-treatment","title":"7. Functional genomics and xenobiotic treatment","text":""},{"location":"chapt_layout/#71-introduction","title":"7.1. Introduction","text":""},{"location":"chapt_layout/#72-crispr","title":"7.2. CRISPR","text":""},{"location":"chapt_layout/#721-considerations","title":"7.2.1. Considerations","text":""},{"location":"chapt_layout/#722-materials","title":"7.2.2. Materials","text":""},{"location":"chapt_layout/#723-methods-for-crisprcas9-gene-editing-of-embryos","title":"7.2.3. Methods for CRISPR/Cas9 gene editing of embryos","text":""},{"location":"chapt_layout/#7231-generating-cas9-protein","title":"7.2.3.1. Generating Cas9 protein","text":""},{"location":"chapt_layout/#7232-generating-sgrna","title":"7.2.3.2. Generating sgRNA","text":""},{"location":"chapt_layout/#7233-ribonucleoprotein-assembly","title":"7.2.3.3. Ribonucleoprotein assembly","text":""},{"location":"chapt_layout/#7234-egg-collection-and-microinjection","title":"7.2.3.4. Egg collection and microinjection","text":""},{"location":"chapt_layout/#73-rna-interference","title":"7.3. RNA interference","text":""},{"location":"chapt_layout/#731-rnai-considerations","title":"7.3.1. RNAi considerations","text":""},{"location":"chapt_layout/#732-methods-for-nanoparticle-mediated-rnai","title":"7.3.2. Methods for nanoparticle-mediated RNAi","text":""},{"location":"chapt_layout/#7321-materials","title":"7.3.2.1. Materials","text":""},{"location":"chapt_layout/#7322-procedure","title":"7.3.2.2. Procedure","text":""},{"location":"chapt_layout/#74-xenobiotic-treatment","title":"7.4. Xenobiotic treatment","text":""},{"location":"chapt_layout/#741-xenobiotic-treatment-considerations","title":"7.4.1 Xenobiotic treatment considerations","text":""},{"location":"chapt_layout/#742-materials","title":"7.4.2. Materials","text":""},{"location":"chapt_layout/#743-procedure","title":"7.4.3 Procedure","text":""},{"location":"chapt_layout/#7431-thorax-application","title":"7.4.3.1 Thorax application","text":""},{"location":"chapt_layout/#7432-injection","title":"7.4.3.2. Injection","text":""},{"location":"chapt_layout/#7433-feeding-individual-bees","title":"7.4.3.3. Feeding individual bees","text":""},{"location":"chapt_layout/#7434-flight-cage-feeding","title":"7.4.3.4. Flight cage feeding","text":""},{"location":"chapt_layout/#75-applications-and-limitations","title":"7.5. Applications and limitations","text":""},{"location":"chapt_layout/#8-proteomics","title":"8. Proteomics","text":""},{"location":"chapt_layout/#81-introduction","title":"8.1. Introduction","text":""},{"location":"chapt_layout/#82-standard-methods-for-shot-gun-proteomics-sample-preparation","title":"8.2. Standard methods for shot-gun proteomics sample preparation","text":""},{"location":"chapt_layout/#821-considerations","title":"8.2.1. Considerations","text":""},{"location":"chapt_layout/#8211-general","title":"8.2.1.1. General","text":""},{"location":"chapt_layout/#8212-sample-handling","title":"8.2.1.2. Sample handling","text":""},{"location":"chapt_layout/#8213-reagent-handling","title":"8.2.1.3. Reagent handling","text":""},{"location":"chapt_layout/#822-materials","title":"8.2.2. Materials","text":""},{"location":"chapt_layout/#823-proteomics-methods","title":"8.2.3. Proteomics methods","text":""},{"location":"chapt_layout/#8231-lysis-and-precipitation","title":"8.2.3.1. Lysis and precipitation","text":""},{"location":"chapt_layout/#8232-solubilization-and-digestion","title":"8.2.3.2. Solubilization and digestion","text":""},{"location":"chapt_layout/#8233-peptide-desalting-and-resuspension","title":"8.2.3.3. Peptide desalting and resuspension","text":""},{"location":"chapt_layout/#83-liquid-chromatography-and-mass-spectrometry","title":"8.3. Liquid chromatography and mass spectrometry","text":""},{"location":"chapt_layout/#84-proteomics-data-processing","title":"8.4. Proteomics data processing","text":""},{"location":"chapt_layout/#841-software-recommendations","title":"8.4.1. Software recommendations","text":""},{"location":"chapt_layout/#8411-maxquant-and-dia-nn-search-parameters","title":"8.4.1.1. MaxQuant and DIA-NN search parameters","text":""},{"location":"chapt_layout/#8412-choosing-an-appropriate-protein-database","title":"8.4.1.2. Choosing an appropriate protein database","text":""},{"location":"chapt_layout/#8413-statistical-analysis","title":"8.4.1.3 Statistical analysis","text":""},{"location":"chapt_layout/#85-applications-and-limitations","title":"8.5. Applications and limitations","text":""},{"location":"chapt_layout/#9-metabolomics","title":"9. Metabolomics","text":""},{"location":"chapt_layout/#91-introduction","title":"9.1. Introduction","text":""},{"location":"chapt_layout/#92-sample-preparation-for-metabolomics","title":"9.2. Sample preparation for metabolomics","text":""},{"location":"chapt_layout/#921-considerations","title":"9.2.1. Considerations","text":""},{"location":"chapt_layout/#9211-general","title":"9.2.1.1. General","text":""},{"location":"chapt_layout/#9212-sample-handling","title":"9.2.1.2. Sample handling","text":""},{"location":"chapt_layout/#9213-reagent-handling","title":"9.2.1.3. Reagent handling","text":""},{"location":"chapt_layout/#922-materials","title":"9.2.2. Materials","text":""},{"location":"chapt_layout/#923-metabolomics-methods","title":"9.2.3. Metabolomics methods","text":""},{"location":"chapt_layout/#9231-sample-homogenization","title":"9.2.3.1. Sample homogenization","text":""},{"location":"chapt_layout/#9232-extraction","title":"9.2.3.2. Extraction","text":""},{"location":"chapt_layout/#93-chromatography-and-mass-spectrometry","title":"9.3. Chromatography and mass spectrometry","text":""},{"location":"chapt_layout/#94-metabolomics-data-processing","title":"9.4. Metabolomics data processing","text":""},{"location":"chapt_layout/#95-metabolomics-applications-and-limitations","title":"9.5. Metabolomics applications and limitations","text":""},{"location":"chapt_layout/#10-microbiome-analysis","title":"10. Microbiome analysis","text":""},{"location":"chapt_layout/#101-introduction","title":"10.1. Introduction","text":""},{"location":"chapt_layout/#102-sampling-and-dna-extraction","title":"10.2. Sampling and DNA extraction","text":""},{"location":"chapt_layout/#1021-considerations","title":"10.2.1. Considerations","text":""},{"location":"chapt_layout/#10211-general","title":"10.2.1.1. General","text":""},{"location":"chapt_layout/#10212-tissue-sample-handling","title":"10.2.1.2. Tissue sample handling","text":""},{"location":"chapt_layout/#10213-hive-material-sample-handling","title":"10.2.1.3. Hive material sample handling","text":""},{"location":"chapt_layout/#1022-protocol-for-tissue-samples","title":"10.2.2. Protocol for tissue samples","text":""},{"location":"chapt_layout/#10221-materials","title":"10.2.2.1. Materials","text":""},{"location":"chapt_layout/#10222-dissection-methods","title":"10.2.2.2. Dissection methods","text":""},{"location":"chapt_layout/#10223-dna-extraction-methods","title":"10.2.2.3. DNA extraction methods","text":""},{"location":"chapt_layout/#1023-protocol-for-sampling-hive-materials","title":"10.2.3. Protocol for sampling hive materials","text":""},{"location":"chapt_layout/#10231-materials","title":"10.2.3.1. Materials","text":""},{"location":"chapt_layout/#10232-methods-for-bee-bread-sampling-and-dna-extraction","title":"10.2.3.2. Methods for bee bread sampling and DNA extraction","text":""},{"location":"chapt_layout/#10233-methods-for-hive-entrance-sampling-and-dna-extraction","title":"10.2.3.3. Methods for hive entrance sampling and DNA extraction","text":""},{"location":"chapt_layout/#103-amplicon-sequencing","title":"10.3. Amplicon sequencing","text":""},{"location":"chapt_layout/#1031-considerations","title":"10.3.1. Considerations","text":""},{"location":"chapt_layout/#1032-materials-for-amplicon-sequencing","title":"10.3.2. Materials for amplicon sequencing","text":""},{"location":"chapt_layout/#1033-methods-for-amplicon-sequencing","title":"10.3.3. Methods for amplicon sequencing","text":""},{"location":"chapt_layout/#104-microbiome-data-analysis","title":"10.4. Microbiome data analysis","text":""},{"location":"chapt_layout/#1041-recommended-software","title":"10.4.1. Recommended software","text":""},{"location":"chapt_layout/#1042-guidance-on-the-data-analysis-methods-an-example-with-qiime-2","title":"10.4.2. Guidance on the data analysis methods: An example with QIIME 2","text":""},{"location":"chapt_layout/#10421-importing-data","title":"10.4.2.1. Importing data","text":""},{"location":"chapt_layout/#10422-non-biological-sequence-removal","title":"10.4.2.2. Non-biological sequence removal","text":""},{"location":"chapt_layout/#10423-sequence-quality-control-denoising","title":"10.4.2.3. Sequence quality control (denoising)","text":""},{"location":"chapt_layout/#10424-removing-biological-contamination","title":"10.4.2.4. Removing biological contamination","text":""},{"location":"chapt_layout/#105-applications-and-limitations","title":"10.5. Applications and limitations","text":""},{"location":"chapt_layout/#11-data-management-and-open-access-sharing","title":"11. Data management and open access sharing","text":""},{"location":"chapt_layout/#111-metadata-standardization","title":"11.1. Metadata standardization","text":""},{"location":"chapt_layout/#1111-common-problems-with-apis-related-bioprojects","title":"11.1.1. Common problems with Apis-related BioProjects","text":""},{"location":"chapt_layout/#1112-common-problems-with-apis-related-biosamples","title":"11.1.2. Common problems with Apis-related BioSamples","text":""},{"location":"chapt_layout/#112-sharing-pipelines-and-scripts","title":"11.2. Sharing pipelines and scripts","text":""},{"location":"chapt_layout/#12-the-future-of-apis-omics-biological-integration","title":"12. The future of Apis omics: Biological integration","text":""},{"location":"theteam/","title":"Meet the team","text":""},{"location":"theteam/#coloss-editor","title":"COLOSS Editor:","text":""},{"location":"theteam/#jay-d-evans","title":"Jay D. Evans","text":"<p>USDA-ARS, Bee Research Lab, BARC-E Bldg 306, Beltsville MD 20705, USA.</p> <p>[Short Bio: -]</p>"},{"location":"theteam/#authors-short-bio-by-alphabetical-order","title":"Authors short bio (by alphabetical order):","text":""},{"location":"theteam/#priyadarshini-chakrabarti","title":"Priyadarshini Chakrabarti","text":"<p>Washington State University affiliation Department of Entomology, Washington State University, Pullman, WA 99164, USA</p>"},{"location":"theteam/#expertise-metabolomics-proteomics-lipidomics-apis-mellifera","title":"Expertise: Metabolomics, proteomics, lipidomics, Apis mellifera","text":"<p>Priya is an Assistant Professor at the Department of Entomology at Washington State University. Priya is also a courtesy faculty at Oregon State University. Priya studies the interactive impacts of multiple stressors on bees, for example poor nutrition, pesticides, and climate change. She uses a wide array of multidisciplinary techniques across fields such as physiology, toxicology, functional biology, multi-omics approaches, and neuroethology to address her research questions. She is currently serving as the secretary/treasurer of the American Association of Professional Apiculturists, the North American Chair of the COLOSS bee nutrition taskforce and is the Vice-President Elect of the PBT Section of the Entomological Society of America. She also served as the chair of the Early Career Professionals Committee of the Entomological Society of America. In addition to the research community, Priya enjoys working with stakeholders, policymakers and the general community in protecting bee pollinators and raising pollinator awareness. She is also a children's book author who engages young readers and helps protect pollinators. More information about her research can be found on her lab\u2019s website.</p> <p></p>"},{"location":"theteam/#lilian-caesar","title":"L\u00edlian Caesar","text":"<p>Department of Biology, Indiana University, Bloomington, Indiana, USA</p>"},{"location":"theteam/#expertise-omics-microbiomes-ecology-and-evolution-of-symbiosis-host-microbe-and-microbe-microbe-interactions-honey-bees-and-stingless-bees","title":"Expertise: Omics, microbiomes, ecology and evolution of symbiosis, host-microbe and microbe-microbe interactions, honey bees, and stingless bees","text":"<p>L\u00edlian earned her PhD at the Universidade Federal do Rio Grande do Sul, Brazil. Currently she is a postdoctoral fellow in the Newton Lab, Department of Biology, at Indiana University, Bloomington. Her research focuses on the eco-evolutionary dynamics of symbiosis, and the impact of symbionts for host health. Her model system is the highly eusocial bees, i.e. honey bees and stingless bees. L\u00edlian is interested in characterizing and studying microbiomes, including bacteria, fungi and viruses associated both with the adult bees, the brood in development and hive environments. For her investigations, L\u00edlian combines multi-omics, in vitro/in vivo microbiology assays, and field work.</p> <p></p>"},{"location":"theteam/#sonia-e-eynard","title":"Sonia E. Eynard","text":"<p>GenPhySE, Universit\u00e9 de Toulouse, INRAE, ENVT, 31326, Castanet Tolosan, France</p>"},{"location":"theteam/#expertise-population-genomics-quantitative-genetics-livestock-species-apis-mellifera","title":"Expertise: Population genomics, quantitative genetics, livestock species, Apis mellifera","text":"<p>As an undergraduate, Sonia studied wildlife conservation and the use of population genetics to advise on conservation strategies. In 2018 she graduated with a PhD in Animal Breeding and Genetics from the Erasmus Mundus project EGS-ABG with a double diploma from Wageningen University and AgroParisTech, where she looked into ways to mitigate the impact of selection on genetic diversity in livestock using next generation sequencing data. After completing her PhD she joined INRAE, in Toulouse, to work on the BeeStrong project. The aim was to identify genetic markers linked to resistance to Varroa destructor infestation in the French Apis mellifera population using pool sequencing experiments. She also contributed to a population genomics project to better understand and describe the genetic diversity observed in the European bee populations. Always fond of analysing new data and developing new methods, in 2023 she moved to a new postdoctoral position working on epigenetics and how it can be included in current breeding decisions in livestock species. Very much in love with honey bees, she hopes to be able to develop her own research line using new data and methods to answer challenges faced in honey bee genomics.</p> <p></p>"},{"location":"theteam/#m-catherine-farrell","title":"M. Catherine Farrell","text":"<p>Agricultural Research and Development Program, Central State University, Wilberforce, OH</p>"},{"location":"theteam/#expertise-behavior-single-cell-transcriptomics-neurobiology-apis-mellifera","title":"Expertise: Behavior, single cell transcriptomics, neurobiology, Apis mellifera","text":"<p>Catherine is a Research Assistant Professor of bee genomics at Central State University. As an undergraduate, her primary research interests were in the transcriptional regulation of circadian clock genes in Xenopus frogs. As a graduate student, her dissertation research focused on Drosophila neurobiology. In particular, she studied the role of serotonin in sensorimotor plasticity, and applied the diverse tools available within the Drosophila model system to look specifically at the neural circuitry underlying coordinated crawling behavior. After taking some time off after gaining her PhD in 2015 to teach, she joined Central State as a postdoctoral fellow, where she utilized transcriptomics, single cell transcriptomics, and epigenomics to understand honey bee grooming behavior.</p> <p></p>"},{"location":"theteam/#leonard-j-foster","title":"Leonard J. Foster","text":"<p>Department of Biochemistry and Molecular Biology, Michael Smith Laboratories, University of British Columbia, Vancouver, BC V6T1Z4, Canada</p>"},{"location":"theteam/#expertise-proteomics-bioinformatics-apis-mellifera-and-many-other-model-systems","title":"Expertise: Proteomics, bioinformatics, Apis mellifera and many other model systems","text":"<p>Leonard is a Professor in the Department of Biochemistry and Molecular Biology at the University of British Columbia. Dr. Foster comes from a family of beekeepers and got his introduction to academic bee research while doing his Bachelor\u2019s degree in biochemistry at Simon Fraser University, where he worked with Drs. Winston and Slessor on honey bee pheromones, particularly the components of queen mandibular pheromone. He then completed a PhD in Toronto and a postdoctoral fellowship in Denmark before starting his current position in 2005. The first independent operating grant that Dr. Foster secured was to study how bee pathogens were able to manipulate the protein machinery within bee cells. Since that time he has led three very large-scale projects that have investigated some of the molecular mechanisms behind disease resistance in bees. This effort has recently moved into trying to apply this knowledge by using this information to guide selective breeding for hygienic behavior in honey bees. He is very active in extension and frequently engages the public on various aspects of honey bee biology.</p> <p></p>"},{"location":"theteam/#june-gorrochategui-ortega","title":"June Gorrochategui-Ortega","text":"<p>Department of Genetics, Physical Anthropology and Animal Physiology, Applied Genomics and Bioinformatics lab., University of the Basque Country (UPV/EHU), Leioa, Spain</p>"},{"location":"theteam/#expertise-bioinformatics-metagenomics-apis-mellifera","title":"Expertise: Bioinformatics, metagenomics, Apis mellifera","text":"<p>June is a PhD student at the Applied Genomics and Bioinformatics group, at the Department of Genetics, Physical Anthropology and Animal Physiology of the University of the Basque Country (UPV/EHU, Spain). She is currently working on her PhD thesis (Basque Government PhD student grant), entitled \u201cIdentification of microbial profiles to promote colony health: towards the reduction of chemical residues in Apiculture (ERLEMIKRO)\u201d. Her research aims to identify and characterize the microbial taxonomic and functional diversity of honey bee hive, for the identification of profiles that harbor symbiotic properties beneficial for honey bee health; by using metagenomics and metatranscriptomics.</p> <p></p>"},{"location":"theteam/#dora-henriques","title":"Dora Henriques","text":"<p>CIMO, LA SusTEC, Instituto Polit\u00e9cnico de Bragan\u00e7a, Campus de Santa Apol\u00f3nia, 5300-253 Bragan\u00e7a, Portugal.</p>"},{"location":"theteam/#expertise-population-genomics-bioinformatics-conservation-genomics-apis-mellifera","title":"Expertise: Population genomics, bioinformatics, conservation genomics, Apis mellifera","text":"<p>Dora is a junior researcher at the Mountain Research Centre (CIMO) and at the Associated Laboratory for Sustainability and Technology in Mountain Regions (SusTEC). She completed her PhD in Molecular and Environmental Biology at Minho University in 2018 with the thesis entitled \u201cEmployment of whole genome resequencing to reveal the evolutionary history and to develop molecular tools for Western European honey bees (Apis mellifera subspecies)\u201d. Her main research interests are honey bee evolution and the development of molecular tools for honey bee conservation. She has collaborated on eight research projects, publishing over 20 peer-reviewed scientific articles and 15 popular articles, while also presenting over 90 conference papers. She is a member of the editorial board of the Journal of Apicultural Research (JAR).</p> <p></p>"},{"location":"theteam/#hongmei-li-byarlay","title":"Hongmei Li-Byarlay","text":"<p>Agricultural Research and Development Program, Central State University, Wilberforce, OH Department of Agricultural and Life Sciences, Central State University, Wilberforce, OH</p>"},{"location":"theteam/#expertise-transcriptomics-epigenomics-functional-genomics-of-honey-bees","title":"Expertise: Transcriptomics, epigenomics, functional genomics of honey bees","text":"<p>Hongmei is currently an Associate Professor at Central State University in the State of Ohio (U.S.A). Her doctoral degree is in entomology from Purdue University (Indiana) where she studied the genetics and physiology of Drosophila melanogaster with Drs. Barry Pittendrigh and Larry Murdock. She then worked at the University of Illinois at Urbana-Champaign (UIUC) and at North Carolina State University for her postdoctoral research. Since 2010, she has conducted her research on bee behavior, genetics, molecular biology and physiology. In 2017, she started her own lab\u2019s research in honey bee functional genomics, transcriptomics, epigenomics such as DNA and RNA methylation, molecular mechanisms underlying social behaviors, selection and breeding for mite resistant stocks, oxidative stress and aging. She has published 40+ peer-reviewed papers and book chapters. She has presented 100+ talks for research, education, extension, outreach to different communities. Her research lab received funding support from the National Science Foundation and U.S. Department of Agriculture. More information can be found on her lab\u2019s website and her Google Scholar page.</p> <p></p>"},{"location":"theteam/#alison-mcafee","title":"Alison McAfee","text":"<p>Department of Biochemistry and Molecular Biology, Michael Smith Laboratories, University of British Columbia, Vancouver, BC V6T1Z4, Canada</p> <p>Department of Applied Ecology, North Carolina State University, Raleigh, NC 27695-7617, USA</p>"},{"location":"theteam/#expertise-proteomics-queen-biology-apis-mellifera","title":"Expertise: Proteomics, queen biology, Apis mellifera","text":"<p>Alison completed her PhD in Genome Science and Technology at the University of British Columbia in 2018. She is now a postdoctoral fellow and uses mass spectrometry to study how extreme temperatures associated with climate change are affecting honey bee and bumble bee fertility and survival. Alison also loves science communication, and has published 90+ magazine articles for publications including Scientific American, American Bee Journal, Conversation Canada, and UBC Magazine. Her research has been covered by outlets such as New Scientist, National Geographic, Science Friday and Scientific American, among others. In 2022, Alison received the L\u2019Oreal-UNESCO for Women in Science International Rising Talents award for North America, becoming one of fifteen top female scientists globally who are recognized for their leadership and research each year.</p> <p></p>"},{"location":"theteam/#jeffrey-t-morre","title":"Jeffrey T. Morr\u00e9","text":"<p>Department of Chemistry, Oregon State University, Corvallis, OR 97331 USA</p>"},{"location":"theteam/#expertise-biological-mass-spectrometry","title":"Expertise: Biological mass spectrometry","text":"<p>Jeffrey has 26 years of mass spectrometry experience. Jeffrey's current position is operations manager for the Oregon State University Mass Spectrometry Center.</p> <p></p>"},{"location":"theteam/#irene-l-g-newton","title":"Irene L. G. Newton","text":"<p>Professor of Biology, Department of Biology, Indiana University, Bloomington, Indiana, USA</p>"},{"location":"theteam/#expertise-host-microbe-interactions-microbial-genomics-microbiomes","title":"Expertise: Host-microbe interactions, microbial genomics, microbiomes","text":"<p>Irene is a Professor of Biology at Indiana University, Bloomington where she studies mechanisms of host-microbe symbiosis. One of her model systems is the honey bee microbiome, where she focuses on understanding the composition of the community and its function.</p> <p></p>"},{"location":"theteam/#melanie-parejo","title":"Melanie Parejo","text":"<p>Department of Genetics, Physical Anthropology and Animal Physiology, Applied Genomics and Bioinformatics lab., University of the Basque Country (UPV/EHU), Leioa, Spain</p>"},{"location":"theteam/#expertise-population-genomics-bioinformatics-apis-mellifera","title":"Expertise: Population genomics, bioinformatics, Apis mellifera","text":"<p>Melanie has a life science background, holding a master's degree in Ecology and Evolution from the Swiss Federal Institute of Technology, Zurich, (ETHZ). She also holds a PhD in Biochemistry and Molecular Biology (2017) from the University of Bern, Switzerland, in collaboration with the Swiss Bee Research Center, Agroscope, the topic of her thesis being \u201cHoney bee Conservation and Population Genetics using Whole-Genome Sequence Data\u201d. With a postdoctoral fellowship from the Swiss National Science Foundation, she now works at the University of the Basque Country (UPV/EHU), where she continues to study honey bee genomics. Since 2018, she has been the Assistant Editor of the Journal of Apicultural Research, published on behalf of the International Bee Research Association. Her interests lie in applied genomics in apiculture, diagnostic molecular tools, conservation, ecology and hologenomics. Findings of her research have led to new and adapted management practices such as increasing the hybridization threshold for native honey bees in conservation areas, genetic monitoring tools such as a high-throughput introgression test for bee breeding based on single-nucleotide polymorphisms (SNPs), a subspecies diagnostic SNP chip to classify European subspecies, and a SNP-based paternity assignment test to be employed in the evaluation of breeding mating stations\u2019 efficiency.</p> <p></p>"},{"location":"theteam/#m-alice-pinto","title":"M. Alice Pinto","text":"<p>CIMO, LA SusTEC, Instituto Polit\u00e9cnico de Bragan\u00e7a, Campus de Santa Apol\u00f3nia, 5300-253 Bragan\u00e7a, Portugal.</p>"},{"location":"theteam/#expertise-population-genomics-apis-mellifera","title":"Expertise: Population genomics, Apis mellifera","text":"<p>Alice is a Professor at the Polytechnic Institute of Bragan\u00e7a (IPB) and a researcher at the Mountain Research Centre (CIMO), Portugal. She earned a doctoral degree in entomology from Texas A&amp;M University in the United States. She developed a keen interest in honey bees during her PhD research, while studying a fascinating feral population living in oak tree cavities. For her PhD dissertation, she examined the genetic changes in this population undergoing Africanization. Currently, her main research interests involve uncovering the processes that shape extant genetic diversity patterns in honey bee populations, with a particular focus on understanding the basis of local adaptation. She has coordinated and collaborated in over 15 national and international research projects funded by the Portuguese Science Foundation and the European Commission. These projects have dealt with a wide array of subjects, such as: (i) the genomics of Apis mellifera to the genetics of its predators (Vespa velutina) and diseases (viruses and nosemosis), and (ii) the development of SNP-based assays and ML-based software for honey bee identification, and (iii) the botanical identification of bee-collected pollen via ITS2-metabarcoding. She has published over 60 peer-reviewed scientific articles, 40 popular articles, and presented over 250 conference papers. She is a member of the editorial board of Scientific Reports, Insects, and Frontiers in Bee Science.</p> <p></p>"},{"location":"theteam/#maeva-a-techer","title":"Maeva A. Techer","text":"<p>Okinawa Institute of Science and Technology, 1919-1 Tancha, Onna-son,904-0495 Okinawa, Japan</p> <p>Texas A&amp;M University, Department of Entomology, College Station, USA</p> <p>Behavioral Plasticity Research Institute, NSF-BII, USA</p>"},{"location":"theteam/#expertise-population-genomics-comparative-genomics-transcriptomics-apis-mellifera-varroa-destructor","title":"Expertise: Population Genomics, Comparative genomics, Transcriptomics, Apis mellifera, Varroa destructor","text":"<p>Maeva joined the Behavioral Plasticity Research Institute as a Postdoctoral Researcher and has been based at Texas A&amp;M University since 2021. While her current research focuses on locust phase polyphenism, she is dedicating herself to learning how to bridge the gap between disciplines and find shared evolution in diverse arthropods to contribute to the new generation of integrative biologists. She completed a PhD in Population Genetics on insular native honey bees evolution at the University of Reunion Island (where she was born). There she learned to combine classical population genetics and demographic inferences to retrace the origins of modern populations and understand which factors shaped their evolution over time. She started using whole genome sequencing during her postdoctoral position at the Okinawa Institute of Science and Technology in Japan, where she focused on the most detrimental honey bee parasites: Varroa mites. Her research seeks to understand how species and populations can rapidly respond and adapt to environmental changes by generating and maintaining variability.</p> <p></p>"},{"location":"theteam/#alain-vignal","title":"Alain Vignal","text":"<p>GenPhySE, Universit\u00e9 de Toulouse, INRAE, ENVT, 31326, Castanet Tolosan, France</p>"},{"location":"theteam/#expertise-population-and-comparative-genomics-qtl-mapping-poultry-apis-mellifera","title":"Expertise: Population and comparative genomics, QTL mapping, poultry, Apis mellifera","text":"<p>Alain obtained his PhD in molecular biology from Orsay University (France) in 1991. His first expertise was on sequencing genes coding for human blood groups and building genetic maps for locating markers linked to monogenic diseases. He now works at INRAE in Toulouse, France, where he first worked on QTL mapping in chickens and was subsequently involved in the consortiums for the assembly of reference genomes of several poultry species. First the chicken in 2004 (Sanger sequencing) and helping with updates until 2017, then the mallard duck, Muskovy duck, quail, and guinea fowl. With the establishment of short-read parallel sequencing and long-read sequencing as new standards, population genomics at the genome scale became possible, which he did in guinea fowl and now in honey bees. His main focus is to better understand the genetic diversity and admixture in European honey bee populations and to deepen our understanding of the honey bee genome structure.</p> <p></p>"},{"location":"theteam/#iratxe-zarraonaindia","title":"Iratxe Zarraonaindia","text":"<p>Department of Genetics, Physical Anthropology and Animal Physiology, Applied Genomics and Bioinformatics lab., University of the Basque Country (UPV/EHU), Leioa, Spain IKERBASQUE, Basque Foundation for Science, Bilbao, Spain</p>"},{"location":"theteam/#expertise-bioinformatics-metagenomics-apis-mellifera_1","title":"Expertise: Bioinformatics, metagenomics, Apis mellifera","text":"<p>Zarraonaindia is an Ikerbasque Research Associate at the Department of Genetics, Physical Anthropology and Animal Physiology of the University of the Basque Country (UPV/EHU, Spain) since 2021. She conducted her postdoctoral research (2012-2015) at the Bioscience Division of Argonne National Laboratory (Chicago, USA), where she acquired ample expertise on environmental microbiology and NGS bioinformatics by joining a massively collaborative project that aimed to characterize microbial life on Earth (The Earth Microbiome Project). In 2016 Zarraonaindia joined the Applied Genomics and Bioinformatics group at UPV/EHU, recently becoming the lead investigator. Her current research interest is implementing NGS approaches for the investigation of the impact of anthropic activities on apiculture, by better understanding microbe-bee interactions and how microbes influence honey bee disease resistance, working towards environmentally friendly alternatives to agrochemicals. She teaches \u201cBioinformatics and omics\u201d classes at several master\u2019s programs and has participated in 3 European, 1 national and a local research project to unravel the contribution of landscape, environment, management, genetics, and microbiota in honey bee health.</p>"}]}